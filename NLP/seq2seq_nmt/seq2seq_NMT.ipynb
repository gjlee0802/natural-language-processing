{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "accaec71aa044b1c86d9cf9817552f1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_17095cb063a246b78bd5f4db6a3bc9a6",
              "IPY_MODEL_284121f6b6d145e981e553486e54e042",
              "IPY_MODEL_3c3575e80b054588b24b938a81fa9d64"
            ],
            "layout": "IPY_MODEL_0cbf5c0798e84516b1f0b239e0b3c6ce"
          }
        },
        "17095cb063a246b78bd5f4db6a3bc9a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee764be16d714d479f2330196c88c627",
            "placeholder": "​",
            "style": "IPY_MODEL_e2db0da360cc4091913d7a467a6b8e93",
            "value": "training routine: 100%"
          }
        },
        "284121f6b6d145e981e553486e54e042": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3172fae225f64083819d7ca2e0a09821",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fd3e730e048c47369873c2121647c7fe",
            "value": 100
          }
        },
        "3c3575e80b054588b24b938a81fa9d64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07104ce38fdc418898b75d9d76e39fbf",
            "placeholder": "​",
            "style": "IPY_MODEL_3503ded6ec7f4ffb92438dcc47f1c790",
            "value": " 100/100 [2:09:51&lt;00:00, 77.88s/it, best_val=2.53]"
          }
        },
        "0cbf5c0798e84516b1f0b239e0b3c6ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee764be16d714d479f2330196c88c627": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2db0da360cc4091913d7a467a6b8e93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3172fae225f64083819d7ca2e0a09821": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd3e730e048c47369873c2121647c7fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "07104ce38fdc418898b75d9d76e39fbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3503ded6ec7f4ffb92438dcc47f1c790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b638e5e48db2487ea5fb242e70fbc32f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a2d724a61c04a5d9f56b06e35616780",
              "IPY_MODEL_ea6436d8dbc54875809c7c989d4bb7c6",
              "IPY_MODEL_7997b911467d4067bacc4a4e27504a1e"
            ],
            "layout": "IPY_MODEL_ff8a5a426fcc4a2eb8a6b7dff86afb87"
          }
        },
        "4a2d724a61c04a5d9f56b06e35616780": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d205549f0674287a149178469edcfbe",
            "placeholder": "​",
            "style": "IPY_MODEL_cfc9c442a72d47ccbeee9e4d120fc1e9",
            "value": "split=train:  99%"
          }
        },
        "ea6436d8dbc54875809c7c989d4bb7c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b285b49943440419b149af8e24240b2",
            "max": 142,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f21550ff33824a02b1d497facf7c2ffa",
            "value": 141
          }
        },
        "7997b911467d4067bacc4a4e27504a1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1f44b7057194cda9c82ea810f02c14f",
            "placeholder": "​",
            "style": "IPY_MODEL_738ceeb0448943e7948a7849ef46c82e",
            "value": " 141/142 [2:09:45&lt;00:00,  1.53it/s, acc=71.6, epoch=99, loss=1.17]"
          }
        },
        "ff8a5a426fcc4a2eb8a6b7dff86afb87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d205549f0674287a149178469edcfbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfc9c442a72d47ccbeee9e4d120fc1e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b285b49943440419b149af8e24240b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f21550ff33824a02b1d497facf7c2ffa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1f44b7057194cda9c82ea810f02c14f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "738ceeb0448943e7948a7849ef46c82e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66412d18c4954268854bff2cf534d1df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_36aca0760e234959bd205d88a8840b77",
              "IPY_MODEL_632df7c717464a5ab5e15273bcbc9a78",
              "IPY_MODEL_e093aee83c1045be8f906704bfe90462"
            ],
            "layout": "IPY_MODEL_4b8cfe7342a449e5aba98ece6939628f"
          }
        },
        "36aca0760e234959bd205d88a8840b77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_301b93cc907e4f8ab4a025dcc9efa954",
            "placeholder": "​",
            "style": "IPY_MODEL_6f06cf8d3f6447109a0688f1a6bea6c8",
            "value": "split=val:  97%"
          }
        },
        "632df7c717464a5ab5e15273bcbc9a78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec7ed9499eff4f059b81bb50d5cecca9",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6c44ff7745b249fcba0e94d8c2d6915b",
            "value": 29
          }
        },
        "e093aee83c1045be8f906704bfe90462": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_479e0b337b46491ead7183eb4f86066a",
            "placeholder": "​",
            "style": "IPY_MODEL_ff88de78de7f41d39a9f6a7e45d1e3f0",
            "value": " 29/30 [2:09:51&lt;00:00,  5.13it/s, acc=60.4, epoch=99, loss=2.56]"
          }
        },
        "4b8cfe7342a449e5aba98ece6939628f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "301b93cc907e4f8ab4a025dcc9efa954": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f06cf8d3f6447109a0688f1a6bea6c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec7ed9499eff4f059b81bb50d5cecca9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c44ff7745b249fcba0e94d8c2d6915b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "479e0b337b46491ead7183eb4f86066a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff88de78de7f41d39a9f6a7e45d1e3f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dIlwJLJAjRdD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from argparse import Namespace\n",
        "from collections import Counter\n",
        "import json\n",
        "import re\n",
        "import string\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vocabulary와 SequenceVocabulary"
      ],
      "metadata": {
        "id": "KAfe9ysEnx8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Vocabulary(object):\n",
        "  \"\"\"매핑을 위해 텍스트를 처리하고 어휘 사전을 만드는 클래스 \"\"\"\n",
        "\n",
        "  def __init__(self, token_to_idx=None):\n",
        "      \"\"\"\n",
        "      매개변수:\n",
        "          token_to_idx (dict): 기존 토큰-인덱스 매핑 딕셔너리\n",
        "      \"\"\"\n",
        "\n",
        "      if token_to_idx is None:\n",
        "          token_to_idx = {}\n",
        "      self._token_to_idx = token_to_idx\n",
        "\n",
        "      self._idx_to_token = {idx: token\n",
        "                            for token, idx in self._token_to_idx.items()}\n",
        "\n",
        "  def to_serializable(self):\n",
        "      \"\"\" 직렬화할 수 있는 딕셔너리를 반환합니다 \"\"\"\n",
        "      return {'token_to_idx': self._token_to_idx}\n",
        "\n",
        "  @classmethod\n",
        "  def from_serializable(cls, contents):\n",
        "      \"\"\" 직렬화된 딕셔너리에서 Vocabulary 객체를 만듭니다 \"\"\"\n",
        "      return cls(**contents)\n",
        "\n",
        "  def add_token(self, token):\n",
        "        \"\"\" 토큰을 기반으로 매핑 딕셔너리를 업데이트합니다\n",
        "\n",
        "        매개변수:\n",
        "            token (str): Vocabulary에 추가할 토큰\n",
        "        반환값:\n",
        "            index (int): 토큰에 상응하는 정수\n",
        "        \"\"\"\n",
        "        if token in self._token_to_idx:\n",
        "            index = self._token_to_idx[token]\n",
        "        else:\n",
        "            index = len(self._token_to_idx)\n",
        "            self._token_to_idx[token] = index\n",
        "            self._idx_to_token[index] = token\n",
        "        return index\n",
        "\n",
        "  def add_many(self, tokens):\n",
        "      \"\"\"토큰 리스트를 Vocabulary에 추가합니다.\n",
        "\n",
        "      매개변수:\n",
        "          tokens (list): 문자열 토큰 리스트\n",
        "      반환값:\n",
        "          indices (list): 토큰 리스트에 상응되는 인덱스 리스트\n",
        "      \"\"\"\n",
        "      return [self.add_token(token) for token in tokens]\n",
        "\n",
        "  def lookup_token(self, token):\n",
        "      \"\"\"토큰에 대응하는 인덱스를 추출합니다.\n",
        "\n",
        "      매개변수:\n",
        "          token (str): 찾을 토큰\n",
        "      반환값:\n",
        "          index (int): 토큰에 해당하는 인덱스\n",
        "      \"\"\"\n",
        "      return self._token_to_idx[token]\n",
        "\n",
        "  def lookup_index(self, index):\n",
        "        \"\"\" 인덱스에 해당하는 토큰을 반환합니다.\n",
        "\n",
        "        매개변수:\n",
        "            index (int): 찾을 인덱스\n",
        "        반환값:\n",
        "            token (str): 인텍스에 해당하는 토큰\n",
        "        에러:\n",
        "            KeyError: 인덱스가 Vocabulary에 없을 때 발생합니다.\n",
        "        \"\"\"\n",
        "        if index not in self._idx_to_token:\n",
        "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
        "        return self._idx_to_token[index]\n",
        "\n",
        "  def __str__(self):\n",
        "      return \"<Vocabulary(size=%d)>\" % len(self)\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self._token_to_idx)\n"
      ],
      "metadata": {
        "id": "5phhFez5mhiD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SequenceVocabulary(Vocabulary):\n",
        "  def __init__(self, token_to_idx=None, unk_token=\"<UNK>\",\n",
        "                mask_token=\"<MASK>\", begin_seq_token=\"<BEGIN>\",\n",
        "                end_seq_token=\"<END>\"):\n",
        "\n",
        "      super(SequenceVocabulary, self).__init__(token_to_idx)\n",
        "\n",
        "      self._mask_token = mask_token\n",
        "      self._unk_token = unk_token\n",
        "      self._begin_seq_token = begin_seq_token\n",
        "      self._end_seq_token = end_seq_token\n",
        "\n",
        "      self.mask_index = self.add_token(self._mask_token)\n",
        "      self.unk_index = self.add_token(self._unk_token)\n",
        "      self.begin_seq_index = self.add_token(self._begin_seq_token)\n",
        "      self.end_seq_index = self.add_token(self._end_seq_token)\n",
        "\n",
        "  def to_serializable(self):\n",
        "      contents = super(SequenceVocabulary, self).to_serializable()\n",
        "      contents.update({'unk_token': self._unk_token,\n",
        "                        'mask_token': self._mask_token,\n",
        "                        'begin_seq_token': self._begin_seq_token,\n",
        "                        'end_seq_token': self._end_seq_token})\n",
        "      return contents\n",
        "\n",
        "  def lookup_token(self, token):\n",
        "      \"\"\" 토큰에 대응하는 인덱스를 추출합니다.\n",
        "      토큰이 없으면 UNK 인덱스를 반환합니다.\n",
        "\n",
        "      매개변수:\n",
        "          token (str): 찾을 토큰\n",
        "      반환값:\n",
        "          index (int): 토큰에 해당하는 인덱스\n",
        "      노트:\n",
        "          UNK 토큰을 사용하려면 (Vocabulary에 추가하기 위해)\n",
        "          `unk_index`가 0보다 커야 합니다.\n",
        "      \"\"\"\n",
        "      if self.unk_index >= 0:\n",
        "          return self._token_to_idx.get(token, self.unk_index)\n",
        "      else:\n",
        "          return self._token_to_idx[token]"
      ],
      "metadata": {
        "id": "hOzDdfLwnJq8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vectorizer"
      ],
      "metadata": {
        "id": "Z9MbGMIin5Fx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NMTVectorizer(object):\n",
        "  def __init__(self, source_vocab, target_vocab, max_source_length, max_target_length):\n",
        "    '''\n",
        "    source_vocab : 소스 단어 정수 매핑\n",
        "    target_vocab : 타깃 단어 정수 매핑\n",
        "    max_source_length : 소스 데이터셋에서 가장 긴 시퀀스 길이\n",
        "    max_target_length : 타깃 데이터셋에서 가장 긴 시퀀스 길이\n",
        "    '''\n",
        "    self.source_vocab = source_vocab\n",
        "    self.target_vocab = target_vocab\n",
        "\n",
        "    self.source_vocab = source_vocab\n",
        "    self.max_source_length = max_source_length\n",
        "    self.max_target_length = max_target_length\n",
        "\n",
        "  def _vectorize(self, indices, vector_length=-1, mask_index=0):\n",
        "    '''\n",
        "    index를 벡터로 변환\n",
        "\n",
        "    indices : 시퀀스를 나타내는 정수 리스트\n",
        "    vector_length : 인덱스 벡터 길이\n",
        "    mask_index : 사용할 MASK 인덱스\n",
        "    '''\n",
        "\n",
        "    if vector_length < 0:             # vector_length 파라미터 전달이 안됐을 경우, indices길이로 지정\n",
        "      vector_length = len(indices)\n",
        "\n",
        "    vector = np.zeros(vector_length, dtype=np.int64)\n",
        "    vector[:len(indices)] = indices\n",
        "    vector[len(indices):] = mask_index  # MASK 인덱스로 패딩\n",
        "\n",
        "    return vector\n",
        "\n",
        "  def _get_source_indices(self, text):\n",
        "    '''\n",
        "    벡터로 변환된 소스 텍스트를 반환 (소스 텍스트의 벡터를 반환)\n",
        "    '''\n",
        "    indices = [self.source_vocab.begin_seq_index]\n",
        "    indices.extend(self.source_vocab.lookup_token(token) for token in text.split(\" \")) # token의 인덱스를 찾음\n",
        "    indices.append(self.source_vocab.end_seq_index)\n",
        "    return indices\n",
        "\n",
        "  def _get_target_indices(self, text):\n",
        "    '''\n",
        "    벡터로 변환된 타깃 텍스트를 반환\n",
        "    '''\n",
        "\n",
        "    indices = [self.target_vocab.lookup_token(token) for token in text.split(' ')]\n",
        "    x_indices = [self.target_vocab.begin_seq_index] + indices\n",
        "    y_indices = indices + [self.target_vocab.end_seq_index]\n",
        "    return x_indices, y_indices # x_indices : 디코더에서 샘플을 나타내는 정수 리스트, y_indices : 디코더에서 예측을 나타내는 정수 리스트\n",
        "\n",
        "  def vectorize(self, source_text, target_text, use_dataset_max_lengths=True):\n",
        "    '''\n",
        "    벡터화된 소스 텍스트와 타깃 텍스트 반환\n",
        "    '''\n",
        "    source_vector_length = -1\n",
        "    target_vector_length = -1\n",
        "\n",
        "    if use_dataset_max_lengths:\n",
        "      source_vector_length = self.max_source_length + 2\n",
        "      target_vector_length = self.max_target_length + 1\n",
        "\n",
        "    source_indices = self._get_source_indices(source_text)\n",
        "    source_vector = self._vectorize(source_indices,\n",
        "                                    vector_length=source_vector_length,\n",
        "                                    mask_index=self.source_vocab.mask_index)\n",
        "\n",
        "    target_x_indices, target_y_indices = self._get_target_indices(target_text)\n",
        "    target_x_vector = self._vectorize(target_x_indices,\n",
        "                                      vector_length=target_vector_length,\n",
        "                                      mask_index=self.target_vocab.mask_index)\n",
        "    target_y_vector = self._vectorize(target_y_indices,\n",
        "                                      vector_length=target_vector_length,\n",
        "                                      mask_index=self.target_vocab.mask_index)\n",
        "    return {\n",
        "        \"source_vector\":source_vector,\n",
        "        \"target_x_vector\":target_x_vector,\n",
        "        \"target_y_vector\":target_y_vector,\n",
        "        \"source_length\":len(source_indices)\n",
        "    }\n",
        "\n",
        "  @classmethod\n",
        "  def from_dataframe(cls, bitext_df):\n",
        "    '''\n",
        "    데이터셋 데이터프레임으로 Vectorizer 초기화\n",
        "    '''\n",
        "\n",
        "    source_vocab = SequenceVocabulary()\n",
        "    target_vocab = SequenceVocabulary()\n",
        "\n",
        "    max_source_length, max_target_length = 0, 0\n",
        "\n",
        "    for _, row in bitext_df.iterrows():\n",
        "      source_tokens = row[\"source_language\"].split(' ')\n",
        "      if len(source_tokens) > max_source_length:\n",
        "        max_source_length = len(source_tokens)\n",
        "      for token in source_tokens:\n",
        "        source_vocab.add_token(token)\n",
        "\n",
        "      target_tokens = row[\"target_language\"].split(' ')\n",
        "      if len(target_tokens) > max_target_length:\n",
        "        max_target_length = len(target_tokens)\n",
        "      for token in target_tokens:\n",
        "        target_vocab.add_token(token)\n",
        "\n",
        "    return cls(source_vocab, target_vocab, max_source_length, max_target_length)\n",
        "\n",
        "  @classmethod\n",
        "  def from_serializable(cls, contents):\n",
        "    source_vocab = SequenceVocabulary.from_serializable(contents[\"source_vocab\"])\n",
        "    target_vocab = SequenceVocabulary.from_serializable(contents[\"target_vocab\"])\n",
        "\n",
        "    return cls(source_vocab=source_vocab,\n",
        "                target_vocab=target_vocab,\n",
        "                max_source_length=contents[\"max_source_length\"],\n",
        "                max_target_length=contents[\"max_target_length\"])\n",
        "\n",
        "  def to_serializable(self): # vectorizer 파일 저장에 필요\n",
        "    return {\"source_vocab\": self.source_vocab.to_serializable(),\n",
        "            \"target_vocab\": self.target_vocab.to_serializable(),\n",
        "            \"max_source_length\": self.max_source_length,\n",
        "            \"max_target_length\": self.max_target_length}"
      ],
      "metadata": {
        "id": "-BYRphlMn9G0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터셋"
      ],
      "metadata": {
        "id": "EOUlMHjPkeHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NMTDataset(Dataset):\n",
        "  def __init__(self, text_df, vectorizer):\n",
        "      \"\"\"\n",
        "      매개변수:\n",
        "          text_df (pandas.DataFrame): 데이터셋\n",
        "          vectorizer (SurnameVectorizer): 데이터셋에서 만든 Vectorizer 객체\n",
        "      \"\"\"\n",
        "      self.text_df = text_df\n",
        "      self._vectorizer = vectorizer\n",
        "\n",
        "      self.train_df = self.text_df[self.text_df.split=='train']\n",
        "      self.train_size = len(self.train_df)\n",
        "\n",
        "      self.val_df = self.text_df[self.text_df.split=='val']\n",
        "      self.validation_size = len(self.val_df)\n",
        "\n",
        "      self.test_df = self.text_df[self.text_df.split=='test']\n",
        "      self.test_size = len(self.test_df)\n",
        "\n",
        "      self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
        "                            'val': (self.val_df, self.validation_size),\n",
        "                            'test': (self.test_df, self.test_size)}\n",
        "\n",
        "      self.set_split('train')\n",
        "\n",
        "  @classmethod\n",
        "  def load_dataset_and_make_vectorizer(cls, dataset_csv):\n",
        "      \"\"\"데이터셋을 로드하고 새로운 Vectorizer를 만듭니다\n",
        "\n",
        "      매개변수:\n",
        "          dataset_csv (str): 데이터셋의 위치\n",
        "      반환값:\n",
        "          NMTDataset의 객체\n",
        "      \"\"\"\n",
        "      text_df = pd.read_csv(dataset_csv)\n",
        "      train_subset = text_df[text_df.split=='train']\n",
        "      return cls(text_df, NMTVectorizer.from_dataframe(train_subset))\n",
        "\n",
        "  @classmethod\n",
        "  def load_dataset_and_load_vectorizer(cls, dataset_csv, vectorizer_filepath):\n",
        "      \"\"\"데이터셋과 새로운 Vectorizer 객체를 로드합니다.\n",
        "      캐싱된 Vectorizer 객체를 재사용할 때 사용합니다.\n",
        "\n",
        "      매개변수:\n",
        "          dataset_csv (str): 데이터셋의 위치\n",
        "          vectorizer_filepath (str): Vectorizer 객체의 저장 위치\n",
        "      반환값:\n",
        "          NMTDataset의 객체\n",
        "      \"\"\"\n",
        "      text_df = pd.read_csv(dataset_csv)\n",
        "      vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
        "      return cls(text_df, vectorizer)\n",
        "\n",
        "  @staticmethod\n",
        "  def load_vectorizer_only(vectorizer_filepath):\n",
        "      \"\"\"파일에서 Vectorizer 객체를 로드하는 정적 메서드\n",
        "\n",
        "      매개변수:\n",
        "          vectorizer_filepath (str): 직렬화된 Vectorizer 객체의 위치\n",
        "      반환값:\n",
        "          NMTVectorizer의 인스턴스\n",
        "      \"\"\"\n",
        "      with open(vectorizer_filepath) as fp:\n",
        "          return NMTVectorizer.from_serializable(json.load(fp))\n",
        "\n",
        "  def save_vectorizer(self, vectorizer_filepath):\n",
        "      \"\"\"Vectorizer 객체를 json 형태로 디스크에 저장합니다\n",
        "\n",
        "      매개변수:\n",
        "          vectorizer_filepath (str): Vectorizer 객체의 저장 위치\n",
        "      \"\"\"\n",
        "      with open(vectorizer_filepath, \"w\") as fp:\n",
        "          json.dump(self._vectorizer.to_serializable(), fp)\n",
        "\n",
        "  def get_vectorizer(self):\n",
        "      \"\"\" 벡터 변환 객체를 반환합니다 \"\"\"\n",
        "      return self._vectorizer\n",
        "\n",
        "  def set_split(self, split=\"train\"):\n",
        "      self._target_split = split\n",
        "      self._target_df, self._target_size = self._lookup_dict[split]\n",
        "\n",
        "  def __len__(self):\n",
        "      return self._target_size\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      \"\"\"파이토치 데이터셋의 주요 진입 메서드\n",
        "\n",
        "      매개변수:\n",
        "          index (int): 데이터 포인트에 대한 인덱스\n",
        "      반환값:\n",
        "          데이터 포인트(x_source, x_target, y_target, x_source_length)를 담고 있는 딕셔너리\n",
        "      \"\"\"\n",
        "      row = self._target_df.iloc[index]\n",
        "\n",
        "      vector_dict = self._vectorizer.vectorize(row.source_language, row.target_language)\n",
        "\n",
        "      return {\"x_source\": vector_dict[\"source_vector\"],\n",
        "              \"x_target\": vector_dict[\"target_x_vector\"],\n",
        "              \"y_target\": vector_dict[\"target_y_vector\"],\n",
        "              \"x_source_length\": vector_dict[\"source_length\"]}\n",
        "\n",
        "  def get_num_batches(self, batch_size):\n",
        "      \"\"\"배치 크기가 주어지면 데이터셋으로 만들 수 있는 배치 개수를 반환합니다\n",
        "\n",
        "      매개변수:\n",
        "          batch_size (int)\n",
        "      반환값:\n",
        "          배치 개수\n",
        "      \"\"\"\n",
        "      return len(self) // batch_size"
      ],
      "metadata": {
        "id": "-x5QYx_1kiGB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NMT를 위한 미니배치 생성 함수 (PackedSequence 데이터 구조를 만듦)"
      ],
      "metadata": {
        "id": "XDoEkxKXkmwr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_nmt_batches(dataset, batch_size, shuffle=True, drop_last=True, device=\"cpu\"):\n",
        "  dataloader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last)\n",
        "\n",
        "  for data_dict in dataloader:\n",
        "    lengths = data_dict['x_source_length'].numpy()           # 각 시퀀스 길이\n",
        "    sorted_length_indices = lengths.argsort()[::-1].tolist() # 시퀀스 길이 순서대로 내림차순 정렬\n",
        "\n",
        "    out_data_dict = {}\n",
        "    for name, tensor in data_dict.items():\n",
        "      out_data_dict[name] = data_dict[name][sorted_length_indices].to(device)\n",
        "    yield out_data_dict"
      ],
      "metadata": {
        "id": "4innnFn8mBJH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NMT 인코더"
      ],
      "metadata": {
        "id": "yQnHbM02pgAW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "pack_padded_sequence 함수에 대한 설명 : https://blog.naver.com/ys10mjh/222215973937\n",
        "\n",
        "텐서에 contiguous 함수를 사용하는 이유 : https://aigong.tistory.com/430\n"
      ],
      "metadata": {
        "id": "GQ4_T7ERTY3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NMTEncoder(nn.Module):\n",
        "  def __init__(self, num_embeddings, embedding_size, rnn_hidden_size):\n",
        "    '''\n",
        "    num_embeddings : 임베딩 개수(= 소스 어휘 사전 크기)\n",
        "    embedding_size : 임베딩 벡터의 크기\n",
        "    rnn_hidden_size : RNN 은닉 상태 벡터 크기\n",
        "    '''\n",
        "    super(NMTEncoder, self).__init__()\n",
        "    self.source_embedding = nn.Embedding(num_embeddings, embedding_size, padding_idx=0)\n",
        "    self.birnn = nn.GRU(embedding_size, rnn_hidden_size, bidirectional=True, batch_first=True) # 양방향 GRU\n",
        "\n",
        "  def forward(self, x_source, x_lengths):\n",
        "    '''\n",
        "    x_source : 입력 데이터 텐서, 형상은 (배치 크기, 시퀀스 크기)\n",
        "    x_lengths : 배치에 있는 아이템의 길이 벡터(텐서)\n",
        "    '''\n",
        "    x_embedded = self.source_embedding(x_source)\n",
        "    x_lengths = x_lengths.detach().cpu().numpy()\n",
        "    # PackedSequence 만듦, x_packed.data.shape : (number_items, embedding_size)\n",
        "    x_packed = pack_padded_sequence(x_embedded, x_lengths, batch_first=True)\n",
        "\n",
        "    x_birnn_out , x_birnn_h = self.birnn(x_packed)\n",
        "    # x_birnn_h 의 형상을 (num_rnn, batch_size, feature_size)에서 (batch_size, num_rnn, feature_size)로 변형함. batch_first이기 때문\n",
        "    x_birnn_h = x_birnn_h.permute(1, 0, 2)\n",
        "\n",
        "    # contiguous 함수는 메모리를 새로 할당하여 비연속적인 텐서를 연속적이게 만들어준다.\n",
        "    # view 함수를 사용하여 x_birnn_h 를 (batch_size, num_rnn * feature_size)로 바꾼다.\n",
        "    x_birnn_h = x_birnn_h.contiguous().view(x_birnn_h.size(0), -1)\n",
        "\n",
        "    x_unpacked, _ = pad_packed_sequence(x_birnn_out, batch_first=True) # PackedSequence 구조를 패딩된 구조로 바꿔줌\n",
        "\n",
        "    return x_unpacked, x_birnn_h # 이 x_birnn_h(마지막 은닉상태)를 이용하여 디코더의 은닉 상태를 초기화 한다."
      ],
      "metadata": {
        "id": "AssRpeofQBNb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NMT 디코더"
      ],
      "metadata": {
        "id": "qxRiCsAdpirQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def verbose_attention(encoder_state_vectors, query_vector):\n",
        "    \"\"\" 원소별 연산을 사용하는 어텐션 메커니즘 버전\n",
        "\n",
        "    매개변수:\n",
        "        encoder_state_vectors (torch.Tensor): 인코더의 양방향 GRU에서 출력된 3차원 텐서\n",
        "        query_vector (torch.Tensor): 디코더 GRU의 은닉 상태\n",
        "    \"\"\"\n",
        "    batch_size, num_vectors, vector_size = encoder_state_vectors.size()\n",
        "    vector_scores = torch.sum(encoder_state_vectors * query_vector.view(batch_size, 1, vector_size),\n",
        "                              dim=2)\n",
        "    vector_probabilities = F.softmax(vector_scores, dim=1)\n",
        "    weighted_vectors = encoder_state_vectors * vector_probabilities.view(batch_size, num_vectors, 1)\n",
        "    context_vectors = torch.sum(weighted_vectors, dim=1)\n",
        "    return context_vectors, vector_probabilities, vector_scores\n",
        "\n",
        "def terse_attention(encoder_state_vectors, query_vector):\n",
        "    \"\"\" 점곱을 사용하는 어텐션 메커니즘 버전\n",
        "\n",
        "    매개변수:\n",
        "        encoder_state_vectors (torch.Tensor): 인코더의 양방향 GRU에서 출력된 3차원 텐서\n",
        "        query_vector (torch.Tensor): 디코더 GRU의 은닉 상태\n",
        "    \"\"\"\n",
        "    vector_scores = torch.matmul(encoder_state_vectors, query_vector.unsqueeze(dim=2)).squeeze()\n",
        "    vector_probabilities = F.softmax(vector_scores, dim=-1)\n",
        "    context_vectors = torch.matmul(encoder_state_vectors.transpose(-2, -1),\n",
        "                                   vector_probabilities.unsqueeze(dim=2)).squeeze()\n",
        "    return context_vectors, vector_probabilities"
      ],
      "metadata": {
        "id": "bspRcGxoPRJR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NMTDecoder(nn.Module):\n",
        "  def __init__(self, num_embeddings, embedding_size, rnn_hidden_size, bos_index):\n",
        "    '''\n",
        "    num_embeddings : 임베딩 개수는 타깃 어휘 사전의 고유한 단어 개수\n",
        "    embedding_size : 임베딩 벡터 크기\n",
        "    rnn_hidden_size : RNN 은닉 상태 크기\n",
        "    bos_index : begin-of-sequence의 인덱스 넘버\n",
        "    '''\n",
        "    super(NMTDecoder, self).__init__()\n",
        "    self._rnn_hidden_size = rnn_hidden_size\n",
        "    self.target_embedding = nn.Embedding(num_embeddings=num_embeddings,\n",
        "                                         embedding_dim=embedding_size,\n",
        "                                         padding_idx=0)\n",
        "    self.gru_cell = nn.GRUCell(embedding_size + rnn_hidden_size,\n",
        "                               rnn_hidden_size)\n",
        "    self.hidden_map = nn.Linear(rnn_hidden_size, rnn_hidden_size)\n",
        "    self.classifier = nn.Linear(rnn_hidden_size * 2, num_embeddings)\n",
        "\n",
        "    self.bos_index = bos_index\n",
        "\n",
        "  def _init_indices(self, batch_size):\n",
        "    # begin-of-seqence 인덱스 벡터를 반환\n",
        "    return torch.ones(batch_size, dtype=torch.int64) * self.bos_index\n",
        "\n",
        "  def _init_context_vectors(self, batch_size):\n",
        "    # 문맥 벡터 초기화를 위한 0 벡터 반환\n",
        "    return torch.zeros(batch_size, self._rnn_hidden_size)\n",
        "\n",
        "  def forward(self, encoder_state, initial_hidden_state, target_sequence):\n",
        "    target_sequence = target_sequence.permute(1, 0)\n",
        "    h_t = self.hidden_map(initial_hidden_state)\n",
        "    batch_size = encoder_state.size(0)\n",
        "    # 문맥 벡터를 0으로 초기화\n",
        "    context_vectors = self._init_context_vectors(batch_size)\n",
        "    # 첫단어 y_t를 begin-of-sequence로 초기화\n",
        "    y_t_index = self._init_indices(batch_size)\n",
        "\n",
        "    # encoder에서 사용한 device와 일치시켜줌\n",
        "    h_t = h_t.to(encoder_state.device)\n",
        "    y_t_index = y_t_index.to(encoder_state.device)\n",
        "    context_vectors = context_vectors.to(encoder_state.device)\n",
        "\n",
        "    output_vectors = []\n",
        "    # 분석을 위해 GPU에서 캐싱된 모든 텐서를 가져와 저장\n",
        "    self._cached_p_attn = []\n",
        "    self._cached_ht = []\n",
        "    self._cached_decoder_state = encoder_state.cpu().detach().numpy()\n",
        "\n",
        "    output_sequence_size = target_sequence.size(0)\n",
        "    for i in range(output_sequence_size):\n",
        "\n",
        "      # 1 단계 : 단어를 임베딩하고 이전 문맥과 연결\n",
        "      y_input_vector = self.target_embedding(target_sequence[i])\n",
        "      rnn_input = torch.cat([y_input_vector, context_vectors], dim=1) # torch.cat : 옆으로 텐서를 나란히 붙인다\n",
        "\n",
        "      # 2단계 : GRU를 적용하고 새로운 은닉 벡터를 얻음\n",
        "      h_t = self.gru_cell(rnn_input, h_t)\n",
        "      self._cached_ht.append(h_t.cpu().data.numpy())\n",
        "\n",
        "      # 3단계 : 현재 은닉 상태를 사용해 인코더의 상태 주목 (원소별 연산을 사용하는 어텐션 메커니즘)\n",
        "      context_vectors, p_attn, _ = verbose_attention(encoder_state_vectors=encoder_state, query_vector=h_t)\n",
        "\n",
        "      # 부가 작업 : 시각화를 위한 어텐션 확률 저장\n",
        "      self._cached_p_attn.append(p_attn.cpu().detach().numpy())\n",
        "\n",
        "      # 4단계 : 현재 은닉 상태(h_t)와 문맥 벡터(context_vectors)를 사용하여 다음 단어 예측\n",
        "      prediction_vector = torch.cat((context_vectors, h_t), dim=1)\n",
        "      #score_for_y_t_index = self.classifier(prediction_vector) # 예측 성능 점수\n",
        "      score_for_y_t_index = self.classifier(F.dropout(prediction_vector, 0.3)) # 예측 성능 점수 (드롭아웃 적용)\n",
        "\n",
        "      # 부가 작업 : 예측 성능 점수 기록\n",
        "      output_vectors.append(score_for_y_t_index)\n",
        "\n",
        "    output_vectors = torch.stack(output_vectors).permute(1, 0, 2)\n",
        "\n",
        "    return output_vectors"
      ],
      "metadata": {
        "id": "Jz1FtVHMFMbb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NMT 모델"
      ],
      "metadata": {
        "id": "0YB_M_MlpYPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NMTModel(nn.Module):\n",
        "  def __init__(self, source_vocab_size, source_embedding_size, target_vocab_size, target_embedding_size, encoding_size, target_bos_index):\n",
        "    '''\n",
        "    source_vocab_size : 소스 언어에 있는 고유한 단어 개수\n",
        "    source_embedding_size : 소스 임베딩 벡터의 크기\n",
        "    target_vocab_size : 타깃 언어에 있는 고유한 단어 개수\n",
        "    target_embedding_size : 타깃 임베딩 벡터 크기\n",
        "    encoding_size : 인코더 RNN의 크기\n",
        "    target_bos_index : begin-of-sequence 토큰의 인덱스\n",
        "\n",
        "    인코더와 디코더를 초기화한다.\n",
        "    '''\n",
        "    super(NMTModel, self).__init__()\n",
        "    self.encoder = NMTEncoder(num_embeddings=source_vocab_size,\n",
        "                              embedding_size=source_embedding_size,\n",
        "                              rnn_hidden_size=encoding_size)\n",
        "    decoding_size = encoding_size * 2\n",
        "    self.decoder = NMTDecoder(num_embeddings=target_vocab_size,\n",
        "                              embedding_size=target_embedding_size,\n",
        "                              rnn_hidden_size=decoding_size,\n",
        "                              bos_index=target_bos_index)\n",
        "\n",
        "  def forward(self, x_source, x_source_lengths, target_sequence):\n",
        "    '''\n",
        "    x_source : 소스 텍스트 데이터 텐서, shape는 (batch, vectorizer.max_source_length)\n",
        "    x_source_lengths : x_source에 있는 시퀀스 길이\n",
        "    target_sequence : 타깃 텍스트 데이터 텐서\n",
        "    '''\n",
        "    encoder_state, final_hidden_states = self.encoder(x_source, x_source_lengths)\n",
        "    decoded_states = self.decoder(encoder_state=encoder_state,\n",
        "                                  initial_hidden_state=final_hidden_states,\n",
        "                                  target_sequence=target_sequence)\n",
        "    return decoded_states"
      ],
      "metadata": {
        "id": "hmcrb8gPPOUK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 훈련 헬퍼 함수"
      ],
      "metadata": {
        "id": "hY3qz6IOUHy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed_everywhere(seed, cuda):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if cuda:\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def handle_dirs(dirpath):\n",
        "    if not os.path.exists(dirpath):\n",
        "        os.makedirs(dirpath)\n",
        "\n",
        "def make_train_state(args):\n",
        "    return {'stop_early': False,\n",
        "            'early_stopping_step': 0,\n",
        "            'early_stopping_best_val': 1e8,\n",
        "            'learning_rate': args.learning_rate,\n",
        "            'epoch_index': 0,\n",
        "            'train_loss': [],\n",
        "            'train_acc': [],\n",
        "            'val_loss': [],\n",
        "            'val_acc': [],\n",
        "            'test_loss': -1,\n",
        "            'test_acc': -1,\n",
        "            'model_filename': args.model_state_file}\n",
        "\n",
        "def update_train_state(args, model, train_state):\n",
        "    \"\"\"후련 상태 업데이트합니다.\n",
        "\n",
        "    콤포넌트:\n",
        "     - 조기 종료: 과대 적합 방지\n",
        "     - 모델 체크포인트: 더 나은 모델을 저장합니다\n",
        "\n",
        "    :param args: 메인 매개변수\n",
        "    :param model: 훈련할 모델\n",
        "    :param train_state: 훈련 상태를 담은 딕셔너리\n",
        "    :returns:\n",
        "        새로운 훈련 상태\n",
        "    \"\"\"\n",
        "\n",
        "    # 적어도 한 번 모델을 저장합니다\n",
        "    if train_state['epoch_index'] == 0:\n",
        "        torch.save(model.state_dict(), train_state['model_filename'])\n",
        "        train_state['stop_early'] = False\n",
        "\n",
        "    # 성능이 향상되면 모델을 저장합니다\n",
        "    elif train_state['epoch_index'] >= 1:\n",
        "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
        "\n",
        "        # 손실이 나빠지면\n",
        "        if loss_t >= loss_tm1:\n",
        "            # 조기 종료 단계 업데이트\n",
        "            train_state['early_stopping_step'] += 1\n",
        "        # 손실이 감소하면\n",
        "        else:\n",
        "            # 최상의 모델 저장\n",
        "            if loss_t < train_state['early_stopping_best_val']:\n",
        "                torch.save(model.state_dict(), train_state['model_filename'])\n",
        "                train_state['early_stopping_best_val'] = loss_t\n",
        "\n",
        "            # 조기 종료 단계 재설정\n",
        "            train_state['early_stopping_step'] = 0\n",
        "\n",
        "        # 조기 종료 여부 확인\n",
        "        train_state['stop_early'] = \\\n",
        "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
        "\n",
        "    return train_state\n",
        "\n",
        "def normalize_sizes(y_pred, y_true):\n",
        "    \"\"\"텐서 크기 정규화\n",
        "\n",
        "    매개변수:\n",
        "        y_pred (torch.Tensor): 모델의 출력\n",
        "            3차원 텐서이면 행렬로 변환합니다.\n",
        "        y_true (torch.Tensor): 타깃 예측\n",
        "            행렬이면 벡터로 변환합니다.\n",
        "    \"\"\"\n",
        "    if len(y_pred.size()) == 3:\n",
        "        y_pred = y_pred.contiguous().view(-1, y_pred.size(2))\n",
        "    if len(y_true.size()) == 2:\n",
        "        y_true = y_true.contiguous().view(-1)\n",
        "    return y_pred, y_true\n",
        "\n",
        "def compute_accuracy(y_pred, y_true, mask_index):\n",
        "    y_pred, y_true = normalize_sizes(y_pred, y_true)\n",
        "\n",
        "    _, y_pred_indices = y_pred.max(dim=1)\n",
        "\n",
        "    correct_indices = torch.eq(y_pred_indices, y_true).float()\n",
        "    valid_indices = torch.ne(y_true, mask_index).float()\n",
        "\n",
        "    n_correct = (correct_indices * valid_indices).sum().item()\n",
        "    n_valid = valid_indices.sum().item()\n",
        "\n",
        "    return n_correct / n_valid * 100\n",
        "\n",
        "def sequence_loss(y_pred, y_true, mask_index):\n",
        "    y_pred, y_true = normalize_sizes(y_pred, y_true)\n",
        "    return F.cross_entropy(y_pred, y_true, ignore_index=mask_index)"
      ],
      "metadata": {
        "id": "zAkmJAlrUG68"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 훈련 설정"
      ],
      "metadata": {
        "id": "BJ7NlPI-Vg_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = Namespace(dataset_csv=\"data/nmt/simplest_eng_fra.csv\",\n",
        "                 vectorizer_file=\"vectorizer.json\",\n",
        "                 model_state_file=\"model.pth\",\n",
        "                 save_dir=\"model_storage/nmt_luong_no_sampling\",\n",
        "                 reload_from_files=True,\n",
        "                 expand_filepaths_to_save_dir=True,\n",
        "                 cuda=False,\n",
        "                 seed=1337,\n",
        "                 learning_rate=5e-4,\n",
        "                 batch_size=64,\n",
        "                 num_epochs=100,\n",
        "                 early_stopping_criteria=5,\n",
        "                 source_embedding_size=64,\n",
        "                 target_embedding_size=64,\n",
        "                 encoding_size=64,\n",
        "                 catch_keyboard_interrupt=True)\n",
        "\n",
        "if args.expand_filepaths_to_save_dir:\n",
        "    args.vectorizer_file = os.path.join(args.save_dir,\n",
        "                                        args.vectorizer_file)\n",
        "\n",
        "    args.model_state_file = os.path.join(args.save_dir,\n",
        "                                         args.model_state_file)\n",
        "\n",
        "    print(\"파일 경로: \")\n",
        "    print(\"\\t{}\".format(args.vectorizer_file))\n",
        "    print(\"\\t{}\".format(args.model_state_file))\n",
        "\n",
        "# CUDA 체크\n",
        "if not torch.cuda.is_available():\n",
        "    args.cuda = False\n",
        "\n",
        "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
        "\n",
        "print(\"CUDA 사용 여부: {}\".format(args.cuda))\n",
        "\n",
        "# 재현성을 위해 시드 설정\n",
        "set_seed_everywhere(args.seed, args.cuda)\n",
        "\n",
        "# 디렉토리 처리\n",
        "handle_dirs(args.save_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FcaN9jSV76P",
        "outputId": "7aa3cfa4-9d24-4fe6-d149-6777325fd35f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "파일 경로: \n",
            "\tmodel_storage/nmt_luong_no_sampling/vectorizer.json\n",
            "\tmodel_storage/nmt_luong_no_sampling/model.pth\n",
            "CUDA 사용 여부: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 만약 코랩에서 실행하는 경우 아래 코드를 실행하여 전처리된 데이터를 다운로드하세요.\n",
        "!mkdir data\n",
        "!wget https://git.io/JqQBE -O data/download.py\n",
        "!wget https://git.io/JqQB7 -O data/get-all-data.sh\n",
        "!chmod 755 data/get-all-data.sh\n",
        "%cd data\n",
        "!./get-all-data.sh\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x95NEqedWXbm",
        "outputId": "29306d21-58b5-42a5-bd90-cf530f4189a4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n",
            "--2024-02-20 08:25:41--  https://git.io/JqQBE\n",
            "Resolving git.io (git.io)... 140.82.114.22\n",
            "Connecting to git.io (git.io)|140.82.114.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://raw.githubusercontent.com/rickiepark/nlp-with-pytorch/main/chapter_8/8_5_NMT/data/download.py [following]\n",
            "--2024-02-20 08:25:41--  https://raw.githubusercontent.com/rickiepark/nlp-with-pytorch/main/chapter_8/8_5_NMT/data/download.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1572 (1.5K) [text/plain]\n",
            "Saving to: ‘data/download.py’\n",
            "\n",
            "data/download.py    100%[===================>]   1.54K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-02-20 08:25:41 (21.5 MB/s) - ‘data/download.py’ saved [1572/1572]\n",
            "\n",
            "--2024-02-20 08:25:41--  https://git.io/JqQB7\n",
            "Resolving git.io (git.io)... 140.82.114.22\n",
            "Connecting to git.io (git.io)|140.82.114.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://raw.githubusercontent.com/rickiepark/nlp-with-pytorch/main/chapter_8/8_5_NMT/data/get-all-data.sh [following]\n",
            "--2024-02-20 08:25:41--  https://raw.githubusercontent.com/rickiepark/nlp-with-pytorch/main/chapter_8/8_5_NMT/data/get-all-data.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 460 [text/plain]\n",
            "Saving to: ‘data/get-all-data.sh’\n",
            "\n",
            "data/get-all-data.s 100%[===================>]     460  --.-KB/s    in 0s      \n",
            "\n",
            "2024-02-20 08:25:41 (37.2 MB/s) - ‘data/get-all-data.sh’ saved [460/460]\n",
            "\n",
            "/content/data\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 초기화"
      ],
      "metadata": {
        "id": "o5ssLmVQXHBc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. dataset, vectorizer 준비\n",
        "\n",
        "2. 모델(classifier) 준비\n",
        "\n",
        "3. 손실함수, 옵티마이저, 스케줄러 준비\n",
        "\n",
        "4. 훈련 상태 값 초기화"
      ],
      "metadata": {
        "id": "EEwayljaWdqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        " vectorizer 파일이 저장되어 있다면 로드하고 아니라면 새로 만들어서 vectorizer 파일로 저장\n",
        "'''\n",
        "if args.reload_from_files and os.path.exists(args.vectorizer_file):\n",
        "    # 체크포인트를 로드합니다.\n",
        "    dataset = NMTDataset.load_dataset_and_load_vectorizer(args.dataset_csv,\n",
        "                                                          args.vectorizer_file)\n",
        "else:\n",
        "    # 데이터셋과 Vectorizer를 만듭니다.\n",
        "    dataset = NMTDataset.load_dataset_and_make_vectorizer(args.dataset_csv)\n",
        "    dataset.save_vectorizer(args.vectorizer_file)\n",
        "\n",
        "vectorizer = dataset.get_vectorizer()"
      ],
      "metadata": {
        "id": "eOAIIlSnXULG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NMTModel(source_vocab_size=len(vectorizer.source_vocab),\n",
        "                 source_embedding_size=args.source_embedding_size,\n",
        "                 target_vocab_size=len(vectorizer.target_vocab),\n",
        "                 target_embedding_size=args.target_embedding_size,\n",
        "                 encoding_size=args.encoding_size,\n",
        "                 target_bos_index=vectorizer.target_vocab.begin_seq_index)\n",
        "\n",
        "if args.reload_from_files and os.path.exists(args.model_state_file):\n",
        "    model.load_state_dict(torch.load(args.model_state_file))\n",
        "    print(\"로드한 모델\")\n",
        "else:\n",
        "    print(\"새로운 모델\")\n",
        "\n",
        "\n",
        "model = model.to(args.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jfYgmmLXZGW",
        "outputId": "e0063074-ef37-41b5-8288-eb2878b1a1c9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "새로운 모델\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_b5G8BKhdN9",
        "outputId": "8e778872-27dc-4c6a-e2e7-ab413c35188c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NMTModel(\n",
              "  (encoder): NMTEncoder(\n",
              "    (source_embedding): Embedding(3025, 64, padding_idx=0)\n",
              "    (birnn): GRU(64, 64, batch_first=True, bidirectional=True)\n",
              "  )\n",
              "  (decoder): NMTDecoder(\n",
              "    (target_embedding): Embedding(4911, 64, padding_idx=0)\n",
              "    (gru_cell): GRUCell(192, 128)\n",
              "    (hidden_map): Linear(in_features=128, out_features=128, bias=True)\n",
              "    (classifier): Linear(in_features=256, out_features=4911, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
        "                                           mode='min', factor=0.5,\n",
        "                                           patience=1)"
      ],
      "metadata": {
        "id": "zEdmogvUXlje"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_index = vectorizer.target_vocab.mask_index\n",
        "train_state = make_train_state(args)"
      ],
      "metadata": {
        "id": "tIxGUsNFX2YI"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 훈련"
      ],
      "metadata": {
        "id": "l32Ku_oEX3Xe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_bar = tqdm.notebook.tqdm(desc='training routine',\n",
        "                               total=args.num_epochs,\n",
        "                               position=0)\n",
        "\n",
        "dataset.set_split('train')\n",
        "train_bar = tqdm.notebook.tqdm(desc='split=train',\n",
        "                               total=dataset.get_num_batches(args.batch_size),\n",
        "                               position=1,\n",
        "                               leave=True)\n",
        "dataset.set_split('val')\n",
        "val_bar = tqdm.notebook.tqdm(desc='split=val',\n",
        "                             total=dataset.get_num_batches(args.batch_size),\n",
        "                             position=1,\n",
        "                             leave=True)\n",
        "\n",
        "try:\n",
        "    for epoch_index in range(args.num_epochs):\n",
        "        train_state['epoch_index'] = epoch_index\n",
        "\n",
        "        # 훈련 세트에 대한 순회\n",
        "\n",
        "        # 훈련 세트와 배치 제너레이터 준비, 손실과 정확도를 0으로 설정\n",
        "        dataset.set_split('train')\n",
        "        batch_generator = generate_nmt_batches(dataset,\n",
        "                                               batch_size=args.batch_size,\n",
        "                                               device=args.device)\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "        model.train()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            # 훈련 과정은 5단계로 이루어집니다\n",
        "\n",
        "            # --------------------------------------\n",
        "            # 단계 1. 그레이디언트를 0으로 초기화합니다\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # 단계 2. 출력을 계산합니다\n",
        "            y_pred = model(batch_dict['x_source'],\n",
        "                           batch_dict['x_source_length'],\n",
        "                           batch_dict['x_target'])\n",
        "\n",
        "            # 단계 3. 손실을 계산합니다\n",
        "            loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n",
        "\n",
        "            # 단계 4. 손실을 사용해 그레이디언트를 계산합니다\n",
        "            loss.backward()\n",
        "\n",
        "            # 단계 5. 옵티마이저로 가중치를 업데이트합니다\n",
        "            optimizer.step()\n",
        "            # -----------------------------------------\n",
        "\n",
        "            # 이동 손실과 이동 정확도를 계산합니다\n",
        "            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
        "\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "            # 진행 상태 막대 업데이트\n",
        "            train_bar.set_postfix(loss=running_loss, acc=running_acc,\n",
        "                            epoch=epoch_index)\n",
        "            train_bar.update()\n",
        "\n",
        "        train_state['train_loss'].append(running_loss)\n",
        "        train_state['train_acc'].append(running_acc)\n",
        "\n",
        "        # 검증 세트에 대한 순회\n",
        "\n",
        "        # 검증 세트와 배치 제너레이터 준비, 손실과 정확도를 0으로 설정\n",
        "        dataset.set_split('val')\n",
        "        batch_generator = generate_nmt_batches(dataset,\n",
        "                                               batch_size=args.batch_size,\n",
        "                                               device=args.device)\n",
        "        running_loss = 0.\n",
        "        running_acc = 0.\n",
        "        model.eval()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            # 단계 1. 출력을 계산합니다\n",
        "            y_pred = model(batch_dict['x_source'],\n",
        "                           batch_dict['x_source_length'],\n",
        "                           batch_dict['x_target'])\n",
        "\n",
        "            # 단계 2. 손실을 계산합니다\n",
        "            loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n",
        "\n",
        "            # 단계 3. 이동 손실과 이동 정확도를 계산합니다\n",
        "            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "            # 진행 상태 막대 업데이트\n",
        "            val_bar.set_postfix(loss=running_loss, acc=running_acc,\n",
        "                            epoch=epoch_index)\n",
        "            val_bar.update()\n",
        "\n",
        "        train_state['val_loss'].append(running_loss)\n",
        "        train_state['val_acc'].append(running_acc)\n",
        "\n",
        "        train_state = update_train_state(args=args, model=model,\n",
        "                                         train_state=train_state)\n",
        "\n",
        "        scheduler.step(train_state['val_loss'][-1])\n",
        "\n",
        "        if train_state['stop_early']:\n",
        "            break\n",
        "\n",
        "        train_bar.n = 0\n",
        "        val_bar.n = 0\n",
        "        epoch_bar.set_postfix(best_val=train_state['early_stopping_best_val'] )\n",
        "        epoch_bar.update()\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"반복 중지\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "accaec71aa044b1c86d9cf9817552f1d",
            "17095cb063a246b78bd5f4db6a3bc9a6",
            "284121f6b6d145e981e553486e54e042",
            "3c3575e80b054588b24b938a81fa9d64",
            "0cbf5c0798e84516b1f0b239e0b3c6ce",
            "ee764be16d714d479f2330196c88c627",
            "e2db0da360cc4091913d7a467a6b8e93",
            "3172fae225f64083819d7ca2e0a09821",
            "fd3e730e048c47369873c2121647c7fe",
            "07104ce38fdc418898b75d9d76e39fbf",
            "3503ded6ec7f4ffb92438dcc47f1c790",
            "b638e5e48db2487ea5fb242e70fbc32f",
            "4a2d724a61c04a5d9f56b06e35616780",
            "ea6436d8dbc54875809c7c989d4bb7c6",
            "7997b911467d4067bacc4a4e27504a1e",
            "ff8a5a426fcc4a2eb8a6b7dff86afb87",
            "1d205549f0674287a149178469edcfbe",
            "cfc9c442a72d47ccbeee9e4d120fc1e9",
            "6b285b49943440419b149af8e24240b2",
            "f21550ff33824a02b1d497facf7c2ffa",
            "c1f44b7057194cda9c82ea810f02c14f",
            "738ceeb0448943e7948a7849ef46c82e",
            "66412d18c4954268854bff2cf534d1df",
            "36aca0760e234959bd205d88a8840b77",
            "632df7c717464a5ab5e15273bcbc9a78",
            "e093aee83c1045be8f906704bfe90462",
            "4b8cfe7342a449e5aba98ece6939628f",
            "301b93cc907e4f8ab4a025dcc9efa954",
            "6f06cf8d3f6447109a0688f1a6bea6c8",
            "ec7ed9499eff4f059b81bb50d5cecca9",
            "6c44ff7745b249fcba0e94d8c2d6915b",
            "479e0b337b46491ead7183eb4f86066a",
            "ff88de78de7f41d39a9f6a7e45d1e3f0"
          ]
        },
        "id": "FaBm8hLFXvx3",
        "outputId": "3ff50b06-5d87-4f41-f074-f59b93e48167"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "training routine:   0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "accaec71aa044b1c86d9cf9817552f1d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "split=train:   0%|          | 0/142 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b638e5e48db2487ea5fb242e70fbc32f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "split=val:   0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66412d18c4954268854bff2cf534d1df"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_source_sentence(vectorizer, batch_dict, index):\n",
        "    indices = batch_dict['x_source'][index].cpu().data.numpy()\n",
        "    vocab = vectorizer.source_vocab\n",
        "    return sentence_from_indices(indices, vocab)\n",
        "\n",
        "def get_true_sentence(vectorizer, batch_dict, index):\n",
        "    return sentence_from_indices(batch_dict['y_target'].cpu().data.numpy()[index], vectorizer.target_vocab)\n",
        "\n",
        "def get_sampled_sentence(vectorizer, batch_dict, index):\n",
        "    y_pred = model(x_source=batch_dict['x_source'],\n",
        "                   x_source_lengths=batch_dict['x_source_length'],\n",
        "                   target_sequence=batch_dict['x_target'])\n",
        "    return sentence_from_indices(torch.max(y_pred, dim=2)[1].cpu().data.numpy()[index], vectorizer.target_vocab)\n",
        "\n",
        "def get_all_sentences(vectorizer, batch_dict, index):\n",
        "    return {\"source\": get_source_sentence(vectorizer, batch_dict, index),\n",
        "            \"truth\": get_true_sentence(vectorizer, batch_dict, index),\n",
        "            \"sampled\": get_sampled_sentence(vectorizer, batch_dict, index)}\n",
        "\n",
        "def sentence_from_indices(indices, vocab, strict=True):\n",
        "    ignore_indices = set([vocab.mask_index, vocab.begin_seq_index, vocab.end_seq_index])\n",
        "    out = []\n",
        "    for index in indices:\n",
        "        if index == vocab.begin_seq_index and strict:\n",
        "            continue\n",
        "        elif index == vocab.end_seq_index and strict:\n",
        "            return \" \".join(out)\n",
        "        else:\n",
        "            out.append(vocab.lookup_index(index))\n",
        "    return \" \".join(out)\n",
        "\n",
        "results = get_all_sentences(vectorizer, batch_dict, 1)\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VH0jjqjwG712",
        "outputId": "a9123d91-5c14-418e-e000-ea7dd55a8623"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'source': \"i am a man who ca n't stand being alone .\",\n",
              " 'truth': \"je suis un homme qui ne <UNK> pas d'être seul .\",\n",
              " 'sampled': 'je suis vraiment peu tellement ne me pas un là à'}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}