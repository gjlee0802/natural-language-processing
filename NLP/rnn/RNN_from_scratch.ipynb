{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uTXfxUwKPc-K"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dataset import ptb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "기본적인 RNN 계층 구현"
      ],
      "metadata": {
        "id": "EGe07-W0fan5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN:\n",
        "  def __init__(self, Wx, Wh, b):\n",
        "    self.params = [Wx, Wh, b]\n",
        "    self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
        "    self.cache = None\n",
        "\n",
        "  # RNN의 순전파 계산\n",
        "  def forward(self, x, h_prev):\n",
        "    Wx, Wh, b = self.params\n",
        "\n",
        "    t = np.matmul(h_prev, Wh) + np.matmul(x, Wx) + b\n",
        "    h_next = np.tanh(t)\n",
        "\n",
        "    self.cache = (x, h_prev, h_next)\n",
        "    return h_next\n",
        "\n",
        "  # RNN의 역전파 계산\n",
        "  def backward(self, dh_next):\n",
        "    Wx, Wh, b = self.params\n",
        "    x, h_prev, h_next = self.cache\n",
        "\n",
        "    dt = dh_next * (1 - h_next ** 2)\n",
        "    db = np.sum(dt, axis=0)\n",
        "    dWh = np.matmul(h_prev.T, dt)\n",
        "    dh_prev = np.matmul(dt, Wh.T)\n",
        "    dWx = np.matmul(x.T, dt)\n",
        "    dx = np.matmul(dt, Wx.T)\n",
        "\n",
        "    self.grads[0][...] = dWx\n",
        "    self.grads[1][...] = dWh\n",
        "    self.grads[2][...] = db\n",
        "\n",
        "    return dx, dh_prev"
      ],
      "metadata": {
        "id": "BT30o3ISPjiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "앞서 구현한 RNN 계층들을 모아서 처리하는 Time RNN을 구현해본다. Time RNN 계층은 RNN 계층 T개를 연결한 신경망이다."
      ],
      "metadata": {
        "id": "pYNFFP__pijp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeRNN:\n",
        "  def __init__(self, Wx, Wh, b, stateful=False):\n",
        "    self.params = [Wx, Wh, b]\n",
        "    self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)] # 저장할 미분값들을 0으로 초기화\n",
        "    self.layers = None                                                    # 다수의 RNN 계층을 리스트로 저장하는 용도\n",
        "\n",
        "    self.h, self.dh = None, None\n",
        "    self.stateful = stateful\n",
        "\n",
        "  def set_state(self, h):\n",
        "    self.h = h\n",
        "\n",
        "  def reset_state(self):\n",
        "    self.h = None\n",
        "\n",
        "  # Time RNN 순전파 계산\n",
        "  def forward(self, xs):\n",
        "    Wx, Wh, b = self.params\n",
        "    N, T, D = xs.shape      # N:미니배치 크기, T:시계열 데이터의 분량, D:입력벡터의 차원 수\n",
        "    D, H = Wx.shape         # D:입력벡터의 차원 수, H:은닉 벡터의 차원 수\n",
        "\n",
        "    self.layers = []\n",
        "    hs = np.empty((N, T, H), dtype='f')     # 출력값을 담을 float형 그릇, N:미니배치 크기, T:시계열 데이터의 분량, H:은닉 벡터의 차원 수\n",
        "\n",
        "    if not self.stateful or self.h is None: # 처음 호출 시에 RNN계층의 은닉상태 h를 0행렬로 초기화\n",
        "      self.h = np.zeros((N, H), dtype='f')\n",
        "\n",
        "    for t in range(T):\n",
        "      layer = RNN(*self.params)                   # 앞서 구현했던 RNN 계층을 이용\n",
        "      self.h = layer.forward(xs[:, t, :], self.h) # t번째 입력에 대해서 RNN 계층 순전파 수행\n",
        "      hs[:, t, :] = self.h                        # 각 시각 t의 출력(은닉 상태)을 저장\n",
        "      self.layers.append(layer)                   # 생성하여 사용된 RNN 계층을 laysers 리스트에 추가하여 저장\n",
        "\n",
        "    return hs\n",
        "\n",
        "  # Time RNN 역전파\n",
        "  def backward(self, dhs):\n",
        "    Wx, Wh, b = self.params\n",
        "    N, T, H = dhs.shape     # N:미니배치 크기, T:시계열 데이터의 분량, H:은닉 벡터의 차원 수\n",
        "    D, H = Wx.shape         # D:입력벡터의 차원 수, H:은닉 벡터의 차원 수\n",
        "\n",
        "    dxs = np.empty((N, T, D), dtype='f')  # 역전파 입력\n",
        "    dh = 0                                # 역전파를 거치며 합산된 기울기\n",
        "    grads = [0, 0, 0]                     # 미분값 초기화\n",
        "\n",
        "    for t in reversed(range(T)): # 역순서의 인덱스로 순회\n",
        "      layer = self.layers[t]                    # RNN 계층을 역으로 순회\n",
        "      dx, dh = layer.backward(dhs[:, t, :] + dh) # 역전파 수행 (순전파에서 분기되었으므로 역전파에서는 기울기를 합산, 분기의 반대는 합산이다!)\n",
        "      dxs[:, t, :] = dx                          # 각 시각 t에서 얻은 x 기울기를 저장\n",
        "\n",
        "      # t를 순회할 때마다 역전파로 얻은 가중치를 위 로컬변수로 초기화 한 grads에 합산\n",
        "      for i, grad in enumerate(layer.grads):\n",
        "        grads[i] += grad\n",
        "\n",
        "    # 합산된 가중치 기울기의 최종 결과를 멤버변수 self.grads에 덮어씀\n",
        "    for i, grad in enumerate(grads):\n",
        "      self.grads[i][...] = grad\n",
        "    self.dh = dh\n",
        "\n",
        "    return dxs"
      ],
      "metadata": {
        "id": "Fzy32XPpfZae"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNN을 사용하여 언어 모델 'RNNLM'을 구현해본다.\n",
        "이때 Embedding 층을 한꺼번에 처리하는 Time Embedding 층과, Affine 층을 한꺼번에 처리하는 Time Affine 층이 필요하다."
      ],
      "metadata": {
        "id": "KhAHEqGrtnIT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RRNLM 구현에 필요한 Time Embedding 층을 구현한다."
      ],
      "metadata": {
        "id": "bkrPzuLcvrf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Embedding:\n",
        "    def __init__(self, W):\n",
        "        self.params = [W]\n",
        "        self.grads = [np.zeros_like(W)]\n",
        "        self.idx = None\n",
        "\n",
        "    def forward(self, idx):\n",
        "        W, = self.params\n",
        "        self.idx = idx\n",
        "        out = W[idx]\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dW, = self.grads\n",
        "        dW[...] = 0\n",
        "        np.add.at(dW, self.idx, dout)\n",
        "        return None\n",
        "\n",
        "class TimeEmbedding:\n",
        "  def __init__(self, W):\n",
        "    self.params = [W]\n",
        "    self.grads = [np.zeros_like(W)]\n",
        "    self.layers = None\n",
        "    self.W = W\n",
        "\n",
        "  def forward(self, xs):\n",
        "    N, T = xs.shape\n",
        "    V, D = self.W.shape\n",
        "\n",
        "    out = np.empty((N, T, D), dtype='f')\n",
        "    self.layers = []\n",
        "\n",
        "    for t in range(T):\n",
        "      layer = Embedding(self.W)\n",
        "      out[:, t, :] = layer.forward(xs[:, t])\n",
        "      self.layers.append(layer)\n",
        "\n",
        "    return out\n",
        "\n",
        "  def backward(self, dout):\n",
        "    N, T, D = dout.shape\n",
        "\n",
        "    grad = 0\n",
        "    for t in range(T):\n",
        "      layer = self.layers[t]\n",
        "      layer.backward(dout[:, t, :])\n",
        "      grad += layer.grads[0]\n",
        "\n",
        "    self.grads[0][...] = grad\n",
        "    return None\n",
        ""
      ],
      "metadata": {
        "id": "k-bpdWuOt19Z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNNLM 구현에 필요한 Time Affine 층을 구현한다.\n",
        "Affine 계층은 어파인 변환(순전파 때 행렬의 곱을 계산)을 수행하는 계층이다.\n",
        "\n",
        "[유튜브-한경훈] https://www.youtube.com/watch?v=QIi8-4uea7M\n",
        "\n",
        "[활성화 함수, Affine, Softmax 계층] https://deep-learning-study.tistory.com/18\n",
        "\n",
        "[Affine, softmax, backprop] https://m.blog.naver.com/fbfbf1/222424511374"
      ],
      "metadata": {
        "id": "wQbPWZzCwC84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Affine:\n",
        "    def __init__(self, W, b):\n",
        "        self.params = [W, b]\n",
        "        self.grads = [np.zeros_like(W), np.zeros_like(b)]\n",
        "        self.x = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        W, b = self.params\n",
        "        out = np.dot(x, W) + b\n",
        "        self.x = x\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        W, b = self.params\n",
        "        dx = np.dot(dout, W.T)\n",
        "        dW = np.dot(self.x.T, dout)\n",
        "        db = np.sum(dout, axis=0)\n",
        "\n",
        "        self.grads[0][...] = dW\n",
        "        self.grads[1][...] = db\n",
        "        return dx\n",
        "\n",
        "class TimeAffine:\n",
        "  def __init__(self, W, b):\n",
        "    self.params = [W, b]\n",
        "    self.grads = [np.zeros_like(W), np.zeros_like(b)] # 가중치와 편향의 기울기를 저장\n",
        "    self.x = None\n",
        "\n",
        "  def forward(self, x):\n",
        "    N, T, D = x.shape\n",
        "    W, b = self.params\n",
        "\n",
        "    rx = x.reshape(N*T, -1)\n",
        "    out = np.dot(rx, W) + b\n",
        "    self.x = x\n",
        "    return out.reshape(N, T, -1)\n",
        "\n",
        "  def backward(self, dout):\n",
        "    x = self.x\n",
        "    N, T, D = x.shape\n",
        "    W, b = self.params\n",
        "\n",
        "    dout = dout.reshape(N*T, -1)\n",
        "    rx = x.reshape(N*T, -1)\n",
        "\n",
        "    db = np.sum(dout, axis=0)\n",
        "    dW = np.dot(rx.T, dout)\n",
        "    dx = np.dot(dout, W.T)\n",
        "    dx = dx.reshape(*x.shape)\n",
        "\n",
        "    self.grads[0][...] = dW\n",
        "    self.grads[1][...] = db\n",
        "\n",
        "    return dx"
      ],
      "metadata": {
        "id": "lde7dakAwJUP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Softmax 계층을 구현할 때에는 손실 오차를 구하는 Cross Entropy Error 계층을 함께 구현한다. 여기에서는 모든 산출된 손실을 합산하여 평균한 값을 최종 손실로 산출한다."
      ],
      "metadata": {
        "id": "6EOYyk6ywifd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeSoftmaxWithLoss:\n",
        "  def __init__(self):\n",
        "    self.params, self.grads = [], []\n",
        "    self.cache = None\n",
        "    self.ignore_label = -1\n",
        "\n",
        "\n",
        "  def softmax(self, x):\n",
        "    if x.ndim == 2:\n",
        "        x = x - x.max(axis=1, keepdims=True)\n",
        "        x = np.exp(x)\n",
        "        x /= x.sum(axis=1, keepdims=True)\n",
        "    elif x.ndim == 1:\n",
        "        x = x - np.max(x)\n",
        "        x = np.exp(x) / np.sum(np.exp(x))\n",
        "\n",
        "    return x\n",
        "\n",
        "  def forward(self, xs, ts): # xs : 전달받는 점수(확률로 정규화되기 전의 값), ts 정답 레이블\n",
        "    N, T, V = xs.shape\n",
        "\n",
        "    if ts.ndim == 3: # 정답 레이블이 원핫 벡터인 경우\n",
        "      ts = ts.argmax(axis=2)\n",
        "\n",
        "    mask = (ts != self.ignore_label)\n",
        "\n",
        "    # 배치용과 시계열용을 정리(reshape)\n",
        "    xs = xs.reshape(N * T, V)\n",
        "    ts = ts.reshape(N * T)\n",
        "    mask = mask.reshape(N * T)\n",
        "\n",
        "    ys = self.softmax(xs)\n",
        "    ls = np.log(ys[np.arange(N * T), ts])\n",
        "    ls *= mask                # ignore_label에 해당하는 데이터는 손실을 0으로 설정\n",
        "    loss = -np.sum(ls)\n",
        "    loss /= mask.sum()        # loss 값들을 합산하고 평균을 낸다\n",
        "\n",
        "    self.cache = (ts, ys, mask, (N, T, V))\n",
        "    return loss\n",
        "\n",
        "  def backward(self, dout=1):\n",
        "    ts, ys, mask, (N, T, V) = self.cache\n",
        "\n",
        "    dx = ys\n",
        "    dx[np.arange(N * T), ts] -= 1\n",
        "    dx *= dout\n",
        "    dx /= mask.sum()\n",
        "    dx *= mask[:, np.newaxis]  # ignore_label에 해당하는 데이터는 기울기를 0으로 설정\n",
        "\n",
        "    dx = dx.reshape((N, T, V))\n",
        "\n",
        "    return dx\n"
      ],
      "metadata": {
        "id": "CZJ6xltbxCmT"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNNLM 구현"
      ],
      "metadata": {
        "id": "XW0WQPAI0Ykd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.append('..')\n",
        "\n",
        "class SimpleRnnlm:\n",
        "  def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
        "    V, D, H = vocab_size, wordvec_size, hidden_size\n",
        "    rn = np.random.randn\n",
        "\n",
        "    # 가중치 초기화\n",
        "    embed_W = (rn(V, D) / 100).astype('f')\n",
        "    rnn_Wx = (rn(D, H) / np.sqrt(D)).astype('f')    # Xavier 초기값\n",
        "    rnn_Wh = (rn(H, H) / np.sqrt(H)).astype('f')    # Xavier 초기값\n",
        "\n",
        "    rnn_b = np.zeros(H).astype('f')\n",
        "    affine_W = (rn(H, V) / np.sqrt(H)).astype('f')  # Xavier 초기값\n",
        "    affine_b = np.zeros(V).astype('f')\n",
        "\n",
        "    # 계층 생성\n",
        "    self.layers = [\n",
        "        TimeEmbedding(embed_W),\n",
        "        TimeRNN(rnn_Wx, rnn_Wh, rnn_b, stateful=True),\n",
        "        TimeAffine(affine_W, affine_b)\n",
        "    ]\n",
        "    self.loss_layer = TimeSoftmaxWithLoss()\n",
        "    self.rnn_layer = self.layers[1]\n",
        "\n",
        "    # 모든 가중치와 기울기를 리스트에 모은다.\n",
        "    self.params, self.grads = [], []\n",
        "    for layer in self.layers:\n",
        "      self.params += layer.params\n",
        "      self.grads += layer.grads\n",
        "\n",
        "  def forward(self, xs, ts):\n",
        "    for layer in self.layers:\n",
        "      xs = layer.forward(xs)\n",
        "\n",
        "    loss = self.loss_layer.forward(xs, ts)\n",
        "    return loss\n",
        "\n",
        "  def backward(self, dout=1):\n",
        "    dout = self.loss_layer.backward(dout)\n",
        "    for layer in reversed(self.layers):\n",
        "      dout = layer.backward(dout)\n",
        "    return dout\n",
        "\n",
        "  def reset_state(self):\n",
        "    self.rnn_layer.reset_state()"
      ],
      "metadata": {
        "id": "xkmd5ySh3Co4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNNLM을 활용한 학습코드"
      ],
      "metadata": {
        "id": "TAJWjAhUB--U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용할 옵티마이저는 아래 SGD(Stochastic Gradient Descent)\n",
        "class SGD:\n",
        "    '''\n",
        "    확률적 경사하강법(Stochastic Gradient Descent)\n",
        "    '''\n",
        "    def __init__(self, lr=0.01):\n",
        "        self.lr = lr\n",
        "\n",
        "    def update(self, params, grads):\n",
        "        for i in range(len(params)):\n",
        "            params[i] -= self.lr * grads[i]"
      ],
      "metadata": {
        "id": "jrJDDRaJCB2T"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('.')\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "batch_size = 10     # 배치 크기\n",
        "wordvec_size = 100  # 단어벡터 개수 (단어 사전 내 단어 수)\n",
        "hidden_size = 100   # 은닉 상태 벡터의 원소 수\n",
        "time_size = 5       # Truncated BPTT가 한 번에 펼치는 시간 크기\n",
        "lr = 0.1\n",
        "max_epoch = 100\n",
        "\n",
        "# 학습 데이터 읽기(전체 중 1000개만)\n",
        "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
        "corpus_size = 1000  # 가져올 단어 수\n",
        "corpus = corpus[:corpus_size]\n",
        "vocab_size = int(max(corpus) + 1)\n",
        "\n",
        "xs = corpus[:-1]\n",
        "ts = corpus[1:]\n",
        "data_size = len(xs)\n",
        "print('corpus size : %d, vocabulary size : %d' % (corpus_size, vocab_size))\n",
        "\n",
        "# 학습 시 사용하는 변수\n",
        "max_iters = data_size // (batch_size * time_size)\n",
        "time_idx = 0\n",
        "total_loss = 0\n",
        "loss_count = 0\n",
        "ppl_list = []\n",
        "\n",
        "# 모델 생성\n",
        "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
        "\n",
        "# 사용할 옵티마이저 생성\n",
        "optimizer = SGD(lr)\n",
        "\n",
        "# 각 미니배치에서 샘플을 읽기 시작하는 위치를 계산하여 offsets에 저장\n",
        "jump = (corpus_size - 1) // batch_size\n",
        "offsets = [i * jump for i in range(batch_size)]\n",
        "\n",
        "for epoch in range(max_epoch):\n",
        "  for iter in range(max_iters):\n",
        "    # 미니배치 획득\n",
        "    batch_x = np.empty((batch_size, time_size), dtype='i')\n",
        "    batch_t = np.empty((batch_size, time_size), dtype='i')\n",
        "    for t in range(time_size):\n",
        "      for i, offset in enumerate(offsets):\n",
        "        batch_x[i, t] = xs[(offset + time_idx) % data_size]\n",
        "        batch_t[i, t] = ts[(offset + time_idx) % data_size]\n",
        "      time_idx += 1\n",
        "\n",
        "    # 기울기를 구하여 매개변수 갱신\n",
        "    # 순전파 수행하여 손실 산출\n",
        "    loss = model.forward(batch_x, batch_t)\n",
        "    # 역전파 수행하여 기울기 계산\n",
        "    model.backward()\n",
        "    # 모델의 가중치 업데이트\n",
        "    optimizer.update(model.params, model.grads)\n",
        "\n",
        "    total_loss += loss\n",
        "    loss_count += 1\n",
        "\n",
        "  # 에폭마다 퍼플렉서티(혼란도, 분기 수) 평가\n",
        "  ppl = np.exp(total_loss / loss_count) # perplexity 계산\n",
        "  print('| epoch %d | 퍼플렉서티 %.2f' % (epoch+1, ppl))\n",
        "  ppl_list.append(float(ppl))\n",
        "  total_loss, loss_count = 0, 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mX-cBVoiE7xO",
        "outputId": "3faef1a3-84ca-41f6-ae08-602bf5d9cd32"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "corpus size : 1000, vocabulary size : 418\n",
            "| epoch 1 | 퍼플렉서티 390.96\n",
            "| epoch 2 | 퍼플렉서티 258.24\n",
            "| epoch 3 | 퍼플렉서티 222.80\n",
            "| epoch 4 | 퍼플렉서티 215.58\n",
            "| epoch 5 | 퍼플렉서티 207.39\n",
            "| epoch 6 | 퍼플렉서티 202.99\n",
            "| epoch 7 | 퍼플렉서티 198.83\n",
            "| epoch 8 | 퍼플렉서티 196.46\n",
            "| epoch 9 | 퍼플렉서티 192.23\n",
            "| epoch 10 | 퍼플렉서티 193.86\n",
            "| epoch 11 | 퍼플렉서티 189.56\n",
            "| epoch 12 | 퍼플렉서티 191.67\n",
            "| epoch 13 | 퍼플렉서티 190.61\n",
            "| epoch 14 | 퍼플렉서티 190.78\n",
            "| epoch 15 | 퍼플렉서티 189.04\n",
            "| epoch 16 | 퍼플렉서티 186.44\n",
            "| epoch 17 | 퍼플렉서티 183.53\n",
            "| epoch 18 | 퍼플렉서티 180.56\n",
            "| epoch 19 | 퍼플렉서티 181.38\n",
            "| epoch 20 | 퍼플렉서티 183.29\n",
            "| epoch 21 | 퍼플렉서티 180.16\n",
            "| epoch 22 | 퍼플렉서티 175.68\n",
            "| epoch 23 | 퍼플렉서티 173.65\n",
            "| epoch 24 | 퍼플렉서티 175.23\n",
            "| epoch 25 | 퍼플렉서티 174.26\n",
            "| epoch 26 | 퍼플렉서티 172.78\n",
            "| epoch 27 | 퍼플렉서티 166.49\n",
            "| epoch 28 | 퍼플렉서티 164.87\n",
            "| epoch 29 | 퍼플렉서티 162.20\n",
            "| epoch 30 | 퍼플렉서티 158.14\n",
            "| epoch 31 | 퍼플렉서티 158.44\n",
            "| epoch 32 | 퍼플렉서티 152.36\n",
            "| epoch 33 | 퍼플렉서티 155.60\n",
            "| epoch 34 | 퍼플렉서티 150.08\n",
            "| epoch 35 | 퍼플렉서티 146.38\n",
            "| epoch 36 | 퍼플렉서티 139.77\n",
            "| epoch 37 | 퍼플렉서티 137.00\n",
            "| epoch 38 | 퍼플렉서티 133.88\n",
            "| epoch 39 | 퍼플렉서티 127.29\n",
            "| epoch 40 | 퍼플렉서티 123.99\n",
            "| epoch 41 | 퍼플렉서티 121.37\n",
            "| epoch 42 | 퍼플렉서티 118.03\n",
            "| epoch 43 | 퍼플렉서티 112.50\n",
            "| epoch 44 | 퍼플렉서티 106.87\n",
            "| epoch 45 | 퍼플렉서티 102.61\n",
            "| epoch 46 | 퍼플렉서티 99.16\n",
            "| epoch 47 | 퍼플렉서티 94.95\n",
            "| epoch 48 | 퍼플렉서티 89.82\n",
            "| epoch 49 | 퍼플렉서티 86.84\n",
            "| epoch 50 | 퍼플렉서티 81.81\n",
            "| epoch 51 | 퍼플렉서티 78.07\n",
            "| epoch 52 | 퍼플렉서티 74.97\n",
            "| epoch 53 | 퍼플렉서티 70.60\n",
            "| epoch 54 | 퍼플렉서티 68.65\n",
            "| epoch 55 | 퍼플렉서티 64.17\n",
            "| epoch 56 | 퍼플렉서티 60.44\n",
            "| epoch 57 | 퍼플렉서티 57.93\n",
            "| epoch 58 | 퍼플렉서티 54.00\n",
            "| epoch 59 | 퍼플렉서티 50.58\n",
            "| epoch 60 | 퍼플렉서티 48.20\n",
            "| epoch 61 | 퍼플렉서티 47.18\n",
            "| epoch 62 | 퍼플렉서티 43.01\n",
            "| epoch 63 | 퍼플렉서티 40.11\n",
            "| epoch 64 | 퍼플렉서티 38.92\n",
            "| epoch 65 | 퍼플렉서티 36.47\n",
            "| epoch 66 | 퍼플렉서티 35.08\n",
            "| epoch 67 | 퍼플렉서티 31.97\n",
            "| epoch 68 | 퍼플렉서티 30.05\n",
            "| epoch 69 | 퍼플렉서티 29.43\n",
            "| epoch 70 | 퍼플렉서티 27.34\n",
            "| epoch 71 | 퍼플렉서티 25.32\n",
            "| epoch 72 | 퍼플렉서티 24.05\n",
            "| epoch 73 | 퍼플렉서티 22.66\n",
            "| epoch 74 | 퍼플렉서티 22.14\n",
            "| epoch 75 | 퍼플렉서티 19.98\n",
            "| epoch 76 | 퍼플렉서티 18.77\n",
            "| epoch 77 | 퍼플렉서티 17.74\n",
            "| epoch 78 | 퍼플렉서티 17.42\n",
            "| epoch 79 | 퍼플렉서티 15.86\n",
            "| epoch 80 | 퍼플렉서티 15.15\n",
            "| epoch 81 | 퍼플렉서티 14.51\n",
            "| epoch 82 | 퍼플렉서티 13.82\n",
            "| epoch 83 | 퍼플렉서티 12.70\n",
            "| epoch 84 | 퍼플렉서티 12.50\n",
            "| epoch 85 | 퍼플렉서티 11.93\n",
            "| epoch 86 | 퍼플렉서티 10.61\n",
            "| epoch 87 | 퍼플렉서티 10.33\n",
            "| epoch 88 | 퍼플렉서티 9.59\n",
            "| epoch 89 | 퍼플렉서티 9.13\n",
            "| epoch 90 | 퍼플렉서티 8.70\n",
            "| epoch 91 | 퍼플렉서티 8.26\n",
            "| epoch 92 | 퍼플렉서티 7.81\n",
            "| epoch 93 | 퍼플렉서티 7.54\n",
            "| epoch 94 | 퍼플렉서티 7.13\n",
            "| epoch 95 | 퍼플렉서티 6.92\n",
            "| epoch 96 | 퍼플렉서티 6.65\n",
            "| epoch 97 | 퍼플렉서티 6.12\n",
            "| epoch 98 | 퍼플렉서티 6.04\n",
            "| epoch 99 | 퍼플렉서티 5.51\n",
            "| epoch 100 | 퍼플렉서티 5.33\n"
          ]
        }
      ]
    }
  ]
}