{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uTXfxUwKPc-K"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "기본적인 RNN 계층 구현"
      ],
      "metadata": {
        "id": "EGe07-W0fan5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN:\n",
        "  def __init__(self, Wx, Wh, b):\n",
        "    self.params = [Wx, Wh, b]\n",
        "    self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
        "    self.cache = None\n",
        "\n",
        "  # RNN의 순전파 계산\n",
        "  def forward(self, x, h_prev):\n",
        "    Wx, Wh, b = self.params\n",
        "\n",
        "    t = np.matmul(h_prev, Wh) + np.matmul(x, Wx) + b\n",
        "    h_next = np.tanh(t)\n",
        "\n",
        "    self.cache = (x, h_prev, h_next)\n",
        "    return h_next\n",
        "\n",
        "  # RNN의 역전파 계산\n",
        "  def backward(self, dh_next):\n",
        "    Wx, Wh, b = self.params\n",
        "    x, h_prev, h_next = self.cache\n",
        "\n",
        "    dt = dh_next * (1 - h_next ** 2)\n",
        "    db = np.sum(dt, axis=0)\n",
        "    dWh = np.matmul(h_prev.T, dt)\n",
        "    dh_prev = np.matmul(dt, Wh.T)\n",
        "    dWx = np.matmul(x.T, dt)\n",
        "    dx = np.matmul(dt, Wx.T)\n",
        "\n",
        "    self.grads[0][...] = dWx\n",
        "    self.grads[1][...] = dWh\n",
        "    self.grads[2][...] = db\n",
        "\n",
        "    return dx, dh_prev"
      ],
      "metadata": {
        "id": "BT30o3ISPjiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "앞서 구현한 RNN 계층들을 모아서 처리하는 Time RNN을 구현해본다. Time RNN 계층은 RNN 계층 T개를 연결한 신경망이다."
      ],
      "metadata": {
        "id": "pYNFFP__pijp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeRNN:\n",
        "  def __init__(self, Wx, Wh, b, stateful=False):\n",
        "    self.params = [Wx, Wh, b]\n",
        "    self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)] # 저장할 미분값들을 0으로 초기화\n",
        "    self.layers = None # 다수의 RNN 계층을 리스트로 저장하는 용도\n",
        "\n",
        "    self.h, self.dh = None, None\n",
        "    self.stateful = stateful\n",
        "\n",
        "  def set_state(self, h):\n",
        "    self.h = h\n",
        "\n",
        "  def reset_state(self):\n",
        "    self.h = None\n",
        "\n",
        "  # Time RNN 순전파 계산\n",
        "  def forward(self, xs):\n",
        "    Wx, Wh, b = self.params\n",
        "    N, T, D = xs.shape # N:미니배치 크기, T:시계열 데이터의 분량, D:입력벡터의 차원 수\n",
        "    D, H = Wx.shape # D:입력벡터의 차원 수, H:은닉 벡터의 차원 수\n",
        "\n",
        "    self.layers = []\n",
        "    hs = np.empty((N, T, H), dtype='f') # 출력값을 담을 float형 그릇, N:미니배치 크기, T:시계열 데이터의 분량, H:은닉 벡터의 차원 수\n",
        "\n",
        "    if not self.stateful or self.h is None: # 처음 호출 시에 RNN계층의 은닉상태 h를 0행렬로 초기화\n",
        "      self.h = np.zeros((N, H), dtype='f')\n",
        "\n",
        "    for t in range(T):\n",
        "      layer = RNN(*self.params) # 앞서 구현했던 RNN 계층을 이용\n",
        "      self.h = layer.forward(xs[:, t, :], self.h) # t번째 입력에 대해서 RNN 계층 순전파 수행\n",
        "      hs[:, t, :] = self.h  # 각 시각 t의 출력(은닉 상태)을 저장\n",
        "      self.layers.append(layer) #생성하여 사용된 RNN 계층을 laysers 리스트에 추가하여 저장\n",
        "\n",
        "    return hs\n",
        "\n",
        "  # Time RNN 역전파\n",
        "  def backward(self, dhs):\n",
        "    Wx, Wh, b = self.params\n",
        "    N, T, H = dhs.shape # N:미니배치 크기, T:시계열 데이터의 분량, H:은닉 벡터의 차원 수\n",
        "    D, H = Wx.shape # D:입력벡터의 차원 수, H:은닉 벡터의 차원 수\n",
        "\n",
        "    dxs = np.empty((N, T, D), dtype='f') # 역전파 입력\n",
        "    dh = 0  # 역전파를 거치며 합산된 기울기\n",
        "    grads = [0, 0, 0] # 미분값 초기화\n",
        "\n",
        "    for t in reversed(range(T)): # 역순서의 인덱스로 순회\n",
        "      layer = self.layeres[t] # RNN 계층을 역으로 순회\n",
        "      dx, dh = layer.backward(dhs[:, t, :] + dh) # 역전파 수행 (순전파에서 분기되었으므로 역전파에서는 기울기를 합산, 분기의 반대는 합산이다!)\n",
        "      dxs[:, t, :] = dx # 각 시각 t에서 얻은 x 기울기를 저장\n",
        "\n",
        "      # t를 순회할 때마다 역전파로 얻은 가중치를 위 로컬변수로 초기화 한 grads에 합산\n",
        "      for i, grad in enumerate(layer.grads):\n",
        "        grads[i] += grad\n",
        "\n",
        "    # 합산된 가중치 기울기의 최종 결과를 멤버변수 self.grads에 덮어씀\n",
        "    for i, grad in enumerate(grads):\n",
        "      self.grads[i][...] = grad\n",
        "    self.dh = dh\n",
        "\n",
        "    return dxs"
      ],
      "metadata": {
        "id": "Fzy32XPpfZae"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}