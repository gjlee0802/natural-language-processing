{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9fadiGlp5EO"
   },
   "source": [
    "# Attention is All You Need (NIPS 2017) 실습\n",
    "\n",
    "트랜스포머 정리 노트: https://github.com/gjlee0802/natural-language-processing/blob/main/NLP/transformer/attention_is_all_you_need_summary.md\n",
    "\n",
    "\n",
    "독일어를 영어로 번역하는 Machine Translation 구현, 데이터셋은 Multi30k 이용."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fxcMGl0fs0Eq"
   },
   "source": [
    "# 데이터 전처리(Preprocessing)\n",
    "\n",
    "spacy 라이브러리: 문장의 토큰화, 태깅 등의 전처리 기능을 위한 라이브러리\n",
    "\n",
    "영어와 독일어 전처리 모듈 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1k_hv31Ip4eu"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!python -m spacy download en\n",
    "!python -m spacy download de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9JExj6Ytn1RP"
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NtS7D7ZYpXvs"
   },
   "outputs": [],
   "source": [
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "spacy_de = spacy.load('de_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eTRo5yXjphab",
    "outputId": "4585f69d-69ba-440e-a5e1-11e5628097dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인덱스 0 : I\n",
      "인덱스 1 : am\n",
      "인덱스 2 : a\n",
      "인덱스 3 : graduate\n",
      "인덱스 4 : student\n",
      "인덱스 5 : .\n"
     ]
    }
   ],
   "source": [
    "tokenized = spacy_en.tokenizer(\"I am a graduate student.\")\n",
    "\n",
    "for i, token in enumerate(tokenized):\n",
    "  print(f\"인덱스 {i} : {token.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WrbKUTTIsxLV"
   },
   "source": [
    "## 토큰화 함수 정의 (spacy의 토크나이저 이용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0TN6TdgBscdG"
   },
   "outputs": [],
   "source": [
    "# 독일어 문장을 토큰화 하는 함수\n",
    "def tokenize_de(text):\n",
    "  return [token.text for token in spacy_de.tokenizer(text)]\n",
    "\n",
    "# 영어 문장을 토큰화 하는 함수\n",
    "def tokenize_en(text):\n",
    "  return [token.text for token in spacy_en.tokenizer(text)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wZMobabcvtvo",
    "outputId": "03699952-d7bf-4a2d-d2d1-c723b28ee882"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0+cu121\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bzZUvITRujcF",
    "outputId": "76312ec5-49b1-49e6-a0a3-6f75377b3dd7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install torchtext==0.17.0\\n!pip install portalocker>=2.0.0\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "!pip install torchtext==0.17.0\n",
    "!pip install portalocker>=2.0.0\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9pg6vp1wGa_v"
   },
   "source": [
    "## 어휘집 Vocab 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "cPx1ryFGMbQ0"
   },
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.datasets import multi30k, Multi30k\n",
    "from typing import Iterable, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update URLs to point to data stored by user\n",
    "#multi30k.URL[\"train\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/training.tar.gz\"\n",
    "#multi30k.URL[\"valid\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/validation.tar.gz\"\n",
    "multi30k.URL[\"test\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/mmt16_task1_test.tar.gz\"\n",
    "\n",
    "# Update hash since there is a discrepancy between user hosted test split and that of the test split in the original dataset \n",
    "multi30k.MD5[\"test\"] = \"6d1ca1dba99e2c5dd54cae1226ff11c2551e6ce63527ebb072a1f70f72a5cd36\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "WXaA4kGG_Sfe"
   },
   "outputs": [],
   "source": [
    "SRC_LANG = 'de'\n",
    "TGT_LANG = 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0xwMHiw9DEsR"
   },
   "outputs": [],
   "source": [
    "tokenizer = {}\n",
    "tokenizer['en'] = tokenize_en\n",
    "tokenizer['de'] = tokenize_de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "uxzGsx_g_Png"
   },
   "outputs": [],
   "source": [
    "# 토큰 목록을 생성하기 위한 헬퍼(helper) 함수\n",
    "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
    "    language_index = {SRC_LANG: 0, TGT_LANG: 1}\n",
    "\n",
    "    for i, datasample_tuple in enumerate(train_iter):\n",
    "      yield tokenizer[language](datasample_tuple[language_index[language]])\n",
    "    '''\n",
    "    for data_sample in data_iter:\n",
    "        yield token_transform[language](data_sample[language_index[language]])\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ivS0lAYgMWZf"
   },
   "outputs": [],
   "source": [
    "# 특수 기호(symbol)와 인덱스를 정의합니다\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "# 토큰들이 어휘집(vocab)에 인덱스 순서대로 잘 삽입되어 있는지 확인합니다\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "\n",
    "vocab_transform = {} # 영어, 독일어에 대해서 torchtext의 Vocab 옵젝이 저장됨.\n",
    "\n",
    "for ln in [SRC_LANG, TGT_LANG]:\n",
    "  train_iter = Multi30k(split='train', language_pair=(SRC_LANG, TGT_LANG))\n",
    "  val_iter = Multi30k(split='valid', language_pair=(SRC_LANG, TGT_LANG))\n",
    "  test_iter = Multi30k(split='test', language_pair=(SRC_LANG, TGT_LANG))\n",
    "\n",
    "  vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n",
    "                                                  min_freq=1, # 최소 n번 이상 등장한 단어만을 선택\n",
    "                                                  specials=special_symbols,\n",
    "                                                  special_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f9K165Ma_MPg",
    "outputId": "6229d701-4c70-4164-d1d2-d106ff163c75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \n",
      "x:Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche. \n",
      "y:Two young, White males are outside near many bushes.\n",
      "[1] \n",
      "x:Mehrere Männer mit Schutzhelmen bedienen ein Antriebsradsystem. \n",
      "y:Several men in hard hats are operating a giant pulley system.\n",
      "[2] \n",
      "x:Ein kleines Mädchen klettert in ein Spielhaus aus Holz. \n",
      "y:A little girl climbing into a wooden playhouse.\n",
      "[3] \n",
      "x:Ein Mann in einem blauen Hemd steht auf einer Leiter und putzt ein Fenster. \n",
      "y:A man in a blue shirt is standing on a ladder cleaning a window.\n",
      "[4] \n",
      "x:Zwei Männer stehen am Herd und bereiten Essen zu. \n",
      "y:Two men are at the stove preparing food.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\이경주\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\combining.py:337: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
      "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
     ]
    }
   ],
   "source": [
    "for idx, (x, y) in enumerate(train_iter):\n",
    "  if idx == 5:\n",
    "    break\n",
    "\n",
    "  print(f'[{idx}] \\nx:{x} \\ny:{y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "aTp2GdU4BIN5"
   },
   "outputs": [],
   "source": [
    "# ``UNK_IDX`` 를 기본 인덱스로 설정합니다. 이 인덱스는 토큰을 찾지 못하는 경우에 반환됩니다.\n",
    "# 만약 기본 인덱스를 설정하지 않으면 어휘집(Vocabulary)에서 토큰을 찾지 못하는 경우\n",
    "# ``RuntimeError`` 가 발생합니다.\n",
    "for ln in [SRC_LANG, TGT_LANG]:\n",
    "    vocab_transform[ln].set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xNAwtyBLEqc6",
    "outputId": "8637ed2c-afb6-4f97-d21e-d935516ab241"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소스 언어의 Vocab(어휘집)\n",
      "[Vocab] index: 0 | token: <unk>\n",
      "[Vocab] index: 1 | token: <pad>\n",
      "[Vocab] index: 2 | token: <bos>\n",
      "[Vocab] index: 3 | token: <eos>\n",
      "[Vocab] index: 4 | token: .\n",
      "[Vocab] index: 5 | token: Ein\n",
      "[Vocab] index: 6 | token: einem\n",
      "[Vocab] index: 7 | token: in\n",
      "[Vocab] index: 8 | token: ,\n",
      "[Vocab] index: 9 | token: und\n",
      "[Vocab] index: 10 | token: mit\n",
      "[Vocab] index: 11 | token: auf\n",
      "[Vocab] index: 12 | token: Mann\n",
      "[Vocab] index: 13 | token: einer\n",
      "[Vocab] index: 14 | token: Eine\n",
      "[Vocab] index: 15 | token: ein\n",
      "[Vocab] index: 16 | token: der\n",
      "[Vocab] index: 17 | token: Frau\n",
      "[Vocab] index: 18 | token: eine\n",
      "[Vocab] index: 19 | token: die\n"
     ]
    }
   ],
   "source": [
    "print('소스 언어의 Vocab(어휘집)')\n",
    "for idx in range(20):\n",
    "  print(f'[Vocab] index: {idx} | token: {vocab_transform[SRC_LANG].lookup_token(idx)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h16VuyrcF7ae",
    "outputId": "684800c7-1e74-450c-a375-304963379f92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타겟 언어의 Vocab(어휘집)\n",
      "[Vocab] index: 0 | token: <unk>\n",
      "[Vocab] index: 1 | token: <pad>\n",
      "[Vocab] index: 2 | token: <bos>\n",
      "[Vocab] index: 3 | token: <eos>\n",
      "[Vocab] index: 4 | token: a\n",
      "[Vocab] index: 5 | token: .\n",
      "[Vocab] index: 6 | token: A\n",
      "[Vocab] index: 7 | token: in\n",
      "[Vocab] index: 8 | token: the\n",
      "[Vocab] index: 9 | token: on\n",
      "[Vocab] index: 10 | token: is\n",
      "[Vocab] index: 11 | token: and\n",
      "[Vocab] index: 12 | token: man\n",
      "[Vocab] index: 13 | token: of\n",
      "[Vocab] index: 14 | token: with\n",
      "[Vocab] index: 15 | token: ,\n",
      "[Vocab] index: 16 | token: woman\n",
      "[Vocab] index: 17 | token: are\n",
      "[Vocab] index: 18 | token: to\n",
      "[Vocab] index: 19 | token: Two\n"
     ]
    }
   ],
   "source": [
    "print('타겟 언어의 Vocab(어휘집)')\n",
    "for idx in range(20):\n",
    "  print(f'[Vocab] index: {idx} | token: {vocab_transform[TGT_LANG].lookup_token(idx)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y9Mzk1E-FAUs",
    "outputId": "b0b9851b-1976-4119-b77b-7ebf40fd4a1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]\n"
     ]
    }
   ],
   "source": [
    "print(vocab_transform[TGT_LANG].lookup_indices(['A']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MO_zPx6xLnsh",
    "outputId": "6fcebbf6-969e-4edb-b9ed-b9b5053e5d82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19214\n",
      "10837\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab_transform[SRC_LANG]))\n",
    "print(len(vocab_transform[TGT_LANG]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UZ7gFWM7dtRe"
   },
   "source": [
    "배치 크기, 문장 내 최대 단어 개수 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "q6Bu7xTaJPrO"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128  # 배치 크기\n",
    "MAX_LENGTH = 100  # 한 문장 내에 들어갈 수 있는 최대 단어 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9PPOjrn-SBMJ"
   },
   "source": [
    "배치 생성 전처리 코드 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "v24L26f-C4zi"
   },
   "outputs": [],
   "source": [
    "from torch.nn.functional import pad\n",
    "\n",
    "src_pipeline = lambda x: vocab_transform[SRC_LANG].lookup_indices(tokenizer[SRC_LANG](x))\n",
    "tgt_pipeline = lambda x: vocab_transform[TGT_LANG].lookup_indices(tokenizer[TGT_LANG](x))\n",
    "\n",
    "def collate_batch(batch):\n",
    "\n",
    "  bs_id = torch.tensor([BOS_IDX])\n",
    "  eos_id = torch.tensor([EOS_IDX])\n",
    "\n",
    "  src_list, tgt_list = [], []\n",
    "  for (_srctext, _tgttext) in batch:\n",
    "    processed_src = torch.cat(\n",
    "        [\n",
    "            bs_id,\n",
    "            torch.tensor(\n",
    "                src_pipeline(_srctext),\n",
    "                dtype=torch.int64\n",
    "            ),\n",
    "            eos_id,\n",
    "        ],\n",
    "        0,\n",
    "    )\n",
    "    processed_tgt = torch.cat(\n",
    "        [\n",
    "            bs_id,\n",
    "            torch.tensor(\n",
    "                tgt_pipeline(_tgttext),\n",
    "                dtype=torch.int64\n",
    "            ),\n",
    "            eos_id\n",
    "        ],\n",
    "        0,\n",
    "    )\n",
    "    src_list.append(\n",
    "            # warning - overwrites values for negative values of padding - len\n",
    "            pad(\n",
    "                processed_src,\n",
    "                (\n",
    "                    0,\n",
    "                    MAX_LENGTH - len(processed_src),\n",
    "                ),\n",
    "                value=PAD_IDX,\n",
    "            )\n",
    "    )\n",
    "    tgt_list.append(\n",
    "            # warning - overwrites values for negative values of padding - len\n",
    "            pad(\n",
    "                processed_tgt,\n",
    "                (\n",
    "                    0,\n",
    "                    MAX_LENGTH - len(processed_tgt),\n",
    "                ),\n",
    "                value=PAD_IDX,\n",
    "            )\n",
    "    )\n",
    "    #src_list.append(processed_src)\n",
    "    #tgt_list.append(processed_tgt)\n",
    "  '''\n",
    "  src_list = torch.cat(src_list)\n",
    "  tgt_list = torch.cat(tgt_list)\n",
    "\n",
    "  src_list = pad(\n",
    "    src_list,\n",
    "    (\n",
    "        0,\n",
    "        BATCH_SIZE - len(src_list),\n",
    "    ),\n",
    "    value=PAD_IDX,\n",
    "  )\n",
    "  tgt_list = pad(\n",
    "    tgt_list,\n",
    "    (\n",
    "        0,\n",
    "        BATCH_SIZE - len(tgt_list),\n",
    "    ),\n",
    "    value=PAD_IDX,\n",
    "  )\n",
    "  '''\n",
    "\n",
    "  src = torch.stack(src_list)\n",
    "  tgt = torch.stack(tgt_list)\n",
    "  return src, tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "j9QkUCNh5ouZ"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def train_valid_split(train_iterator, split_ratio=0.8, seed=42):\n",
    "    train_count = int(split_ratio * len(train_iterator))\n",
    "    valid_count = len(train_iterator) - train_count\n",
    "    generator = torch.Generator().manual_seed(seed)\n",
    "    train_set, valid_set = random_split(\n",
    "        train_iterator, lengths=[train_count, valid_count], generator=generator)\n",
    "    return train_set, valid_set\n",
    "\n",
    "# iterable type에서 map style로 변환해야 length check 가능\n",
    "train_iter = to_map_style_dataset(train_iter)\n",
    "valid_iter = to_map_style_dataset(val_iter)\n",
    "#test_iter = to_map_style_dataset(test_iter)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_iter, batch_size=BATCH_SIZE, shuffle=True, collate_fn = collate_batch)\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_iter, batch_size=BATCH_SIZE, shuffle=True, collate_fn = collate_batch)\n",
    "#test_dataloader = DataLoader(\n",
    "#    test_iter, batch_size=BATCH_SIZE, shuffle=True, collate_fn = collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PJwkeOUoiY-y",
    "outputId": "7467fb8d-e831-428f-83bf-c3982bbc9ca4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29001\n"
     ]
    }
   ],
   "source": [
    "print(len(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K_WY977piby3",
    "outputId": "1d50b163-5820-46a8-d272-a707b52de735"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1015\n"
     ]
    }
   ],
   "source": [
    "print(len(valid_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iPiTz04K_asj"
   },
   "source": [
    "train_dataloader를 돌며 Source에 대한 배치 데이터 출력해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r86krVyZGiGa"
   },
   "source": [
    "# Transformer 활용 Seq2Seq 모델\n",
    "\n",
    "torch에서 제공하는 Transformer을 사용하지 않고, transformer을 구현하여 활용해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Apd2N7M2GrSD"
   },
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "import math\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRVJ_C0XPNbG"
   },
   "source": [
    "## Multi Head Attention\n",
    "\n",
    "어텐션은 세가지 요소를 입력으로 받는다.\n",
    "- 쿼리(queries)\n",
    "- 키(keys)\n",
    "- 값(values)\n",
    "\n",
    "하이퍼 파라미터\n",
    "- hidden_dim: 하나의 단어에 대한 임베딩 차원\n",
    "- n_heads: 헤드의 개수(scaled dot-product attention 개수)\n",
    "- dropout_ratio: 드롭아웃 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "7A6B9TajPSvm"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MultiHeadAttentionLayer(nn.Module):\n",
    "  def __init__(self, hidden_dim, n_heads, dropout_ratio, device):\n",
    "    super().__init__()\n",
    "\n",
    "    # assert는 뒤의 조건이 True가 아니면 AssertError를 발생한다.\n",
    "    assert hidden_dim % n_heads == 0\n",
    "\n",
    "    self.hidden_dim = hidden_dim # 임베딩 차원\n",
    "    self.n_heads = n_heads # 헤드의 개수(서로 다른 어텐션 컨셉의 수)\n",
    "    self.head_dim = hidden_dim // n_heads # 각 헤드에서의 임베딩 차원 = 전체 임베딩 차원을 헤드의 수로 나눈 값\n",
    "\n",
    "    self.fc_q = nn.Linear(hidden_dim, hidden_dim) # Query 값에 적용될 FC 레이어\n",
    "    self.fc_k = nn.Linear(hidden_dim, hidden_dim) # Key 값에 적용될 FC 레이어\n",
    "    self.fc_v = nn.Linear(hidden_dim, hidden_dim) # Value 값에 적용될 FC 레이어\n",
    "\n",
    "    self.fc_o = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "    self.dropout = nn.Dropout(dropout_ratio)\n",
    "\n",
    "    self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
    "\n",
    "  def forward(self, query, key, value, mask = None):\n",
    "    batch_size = query.shape[0]\n",
    "\n",
    "    # query: [batch_size, query_len, hidden_dim]\n",
    "    # key: [batch_size, key_len, hidden_dim]\n",
    "    # value: [batch_size, value_len, hidden_dim]\n",
    "\n",
    "    # 각각 FC 레이어에 입력\n",
    "    Q = self.fc_q(query)\n",
    "    K = self.fc_k(key)\n",
    "    V = self.fc_v(value)\n",
    "\n",
    "    # Q: [batch_size, query_len, hidden_dim]\n",
    "    # K: [batch_size, key_len, hidden_dim]\n",
    "    # V: [batch_size, value_len, hidden_dim]\n",
    "\n",
    "    # hidden_dim -> n_heads X head_dim 형태로 변형\n",
    "    # after permute\n",
    "    # Q: [batch_size, query_len, n_heads, head_dim] -> [batch_size, n_heads, query_len, head_dim]\n",
    "    # K: [batch_size, key_len, n_heads, head_dim] -> [batch_size, n_heads, key_len, head_dim]\n",
    "    # V: [batch_size, value_len, n_heads, head_dim] -> [batch_size, n_heads, value_len, head_dim]\n",
    "    Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0,2,1,3)\n",
    "    K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0,2,1,3)\n",
    "    V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0,2,1,3)\n",
    "\n",
    "    # Q: [batch_size, n_heads, query_len, head_dim]\n",
    "    # K: [batch_size, n_heads, key_len, head_dim]\n",
    "    # V: [batch_size, n_heads, value_len, head_dim]\n",
    "\n",
    "    # Attention Energy 계산 (유사도 계산)\n",
    "    energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
    "\n",
    "    # 마스크를 사용할 경우\n",
    "    if mask is not None:\n",
    "      energy = energy.masked_fill(mask==0, -1e10) # 마스크 값이 0인 부분에 상당이 작은 값으로 채워준다.\n",
    "\n",
    "    # 어텐션 스코어 계산: 각 단어에 대한 확률 값\n",
    "    attention = torch.softmax(energy, dim=-1) # 소프트맥스로 정규화\n",
    "\n",
    "    # attention: [batch_size, n_heads, query_len, key_len]\n",
    "\n",
    "    # Scaled Dot-Product Attention을 계산\n",
    "    x = torch.matmul(self.dropout(attention), V)\n",
    "\n",
    "    # x: [batch_size, n_heads, query_len, head_dim]\n",
    "\n",
    "    x = x.permute(0,2,1,3).contiguous()\n",
    "\n",
    "    # x: [batch_size, query_len, n_heads, head_dim]\n",
    "\n",
    "    # n_heads X head_dim -> hidden_dim 변형\n",
    "    x = x.view(batch_size, -1, self.hidden_dim)\n",
    "\n",
    "    # x: [batch_size, query_len, hidden_dim]\n",
    "\n",
    "    x = self.fc_o(x)\n",
    "\n",
    "    return x, attention\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WrHqPNDD1ib3"
   },
   "source": [
    "## Position-wise Feedforward\n",
    "입력과 출력의 차원이 동일함.  \n",
    "- encoder와 decoder의 각각의 layer는 fully connected feed-forward network를 포함하고 있음.  \n",
    "- position 마다, 즉 개별 단어마다 적용되기 때문에 position-wise.  \n",
    "- network는 두 번의 linear transformation과 activation function ReLU로 이루어져 있음(fc1 -> relu -> fc2).  \n",
    "\n",
    "하이퍼 파라미터\n",
    "- hidden_dim: 하나의 단어에 대한 임베딩 차원\n",
    "- pf_dim: Feedforward 레이어에서의 내부 임베딩 차원\n",
    "- dropout_ratio: 드롭아웃 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "RM2bCgO-1IDQ"
   },
   "outputs": [],
   "source": [
    "class PositionwiseFeedforwardLayer(nn.Module):\n",
    "  def __init__(self, hidden_dim, pf_dim, dropout_ratio):\n",
    "      super().__init__()\n",
    "\n",
    "      self.fc_1 = nn.Linear(hidden_dim, pf_dim)\n",
    "      self.fc_2 = nn.Linear(pf_dim, hidden_dim)\n",
    "\n",
    "      self.dropout = nn.Dropout(dropout_ratio)\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "    # x: [batch_size, seq_len, hidden_dim]\n",
    "\n",
    "    x = self.dropout(torch.relu(self.fc_1(x)))\n",
    "\n",
    "    # x: [batch_size, seq_len, pf_dim]\n",
    "\n",
    "    x = self.fc_2(x)\n",
    "\n",
    "    # x: [batch_size, seq_len, hidden_dim]\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpCBRc9A4DO5"
   },
   "source": [
    "## Encoder 레이어\n",
    "인코더는 아래의 인코더 레이어를 여러번 중첩하여 사용함.  \n",
    "인코더 레이어의 입력과 출력의 차원이 같음.  \n",
    "\n",
    "\n",
    "하이퍼 파라미터\n",
    "- hidden_dim: 하나의 단어에 대한 임베딩 차원\n",
    "- n_heads: 헤드의 개수\n",
    "- pf_dim: Feedforward 레이어(PositionwiseFeedforward)에서의 내부 임베딩 차원\n",
    "- dropout_ratio: 드롭아웃 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "0_NDqu9B4IEJ"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "  def __init__(self, hidden_dim, n_heads, pf_dim, dropout_ratio, device):\n",
    "    super().__init__()\n",
    "\n",
    "    self.self_attn_layer_norm = nn.LayerNorm(hidden_dim)\n",
    "    self.ff_layer_norm = nn.LayerNorm(hidden_dim)\n",
    "    self.self_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio, device)\n",
    "    self.positionwise_feedforward = PositionwiseFeedforwardLayer(hidden_dim, pf_dim, dropout_ratio)\n",
    "    self.dropout = nn.Dropout(dropout_ratio)\n",
    "\n",
    "  def forward(self, src, src_mask):\n",
    "    # src: [batch_size, src_len, hidden_dim]\n",
    "    # src_mask: [batch_size, src_len]\n",
    "\n",
    "    # Self Attention\n",
    "    # 필요한 경우 마스크 행렬을 이용하여 어텐션할 단어 조절 가능\n",
    "    _src, _ = self.self_attention.forward(src, src, src, src_mask) # params : query, key, value, mask\n",
    "\n",
    "    # dropout, residual connection and layer norm\n",
    "    # residual connection : feedforward를 거치기 전 입력 x를 feedforward를 거친 결과값에 더해주어 입력하는 것\n",
    "    src = self.self_attn_layer_norm.forward(src + self.dropout(_src))\n",
    "\n",
    "    # src: [batch_size, src_len, hidden_dim]\n",
    "\n",
    "    # Position-wisd feedforward\n",
    "    _src = self.positionwise_feedforward.forward(src)\n",
    "\n",
    "    # dropout, residual and layer norm\n",
    "    src = self.ff_layer_norm(src + self.dropout(_src))\n",
    "\n",
    "    # src: [batch_size, src_len, hidden_dim]\n",
    "\n",
    "    return src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxkzEBsYxNaW"
   },
   "source": [
    "## Encoder\n",
    "\n",
    "하이퍼 파라미터\n",
    "- input_dim: 하나의 단어에 대한 원-핫 인코딩 차원\n",
    "- hidden_dim: 하나의 단어에 대한 임베딩 차원\n",
    "- n_layers: 내부적으로 사용할 인코더 레이어의 개수\n",
    "- n_heads: 헤드의 개수\n",
    "- pf_dim: Feedforward 레이어에서의 내부 임베딩 차원\n",
    "- dropout_ratio: 드롭아웃 비율\n",
    "- max_length: 문장 내 최대 단어 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "75t0GSZ793lU"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "  def __init__(self, input_dim, hidden_dim, n_layers, n_heads, pf_dim, dropout_ratio, device, max_length=100):\n",
    "    super().__init__()\n",
    "\n",
    "    self.device = device\n",
    "\n",
    "    self.tok_embedding = nn.Embedding(input_dim, hidden_dim)\n",
    "    self.pos_embedding = nn.Embedding(max_length, hidden_dim)\n",
    "\n",
    "    self.encoder_layers = nn.ModuleList([EncoderLayer(hidden_dim, n_heads, pf_dim, dropout_ratio, device) for _ in range(n_layers)])\n",
    "\n",
    "    self.dropout = nn.Dropout(dropout_ratio)\n",
    "\n",
    "    self.scale = torch.sqrt(torch.FloatTensor([hidden_dim])).to(device)\n",
    "\n",
    "  def forward(self, src, src_mask):\n",
    "    # src: [batch_size, src_len]\n",
    "    # src_mask: [batch_size, src_len]\n",
    "\n",
    "    src = src.to(self.device)\n",
    "    src_mask = src_mask.to(self.device)\n",
    "\n",
    "    batch_size = src.shape[0]\n",
    "    src_len = src.shape[1]\n",
    "\n",
    "    # unsqueeze는 특정 위치에 1인 차원을 추가함.\n",
    "    # unsqueeze(0)는 첫번째 차원에 1인 차원을 추가함. [1 X src_len]\n",
    "    # repeat 함수는 텐서를 반복 확장시켜줌.\n",
    "    # repeat(batch_size, 1)은 [1 X src_len] 형태를 [batch_size, src_len] 차원으로 만들어줌.\n",
    "    pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
    "\n",
    "    # pos: [batch_size, src_len]\n",
    "\n",
    "    # 소스 문장의 임베딩과 위치 임베딩을 더함. (Positional Encoding)\n",
    "    src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos)).to(device)\n",
    "\n",
    "    # src: [batch_size, src_len, hidden_dim]\n",
    "\n",
    "    # 모든 인코더 레이어를 차례대로 거치며 순전파 수행\n",
    "    for layer in self.encoder_layers:\n",
    "      src = layer(src, src_mask)\n",
    "\n",
    "    # src: [batch_size, src_len, hidden_dim]\n",
    "\n",
    "    # 마지막 레이어의 출력 반환\n",
    "    return src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qic-2XOFMPJV"
   },
   "source": [
    "## Decoder 레이어\n",
    "\n",
    "하이퍼 파라미터\n",
    "- hidden_dim: 하나의 단어에 대한 임베딩 차원\n",
    "- n_heads: 헤드의 개수\n",
    "- pf_dim: Feedforward 레이어(PositionwiseFeedforward)에서의 내부 임베딩 차원\n",
    "- dropout_ratio: 드롭아웃 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "YX1nh8YWMOFl"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "  def __init__(self, hidden_dim, n_heads, pf_dim, dropout_ratio, device):\n",
    "    super().__init__()\n",
    "\n",
    "    self.self_attn_layer_norm = nn.LayerNorm(hidden_dim)\n",
    "    self.enc_attn_layer_norm = nn.LayerNorm(hidden_dim)\n",
    "    self.ff_layer_norm = nn.LayerNorm(hidden_dim)\n",
    "    self.self_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio, device)\n",
    "    self.encoder_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio, device)\n",
    "    self.positionwise_feedforward = PositionwiseFeedforwardLayer(hidden_dim, pf_dim, dropout_ratio)\n",
    "    self.dropout = nn.Dropout(dropout_ratio)\n",
    "\n",
    "  # 인코더의 출력 값(enc_src)를 어텐션하는 구조\n",
    "  def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "    # trg: [batch_size, trg_len, hidden_dim]\n",
    "    # enc_src: [batch_size, src_len, hidden_dim]\n",
    "    # trg_mask: [batch_size, trg_len, hidden_dim]\n",
    "    # src_mask: [batch_size, src_len, hidden_dim]\n",
    "\n",
    "    _trg, _ = self.self_attention.forward(trg, trg, trg, trg_mask) # params : query, key, value, mask\n",
    "\n",
    "    trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
    "\n",
    "    # trg: [batch_size, trg_len, hidden_dim]\n",
    "\n",
    "    # Encoder Attention\n",
    "    # 디코더의 쿼리(Query)를 이용하여 인코더를 어텐션\n",
    "    _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
    "\n",
    "    # dropout, residual connection and layer norm\n",
    "    trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
    "\n",
    "    # trg: [batch_size, trg_len, hidden_dim]\n",
    "    # attention: [batch_size, n_heads, trg_len, src_len]\n",
    "\n",
    "    # positionwise feedforward\n",
    "    _trg = self.positionwise_feedforward(trg)\n",
    "\n",
    "    # dropout, residual and layer norm\n",
    "    # residual connection : feedforward를 거치기 전 입력 x를 feedforward를 거친 결과값에 더해주어 입력하는 것\n",
    "    trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
    "\n",
    "    # trg: [batch_size, trg_len, hidden_dim]\n",
    "    # attention: [batch_size, n_heads, trg_len, src_len]\n",
    "\n",
    "    return trg, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "seOLTrmBR7eA"
   },
   "source": [
    "## Decoder\n",
    "원본 논문과 다르게 위치 임베딩(positional embedding)을 학습하는 형태(BERT와 같은 모던 트랜스포머 모델에서 사용되는 방식)로 구현함.  \n",
    "  \n",
    "소스 문장의 'pad' 토큰에 대해 마스크(MASK) 값을 0으로 설정함.  \n",
    "  \n",
    "Masked Decoder Self-Attention: 타겟 문장에서 각 단어는 다음 단어가 무엇인지 알 수 없도록(이전 단어만 보도록) 만들기 위해 마스크(MASK)를 사용함.\n",
    "~~~\n",
    "Masked Decoder Self-Attention : 디코더 파트에서 셀프 어텐션을 사용할 때는 각각의 출력 단어가 다른 모든 출력 단어를 참고하도록 하지는 않고, 앞쪽의 단어들만 참고하도록 함.\n",
    "~~~\n",
    "\n",
    "하이퍼 파라미터\n",
    "- output_dim: 하나의 단어에 대한 원-핫 인코딩 차원\n",
    "- hidden_dim: 하나의 단어에 대한 임베딩 차원\n",
    "- n_layers: 내부적으로 사용할 인코더 레이어의 개수\n",
    "- n_heads: 헤드의 개수\n",
    "- pf_dim: Feedforward 레이어에서의 내부 임베딩 차원\n",
    "- dropout_ratio: 드롭아웃 비율\n",
    "- max_length: 문장 내 최대 단어 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "fQ48w4KqSoei"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "  def __init__(self, output_dim, hidden_dim, n_layers, n_heads, pf_dim, dropout_ratio, device, max_length=100):\n",
    "    super().__init__()\n",
    "\n",
    "    self.device = device\n",
    "\n",
    "    self.tok_embedding = nn.Embedding(output_dim, hidden_dim)\n",
    "    self.pos_embedding = nn.Embedding(max_length, hidden_dim)\n",
    "\n",
    "    self.decoder_layers = nn.ModuleList([DecoderLayer(hidden_dim, n_heads, pf_dim, dropout_ratio, device) for _ in range(n_layers)])\n",
    "\n",
    "    self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    self.dropout = nn.Dropout(dropout_ratio)\n",
    "\n",
    "    self.scale = torch.sqrt(torch.FloatTensor([hidden_dim])).to(device)\n",
    "\n",
    "  def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "    # trg: [batch_size, trg_len]\n",
    "    # enc_src: [batch_size, src_len, hidden_dim]\n",
    "    # trg_mask: [batch_size, trg_len]\n",
    "    # src_mask: [batch_size, src_len]\n",
    "\n",
    "    batch_size = trg.shape[0]\n",
    "    trg_len = trg.shape[1]\n",
    "\n",
    "    # unsqueeze는 특정 위치에 1인 차원을 추가함.\n",
    "    # unsqueeze(0)는 첫번째 차원에 1인 차원을 추가함. [1 X trg_len]\n",
    "    # repeat 함수는 텐서를 반복 확장시켜줌.\n",
    "    # repeat(batch_size, 1)은 [1 X trg_len] 형태를 [batch_size, trg_len] 차원으로 만들어줌.\n",
    "    pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
    "\n",
    "    # pos : [batch_size, trg_len]\n",
    "\n",
    "    # 타겟 문장의 임베딩과 위치 임베딩을 더함. (Positional Encoding)\n",
    "    trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
    "\n",
    "    # trg: [batch_size, trg_len, hidden_dim]\n",
    "\n",
    "    # 모든 디코더 레이어를 거치며 순전파 수행\n",
    "    for layer in self.decoder_layers:\n",
    "      trg, attention = layer(trg, enc_src, trg_mask, src_mask) # 소스 마스크와 타겟 마스크 모두 사용\n",
    "\n",
    "    # trg: [batch_size, trg_len, hidden_dim]\n",
    "    # attention: [batch_size, n_heads, trg_len, src_len]\n",
    "\n",
    "    output = self.fc_out(trg)\n",
    "\n",
    "    # output: [batch_size, trg_len, output_dim]\n",
    "\n",
    "    return output, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1BSe_vRZZIY"
   },
   "source": [
    "## Transformer Model\n",
    "입력이 들어왔을 때 앞서 정의한 Encoder와 Decoder을 거쳐 출력 문장을 생성함.\n",
    "\n",
    "파라미터\n",
    "- encoder: encoder 객체\n",
    "- decoder: decoder 객체\n",
    "- src_pad_idx: 소스 문장의 패딩 문자 인덱스\n",
    "- trg_pad_idx: 타겟 문장의 패딩 문자 인덱스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "m5rahb6AZhok"
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "  def __init__(self, encoder, decoder, src_pad_idx, trg_pad_idx, device):\n",
    "    super().__init__()\n",
    "\n",
    "    self.encoder = encoder\n",
    "    self.decoder = decoder\n",
    "    #self.src_pad_idx = src_pad_idx\n",
    "    #self.trg_pad_idx = trg_pad_idx\n",
    "    self.padding_idx = src_pad_idx\n",
    "\n",
    "    self.device = device\n",
    "    '''\n",
    "      def make_padding_mask(self, q, k):\n",
    "        # q,k의 size = (batch_size, seq_len)\n",
    "        _, q_seq_len = q.size()\n",
    "        _, k_seq_len = k.size()\n",
    "    \n",
    "        q = q.ne(self.padding_idx)  # padding token을 0, 나머지를 1로 만들어줌\n",
    "        q = q.unsqueeze(1).unsqueeze(3) # (batch_size, 1, q_seq_len, 1)\n",
    "        q = q.repeat(1,1,1,k_seq_len)   # (batch_size, 1, q_seq_len, k_seq_len)\n",
    "    \n",
    "        k = k.ne(self.padding_idx)\n",
    "        k = k.unsqueeze(1).unsqueeze(2) # (batch_size, 1, 1, k_seq_len)\n",
    "        k = k.repeat(1,1,q_seq_len,1)   # (batch_size, 1, q_seq_len, k_seq_len)\n",
    "    \n",
    "        # and 연산\n",
    "        # (batch_size, 1, q_seq_len, k_seq_len)\n",
    "        mask = q & k\n",
    "    \n",
    "        return mask\n",
    "          \n",
    "      def make_look_ahead_mask(self, tgt):\n",
    "        _, seq_len = tgt.size()\n",
    "    \n",
    "        # torch.tril 함수를 사용하여 한칸씩 밀려나며 마스킹을 해줌\n",
    "        # (seq_len, seq_len)\n",
    "        mask = torch.tril(torch.ones(seq_len,seq_len)).type(torch.BoolTensor).to(self.device)\n",
    "    \n",
    "        return mask\n",
    "    '''\n",
    "  # 소스 문장의  토큰에 대하여 마스크(mask) 값을 0으로 설정\n",
    "  def create_src_mask(self, src):\n",
    "    #주어진 src에서 패딩 인덱스와 같지 않은 요소를 찾는다.\n",
    "    src_mask = torch.ne(src, self.padding_idx).unsqueeze(1).unsqueeze(2)\n",
    "    # src shape: (batch_size, seq_length)\n",
    "    # src_mask shape: (batch_size, 1, 1, seq_length)\n",
    "    return src_mask\n",
    "\n",
    "  # 타겟 문장에서 각 단어는 다음 단어가 무엇인지 알 수 없도록(이전 단어만 보도록) 만들기 위해 마스크를 사용\n",
    "  def create_tgt_mask(self, tgt):\n",
    "    \"\"\"\n",
    "    Pad Mask example\n",
    "        1 0 0 0 0\n",
    "        1 1 0 0 0\n",
    "        1 1 1 0 0\n",
    "        1 1 1 0 0\n",
    "        1 1 1 0 0\n",
    "    \"\"\"\n",
    "    tgt_pad_mask = torch.ne(tgt, self.padding_idx).unsqueeze(1).unsqueeze(3)\n",
    "    # tgt_pad_mask shape: (batch_size, 1, seq_length, 1)\n",
    "        \n",
    "    tgt_len = tgt.shape[1]\n",
    "    # torch.tril 함수는 주어진 텐서의 하삼각부분만을 유지하고 나머지를 0으로 만드는 함수입니다. \n",
    "    # 이를 이용하여 각 위치에서 자신과 이전 토큰만 \"볼 수 있는\" 마스크를 생성합니다. \n",
    "    \"\"\"\n",
    "    Sub Mask example\n",
    "        1 0 0 0 0\n",
    "        1 1 0 0 0\n",
    "        1 1 1 0 0\n",
    "        1 1 1 1 0\n",
    "        1 1 1 1 1\n",
    "        \"\"\"\n",
    "    tgt_sub_mask = torch.tril(torch.ones((tgt_len, tgt_len))).bool()\n",
    "    # tgt_sub_mask shape: (seq_length, seq_length)\n",
    "        \n",
    "    # 이 두 마스크를 합치면, 패딩 토큰과 미래 토큰 모두에 대한 마스크를 생성할 수 있습니다.\n",
    "    tgt_mask = tgt_pad_mask & tgt_sub_mask\n",
    "    # tgt_mask shape: (batch_size, 1, seq_length, seq_length)\n",
    "    return tgt_mask\n",
    "\n",
    "  def forward(self, src, trg):\n",
    "    # src: [batch_size, src_len]\n",
    "    # trg: [batch_size, trg_len]\n",
    "\n",
    "    src_mask = self.create_src_mask(src)\n",
    "    tgt_mask = self.create_tgt_mask(trg)\n",
    "\n",
    "    enc_src = self.encoder(src, src_mask)\n",
    "    # enc_src: [batch_size, src_len, hidden_dim]\n",
    "\n",
    "    output, attention = self.decoder(trg, enc_src, tgt_mask, src_mask)\n",
    "\n",
    "    # output: [batch_size, trg_len, otuput_dim]\n",
    "    # attention: [batch_size, n_heads, trg_len, src_len]\n",
    "\n",
    "    return output, attention\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RbKLabhmgErU"
   },
   "source": [
    "## Training (학습)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5p-kCLmmspl"
   },
   "source": [
    "### 하이퍼 파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "A9dXwLSDZj4p"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(vocab_transform[SRC_LANG])\n",
    "OUTPUT_DIM = len(vocab_transform[TGT_LANG])\n",
    "HIDDEN_DIM = 256\n",
    "ENC_LAYERS = 3\n",
    "DEC_LAYERS = 3\n",
    "ENC_HEADS = 8\n",
    "DEC_HEADS = 8\n",
    "ENC_PF_DIM = 512\n",
    "DEC_PF_DIM = 512\n",
    "ENC_DROPOUT = 0.1\n",
    "DEC_DROPOUT = 0.1\n",
    "\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xqGYQMamnjK"
   },
   "source": [
    "### 모델 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BAJbQwfsiM8I",
    "outputId": "8eddb74e-5d7f-462b-dbc2-5df7006aa9bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# 패딩 인덱스를 확인하기 위해 출력해본다.\n",
    "print(vocab_transform[SRC_LANG].lookup_indices(['<pad>']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "gpuMMWv1h7Q2"
   },
   "outputs": [],
   "source": [
    "SRC_PAD_IDX = vocab_transform[SRC_LANG].lookup_indices(['<pad>'])[0]\n",
    "TGT_PAD_IDX = vocab_transform[TGT_LANG].lookup_indices(['<pad>'])[0]\n",
    "\n",
    "# 인코더와 디코더 객체 선언\n",
    "enc = Encoder(INPUT_DIM, HIDDEN_DIM, ENC_LAYERS, ENC_HEADS, ENC_PF_DIM, ENC_DROPOUT, device)\n",
    "dec = Decoder(OUTPUT_DIM, HIDDEN_DIM, DEC_LAYERS, DEC_HEADS, DEC_PF_DIM, DEC_DROPOUT, device)\n",
    "\n",
    "# Transformer 객체 선언\n",
    "model = Transformer(enc, dec, SRC_PAD_IDX, TGT_PAD_IDX, device).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SH6p7N-FnGS3"
   },
   "source": [
    "### 모델 가중치 파라미터 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dLXaoHqsjp1k",
    "outputId": "1c87c0d2-679f-453a-d703-93da83d7ce61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 14,483,029 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rqcMJz4UnyXk",
    "outputId": "fe78fa99-48db-4ca5-d37d-2f3ab9134c56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): Encoder(\n",
       "    (tok_embedding): Embedding(19214, 256)\n",
       "    (pos_embedding): Embedding(100, 256)\n",
       "    (encoder_layers): ModuleList(\n",
       "      (0-2): 3 x EncoderLayer(\n",
       "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
       "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (tok_embedding): Embedding(10837, 256)\n",
       "    (pos_embedding): Embedding(100, 256)\n",
       "    (decoder_layers): ModuleList(\n",
       "      (0-2): 3 x DecoderLayer(\n",
       "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
       "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (fc_out): Linear(in_features=256, out_features=10837, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def initialize_weights(m):\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "        nn.init.xavier_uniform_(m.weight.data) # 가중치를 Xavier 값으로 초기화\n",
    "\n",
    "model.apply(initialize_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ih-oGnXtn8qg"
   },
   "source": [
    "### 학습 및 평가 함수 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PGuSujTzpTvh"
   },
   "source": [
    "optimizer는 Adam optimizer 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "P_1PEe_PpLWy"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "lr = 0.0005\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# 뒷 부분의 패딩에 대해서는 값 무시\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TGT_PAD_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDKQoU_lpoLe"
   },
   "source": [
    "모델 학습 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QEK93Pq_YX9Q",
    "outputId": "bef27e06-18b1-4be1-e136-5b7326617707"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "gW-VkN2jKTRz"
   },
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion, clip, device):\n",
    "  model.train()\n",
    "  epoch_loss = 0\n",
    "  running_loss = 0\n",
    "\n",
    "  for index, batch in enumerate(dataloader):\n",
    "    src = batch[0]\n",
    "    tgt = batch[1]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 출력 단어의 마지막 인덱스()는 제외\n",
    "    # 입력을 할 때는 부터 시작하도록 처리\n",
    "    output, _ = model(src, tgt[:,:-1])\n",
    "\n",
    "    # output: [배치 크기, tgt_len - 1, output_dim]\n",
    "    # trg: [배치 크기, tgt_len]\n",
    "\n",
    "    output_dim = output.shape[-1]\n",
    "\n",
    "    output = output.contiguous().view(-1, output_dim)\n",
    "    # 출력 단어의 인덱스 0()은 제외\n",
    "    tgt = tgt[:,1:].contiguous().view(-1)\n",
    "\n",
    "    # output: [배치 크기 * tgt_len - 1, output_dim]\n",
    "    # tgt: [배치 크기 * tgt_len - 1]\n",
    "\n",
    "    # 모델의 출력 결과와 타겟 문장을 비교하여 손실 계산\n",
    "    loss = criterion(output, tgt)\n",
    "    loss.backward() # 기울기(gradient) 계산\n",
    "\n",
    "    # 기울기(gradient) clipping 진행\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "    # 파라미터 업데이트\n",
    "    optimizer.step()\n",
    "\n",
    "    # 전체 손실 값 계산\n",
    "    epoch_loss += loss.item()\n",
    "\n",
    "    running_loss += (loss.item() - running_loss) / (index + 1)\n",
    "\n",
    "\n",
    "    print(f\"배치 인덱스 : {index}\\t|\\t이동 손실 : {running_loss}\")\n",
    "\n",
    "  return epoch_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "_9lXdn2eYgTK"
   },
   "outputs": [],
   "source": [
    "# 모델 평가(evaluate) 함수\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval() # 평가 모드\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # 전체 평가 데이터를 확인하며\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            src = batch[0].to(device)\n",
    "            tgt = batch[1].to(device)\n",
    "\n",
    "            # 출력 단어의 마지막 인덱스()는 제외\n",
    "            # 입력을 할 때는 부터 시작하도록 처리\n",
    "            output, _ = model(src, tgt[:,:-1])\n",
    "\n",
    "            # output: [배치 크기, trg_len - 1, output_dim]\n",
    "            # tgt: [배치 크기, tgt_len]\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "\n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            # 출력 단어의 인덱스 0()은 제외\n",
    "            tgt = tgt[:,1:].contiguous().view(-1)\n",
    "\n",
    "            # output: [배치 크기 * trg_len - 1, output_dim]\n",
    "            # tgt: [배치 크기 * tgt_len - 1]\n",
    "\n",
    "            # 모델의 출력 결과와 타겟 문장을 비교하여 손실 계산\n",
    "            loss = criterion(output, tgt)\n",
    "\n",
    "            # 전체 손실 값 계산\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "ckMu93wrYp-W"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uWP6bMABYryG",
    "outputId": "9ea5e144-853d-4785-e055-cd9d4b370951"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에폭 : 0\n",
      "배치 인덱스 : 0\t|\t이동 손실 : 9.296615600585938\n",
      "배치 인덱스 : 1\t|\t이동 손실 : 9.13586139678955\n",
      "배치 인덱스 : 2\t|\t이동 손실 : 9.02352492014567\n",
      "배치 인덱스 : 3\t|\t이동 손실 : 8.931631326675415\n",
      "배치 인덱스 : 4\t|\t이동 손실 : 8.846220207214355\n",
      "배치 인덱스 : 5\t|\t이동 손실 : 8.765840371449787\n",
      "배치 인덱스 : 6\t|\t이동 손실 : 8.684893063136508\n",
      "배치 인덱스 : 7\t|\t이동 손실 : 8.607539057731627\n",
      "배치 인덱스 : 8\t|\t이동 손실 : 8.534253226386175\n",
      "배치 인덱스 : 9\t|\t이동 손실 : 8.459963512420654\n",
      "배치 인덱스 : 10\t|\t이동 손실 : 8.3844237761064\n",
      "배치 인덱스 : 11\t|\t이동 손실 : 8.311448017756144\n",
      "배치 인덱스 : 12\t|\t이동 손실 : 8.239567793332613\n",
      "배치 인덱스 : 13\t|\t이동 손실 : 8.170863900865827\n",
      "배치 인덱스 : 14\t|\t이동 손실 : 8.098766104380289\n",
      "배치 인덱스 : 15\t|\t이동 손실 : 8.02803549170494\n",
      "배치 인덱스 : 16\t|\t이동 손실 : 7.962239882525275\n",
      "배치 인덱스 : 17\t|\t이동 손실 : 7.895158025953505\n",
      "배치 인덱스 : 18\t|\t이동 손실 : 7.828265441091437\n",
      "배치 인덱스 : 19\t|\t이동 손실 : 7.763408851623535\n",
      "배치 인덱스 : 20\t|\t이동 손실 : 7.696690286908831\n",
      "배치 인덱스 : 21\t|\t이동 손실 : 7.635224754160101\n",
      "배치 인덱스 : 22\t|\t이동 손실 : 7.5745047900987705\n",
      "배치 인덱스 : 23\t|\t이동 손실 : 7.514798879623413\n",
      "배치 인덱스 : 24\t|\t이동 손실 : 7.458246326446533\n",
      "배치 인덱스 : 25\t|\t이동 손실 : 7.401129099038931\n",
      "배치 인덱스 : 26\t|\t이동 손실 : 7.342460279111509\n",
      "배치 인덱스 : 27\t|\t이동 손실 : 7.287446158272879\n",
      "배치 인덱스 : 28\t|\t이동 손실 : 7.234322317715349\n",
      "배치 인덱스 : 29\t|\t이동 손실 : 7.180607875188191\n",
      "배치 인덱스 : 30\t|\t이동 손실 : 7.130167745774791\n",
      "배치 인덱스 : 31\t|\t이동 손실 : 7.08471593260765\n",
      "배치 인덱스 : 32\t|\t이동 손실 : 7.038659283609101\n",
      "배치 인덱스 : 33\t|\t이동 손실 : 6.991764910080853\n",
      "배치 인덱스 : 34\t|\t이동 손실 : 6.9504364831107\n",
      "배치 인덱스 : 35\t|\t이동 손실 : 6.907337374157375\n",
      "배치 인덱스 : 36\t|\t이동 손실 : 6.868136251294935\n",
      "배치 인덱스 : 37\t|\t이동 손실 : 6.8269722963634285\n",
      "배치 인덱스 : 38\t|\t이동 손실 : 6.789797244927821\n",
      "배치 인덱스 : 39\t|\t이동 손실 : 6.751314032077788\n",
      "배치 인덱스 : 40\t|\t이동 손실 : 6.716757088172725\n",
      "배치 인덱스 : 41\t|\t이동 손실 : 6.680028336388723\n",
      "배치 인덱스 : 42\t|\t이동 손실 : 6.645021194635435\n",
      "배치 인덱스 : 43\t|\t이동 손실 : 6.610544605688615\n",
      "배치 인덱스 : 44\t|\t이동 손실 : 6.578685908847384\n",
      "배치 인덱스 : 45\t|\t이동 손실 : 6.547085637631623\n",
      "배치 인덱스 : 46\t|\t이동 손실 : 6.515875796054272\n",
      "배치 인덱스 : 47\t|\t이동 손실 : 6.482993384202321\n",
      "배치 인덱스 : 48\t|\t이동 손실 : 6.452953951699393\n",
      "배치 인덱스 : 49\t|\t이동 손실 : 6.424494647979736\n",
      "배치 인덱스 : 50\t|\t이동 손실 : 6.395887103735231\n",
      "배치 인덱스 : 51\t|\t이동 손실 : 6.366095506227933\n",
      "배치 인덱스 : 52\t|\t이동 손실 : 6.339791351894163\n",
      "배치 인덱스 : 53\t|\t이동 손실 : 6.310689175570452\n",
      "배치 인덱스 : 54\t|\t이동 손실 : 6.283576367118141\n",
      "배치 인덱스 : 55\t|\t이동 손실 : 6.255933676447187\n",
      "배치 인덱스 : 56\t|\t이동 손실 : 6.230590694829037\n",
      "배치 인덱스 : 57\t|\t이동 손실 : 6.2039677027998295\n",
      "배치 인덱스 : 58\t|\t이동 손실 : 6.178807436409643\n",
      "배치 인덱스 : 59\t|\t이동 손실 : 6.154102269808451\n",
      "배치 인덱스 : 60\t|\t이동 손실 : 6.12939872116339\n",
      "배치 인덱스 : 61\t|\t이동 손실 : 6.105518725610548\n",
      "배치 인덱스 : 62\t|\t이동 손실 : 6.081656879848904\n",
      "배치 인덱스 : 63\t|\t이동 손실 : 6.060139894485474\n",
      "배치 인덱스 : 64\t|\t이동 손실 : 6.03799707706158\n",
      "배치 인덱스 : 65\t|\t이동 손실 : 6.015091267499057\n",
      "배치 인덱스 : 66\t|\t이동 손실 : 5.992668899137582\n",
      "배치 인덱스 : 67\t|\t이동 손실 : 5.9704209075254555\n",
      "배치 인덱스 : 68\t|\t이동 손실 : 5.9488738377889\n",
      "배치 인덱스 : 69\t|\t이동 손실 : 5.927755042484829\n",
      "배치 인덱스 : 70\t|\t이동 손실 : 5.906319268992251\n",
      "배치 인덱스 : 71\t|\t이동 손실 : 5.885102331638337\n",
      "배치 인덱스 : 72\t|\t이동 손실 : 5.864225211208815\n",
      "배치 인덱스 : 73\t|\t이동 손실 : 5.844302518947706\n",
      "배치 인덱스 : 74\t|\t이동 손실 : 5.825208129882814\n",
      "배치 인덱스 : 75\t|\t이동 손실 : 5.8062078952789316\n",
      "배치 인덱스 : 76\t|\t이동 손실 : 5.7883302267495695\n",
      "배치 인덱스 : 77\t|\t이동 손실 : 5.767774600249071\n",
      "배치 인덱스 : 78\t|\t이동 손실 : 5.749410104147996\n",
      "배치 인덱스 : 79\t|\t이동 손실 : 5.732251554727555\n",
      "배치 인덱스 : 80\t|\t이동 손실 : 5.715050921028044\n",
      "배치 인덱스 : 81\t|\t이동 손실 : 5.697263932809598\n",
      "배치 인덱스 : 82\t|\t이동 손실 : 5.679813936532263\n",
      "배치 인덱스 : 83\t|\t이동 손실 : 5.66335259732746\n",
      "배치 인덱스 : 84\t|\t이동 손실 : 5.649182734769934\n",
      "배치 인덱스 : 85\t|\t이동 손실 : 5.632675808529522\n",
      "배치 인덱스 : 86\t|\t이동 손실 : 5.615943316755625\n",
      "배치 인덱스 : 87\t|\t이동 손실 : 5.601986028931359\n",
      "배치 인덱스 : 88\t|\t이동 손실 : 5.586021809095748\n",
      "배치 인덱스 : 89\t|\t이동 손실 : 5.568999979231094\n",
      "배치 인덱스 : 90\t|\t이동 손실 : 5.553887131449942\n",
      "배치 인덱스 : 91\t|\t이동 손실 : 5.539721587429877\n",
      "배치 인덱스 : 92\t|\t이동 손실 : 5.525758594594977\n",
      "배치 인덱스 : 93\t|\t이동 손실 : 5.511755441097504\n",
      "배치 인덱스 : 94\t|\t이동 손실 : 5.49585623992117\n",
      "배치 인덱스 : 95\t|\t이동 손실 : 5.481738472978275\n",
      "배치 인덱스 : 96\t|\t이동 손실 : 5.46788495348901\n",
      "배치 인덱스 : 97\t|\t이동 손실 : 5.45335093809634\n",
      "배치 인덱스 : 98\t|\t이동 손실 : 5.439365319531374\n",
      "배치 인덱스 : 99\t|\t이동 손실 : 5.426343712806703\n",
      "배치 인덱스 : 100\t|\t이동 손실 : 5.414583069263119\n",
      "배치 인덱스 : 101\t|\t이동 손실 : 5.401366785460828\n",
      "배치 인덱스 : 102\t|\t이동 손실 : 5.389192428403689\n",
      "배치 인덱스 : 103\t|\t이동 손실 : 5.377032917279465\n",
      "배치 인덱스 : 104\t|\t이동 손실 : 5.365328407287599\n",
      "배치 인덱스 : 105\t|\t이동 손실 : 5.35354933198893\n",
      "배치 인덱스 : 106\t|\t이동 손실 : 5.341275879155811\n",
      "배치 인덱스 : 107\t|\t이동 손실 : 5.329756034745111\n",
      "배치 인덱스 : 108\t|\t이동 손실 : 5.3178325486839375\n",
      "배치 인덱스 : 109\t|\t이동 손실 : 5.304683188958602\n",
      "배치 인덱스 : 110\t|\t이동 손실 : 5.292940580093109\n",
      "배치 인덱스 : 111\t|\t이동 손실 : 5.28182695380279\n",
      "배치 인덱스 : 112\t|\t이동 손실 : 5.271246051366351\n",
      "배치 인덱스 : 113\t|\t이동 손실 : 5.260499864293818\n",
      "배치 인덱스 : 114\t|\t이동 손실 : 5.249825023568195\n",
      "배치 인덱스 : 115\t|\t이동 손실 : 5.2388374394383925\n",
      "배치 인덱스 : 116\t|\t이동 손실 : 5.227821132056734\n",
      "배치 인덱스 : 117\t|\t이동 손실 : 5.216795729378523\n",
      "배치 인덱스 : 118\t|\t이동 손실 : 5.2060578410365\n",
      "배치 인덱스 : 119\t|\t이동 손실 : 5.195630005995433\n",
      "배치 인덱스 : 120\t|\t이동 손실 : 5.1844840897016296\n",
      "배치 인덱스 : 121\t|\t이동 손실 : 5.173997478406938\n",
      "배치 인덱스 : 122\t|\t이동 손실 : 5.164580804545706\n",
      "배치 인덱스 : 123\t|\t이동 손실 : 5.154387391382649\n",
      "배치 인덱스 : 124\t|\t이동 손실 : 5.143791397094727\n",
      "배치 인덱스 : 125\t|\t이동 손실 : 5.135120403198969\n",
      "배치 인덱스 : 126\t|\t이동 손실 : 5.126743230294055\n",
      "배치 인덱스 : 127\t|\t이동 손실 : 5.117377998307347\n",
      "배치 인덱스 : 128\t|\t이동 손실 : 5.106765551160472\n",
      "배치 인덱스 : 129\t|\t이동 손실 : 5.097516199258657\n",
      "배치 인덱스 : 130\t|\t이동 손실 : 5.086771562809252\n",
      "배치 인덱스 : 131\t|\t이동 손실 : 5.076687856154008\n",
      "배치 인덱스 : 132\t|\t이동 손실 : 5.067191509375895\n",
      "배치 인덱스 : 133\t|\t이동 손실 : 5.057260077391097\n",
      "배치 인덱스 : 134\t|\t이동 손실 : 5.048694184974387\n",
      "배치 인덱스 : 135\t|\t이동 손실 : 5.040034534300074\n",
      "배치 인덱스 : 136\t|\t이동 손실 : 5.031319021308508\n",
      "배치 인덱스 : 137\t|\t이동 손실 : 5.02174951719201\n",
      "배치 인덱스 : 138\t|\t이동 손실 : 5.01304214463817\n",
      "배치 인덱스 : 139\t|\t이동 손실 : 5.004226839542388\n",
      "배치 인덱스 : 140\t|\t이동 손실 : 4.995550128585057\n",
      "배치 인덱스 : 141\t|\t이동 손실 : 4.9876994566178645\n",
      "배치 인덱스 : 142\t|\t이동 손실 : 4.980033359327515\n",
      "배치 인덱스 : 143\t|\t이동 손실 : 4.972057971689435\n",
      "배치 인덱스 : 144\t|\t이동 손실 : 4.963642367001237\n",
      "배치 인덱스 : 145\t|\t이동 손실 : 4.955965409540149\n",
      "배치 인덱스 : 146\t|\t이동 손실 : 4.947344947023455\n",
      "배치 인덱스 : 147\t|\t이동 손실 : 4.938389418898401\n",
      "배치 인덱스 : 148\t|\t이동 손실 : 4.931525632039012\n",
      "배치 인덱스 : 149\t|\t이동 손실 : 4.9226243829727165\n",
      "배치 인덱스 : 150\t|\t이동 손실 : 4.915383188929778\n",
      "배치 인덱스 : 151\t|\t이동 손실 : 4.907734525831121\n",
      "배치 인덱스 : 152\t|\t이동 손실 : 4.899041244407105\n",
      "배치 인덱스 : 153\t|\t이동 손실 : 4.8924231420863755\n",
      "배치 인덱스 : 154\t|\t이동 손실 : 4.885532885213052\n",
      "배치 인덱스 : 155\t|\t이동 손실 : 4.877654809218186\n",
      "배치 인덱스 : 156\t|\t이동 손실 : 4.871497293946089\n",
      "배치 인덱스 : 157\t|\t이동 손실 : 4.864027559002743\n",
      "배치 인덱스 : 158\t|\t이동 손실 : 4.856578922871523\n",
      "배치 인덱스 : 159\t|\t이동 손실 : 4.849023805558681\n",
      "배치 인덱스 : 160\t|\t이동 손실 : 4.842445047745793\n",
      "배치 인덱스 : 161\t|\t이동 손실 : 4.835577966254434\n",
      "배치 인덱스 : 162\t|\t이동 손실 : 4.828456549556708\n",
      "배치 인덱스 : 163\t|\t이동 손실 : 4.821085357084506\n",
      "배치 인덱스 : 164\t|\t이동 손실 : 4.814822506182121\n",
      "배치 인덱스 : 165\t|\t이동 손실 : 4.807264293532773\n",
      "배치 인덱스 : 166\t|\t이동 손실 : 4.800421828995208\n",
      "배치 인덱스 : 167\t|\t이동 손실 : 4.793320058357148\n",
      "배치 인덱스 : 168\t|\t이동 손실 : 4.7874391798437\n",
      "배치 인덱스 : 169\t|\t이동 손실 : 4.780224950173323\n",
      "배치 인덱스 : 170\t|\t이동 손실 : 4.773674150656539\n",
      "배치 인덱스 : 171\t|\t이동 손실 : 4.766810791437017\n",
      "배치 인덱스 : 172\t|\t이동 손실 : 4.759608978480963\n",
      "배치 인덱스 : 173\t|\t이동 손실 : 4.753188157903738\n",
      "배치 인덱스 : 174\t|\t이동 손실 : 4.7474977316175195\n",
      "배치 인덱스 : 175\t|\t이동 손실 : 4.739874450997873\n",
      "배치 인덱스 : 176\t|\t이동 손실 : 4.733637533618906\n",
      "배치 인덱스 : 177\t|\t이동 손실 : 4.726809648985274\n",
      "배치 인덱스 : 178\t|\t이동 손실 : 4.720565994358596\n",
      "배치 인덱스 : 179\t|\t이동 손실 : 4.714551421006521\n",
      "배치 인덱스 : 180\t|\t이동 손실 : 4.708184758602585\n",
      "배치 인덱스 : 181\t|\t이동 손실 : 4.702267790888692\n",
      "배치 인덱스 : 182\t|\t이동 손실 : 4.696132041066071\n",
      "배치 인덱스 : 183\t|\t이동 손실 : 4.69010784574177\n",
      "배치 인덱스 : 184\t|\t이동 손실 : 4.683311182743795\n",
      "배치 인덱스 : 185\t|\t이동 손실 : 4.6773508697427735\n",
      "배치 인덱스 : 186\t|\t이동 손실 : 4.671964173648448\n",
      "배치 인덱스 : 187\t|\t이동 손실 : 4.6661501121013735\n",
      "배치 인덱스 : 188\t|\t이동 손실 : 4.660119605442835\n",
      "배치 인덱스 : 189\t|\t이동 손실 : 4.653651798398872\n",
      "배치 인덱스 : 190\t|\t이동 손실 : 4.647713440250977\n",
      "배치 인덱스 : 191\t|\t이동 손실 : 4.64177607993285\n",
      "배치 인덱스 : 192\t|\t이동 손실 : 4.636436023860399\n",
      "배치 인덱스 : 193\t|\t이동 손실 : 4.631026668646902\n",
      "배치 인덱스 : 194\t|\t이동 손실 : 4.624596253419535\n",
      "배치 인덱스 : 195\t|\t이동 손실 : 4.619085532061908\n",
      "배치 인덱스 : 196\t|\t이동 손실 : 4.614004337243018\n",
      "배치 인덱스 : 197\t|\t이동 손실 : 4.608027119829198\n",
      "배치 인덱스 : 198\t|\t이동 손실 : 4.602427824058725\n",
      "배치 인덱스 : 199\t|\t이동 손실 : 4.597049543857575\n",
      "배치 인덱스 : 200\t|\t이동 손실 : 4.591739629631612\n",
      "배치 인덱스 : 201\t|\t이동 손실 : 4.586604447648077\n",
      "배치 인덱스 : 202\t|\t이동 손실 : 4.580593499056812\n",
      "배치 인덱스 : 203\t|\t이동 손실 : 4.575101070544299\n",
      "배치 인덱스 : 204\t|\t이동 손실 : 4.568543729549502\n",
      "배치 인덱스 : 205\t|\t이동 손실 : 4.563673894382219\n",
      "배치 인덱스 : 206\t|\t이동 손실 : 4.559206657363598\n",
      "배치 인덱스 : 207\t|\t이동 손실 : 4.5544702399235515\n",
      "배치 인덱스 : 208\t|\t이동 손실 : 4.549688407678924\n",
      "배치 인덱스 : 209\t|\t이동 손실 : 4.5445447342736385\n",
      "배치 인덱스 : 210\t|\t이동 손실 : 4.540074642235634\n",
      "배치 인덱스 : 211\t|\t이동 손실 : 4.534782136386296\n",
      "배치 인덱스 : 212\t|\t이동 손실 : 4.529972033881246\n",
      "배치 인덱스 : 213\t|\t이동 손실 : 4.525748256210969\n",
      "배치 인덱스 : 214\t|\t이동 손실 : 4.520524684772935\n",
      "배치 인덱스 : 215\t|\t이동 손실 : 4.515973421158614\n",
      "배치 인덱스 : 216\t|\t이동 손실 : 4.51147094739747\n",
      "배치 인덱스 : 217\t|\t이동 손실 : 4.50619789001045\n",
      "배치 인덱스 : 218\t|\t이동 손실 : 4.500816006638689\n",
      "배치 인덱스 : 219\t|\t이동 손실 : 4.495873792604968\n",
      "배치 인덱스 : 220\t|\t이동 손실 : 4.490798812106725\n",
      "배치 인덱스 : 221\t|\t이동 손실 : 4.4863251619510836\n",
      "배치 인덱스 : 222\t|\t이동 손실 : 4.482055531488942\n",
      "배치 인덱스 : 223\t|\t이동 손실 : 4.477422458784922\n",
      "배치 인덱스 : 224\t|\t이동 손실 : 4.47256192525228\n",
      "배치 인덱스 : 225\t|\t이동 손실 : 4.4679314193472415\n",
      "배치 인덱스 : 226\t|\t이동 손실 : 4.462707393494998\n",
      "Epoch: 01 | Time: 15m 21s\n",
      "\tTrain Loss: 4.463 | Train PPL: 86.722\n",
      "\tValidation Loss: 3.295 | Validation PPL: 26.987\n",
      "에폭 : 1\n",
      "배치 인덱스 : 0\t|\t이동 손실 : 3.2153139114379883\n",
      "배치 인덱스 : 1\t|\t이동 손실 : 3.3026927709579468\n",
      "배치 인덱스 : 2\t|\t이동 손실 : 3.2874866326649985\n",
      "배치 인덱스 : 3\t|\t이동 손실 : 3.2898709774017334\n",
      "배치 인덱스 : 4\t|\t이동 손실 : 3.308212995529175\n",
      "배치 인덱스 : 5\t|\t이동 손실 : 3.293761054674784\n",
      "배치 인덱스 : 6\t|\t이동 손실 : 3.285257271357945\n",
      "배치 인덱스 : 7\t|\t이동 손실 : 3.2555296421051025\n",
      "배치 인덱스 : 8\t|\t이동 손실 : 3.240210771560669\n",
      "배치 인덱스 : 9\t|\t이동 손실 : 3.2463098764419556\n",
      "배치 인덱스 : 10\t|\t이동 손실 : 3.237537210637873\n",
      "배치 인덱스 : 11\t|\t이동 손실 : 3.2409966985384626\n",
      "배치 인덱스 : 12\t|\t이동 손실 : 3.244394614146306\n",
      "배치 인덱스 : 13\t|\t이동 손실 : 3.2477435043879916\n",
      "배치 인덱스 : 14\t|\t이동 손실 : 3.2303921699523923\n",
      "배치 인덱스 : 15\t|\t이동 손실 : 3.2282074540853496\n",
      "배치 인덱스 : 16\t|\t이동 손실 : 3.227351076462689\n",
      "배치 인덱스 : 17\t|\t이동 손실 : 3.224485596021016\n",
      "배치 인덱스 : 18\t|\t이동 손실 : 3.2241564675381307\n",
      "배치 인덱스 : 19\t|\t이동 손실 : 3.2217681050300597\n",
      "배치 인덱스 : 20\t|\t이동 손실 : 3.2166066964467364\n",
      "배치 인덱스 : 21\t|\t이동 손실 : 3.21672435240312\n",
      "배치 인덱스 : 22\t|\t이동 손실 : 3.2127459671186362\n",
      "배치 인덱스 : 23\t|\t이동 손실 : 3.208330323298772\n",
      "배치 인덱스 : 24\t|\t이동 손실 : 3.2153370380401607\n",
      "배치 인덱스 : 25\t|\t이동 손실 : 3.2130483755698567\n",
      "배치 인덱스 : 26\t|\t이동 손실 : 3.2145266532897945\n",
      "배치 인덱스 : 27\t|\t이동 손실 : 3.212164529732295\n",
      "배치 인덱스 : 28\t|\t이동 손실 : 3.2107804150416928\n",
      "배치 인덱스 : 29\t|\t이동 손실 : 3.211452651023864\n",
      "배치 인덱스 : 30\t|\t이동 손실 : 3.20976331157069\n",
      "배치 인덱스 : 31\t|\t이동 손실 : 3.20378291606903\n",
      "배치 인덱스 : 32\t|\t이동 손실 : 3.202860622694997\n",
      "배치 인덱스 : 33\t|\t이동 손실 : 3.2061794785892253\n",
      "배치 인덱스 : 34\t|\t이동 손실 : 3.197290052686418\n",
      "배치 인덱스 : 35\t|\t이동 손실 : 3.1942481067445536\n",
      "배치 인덱스 : 36\t|\t이동 손실 : 3.192122433636639\n",
      "배치 인덱스 : 37\t|\t이동 손실 : 3.1910592129355977\n",
      "배치 인덱스 : 38\t|\t이동 손실 : 3.1863834307743946\n",
      "배치 인덱스 : 39\t|\t이동 손실 : 3.1833590388298028\n",
      "배치 인덱스 : 40\t|\t이동 손실 : 3.183893814319517\n",
      "배치 인덱스 : 41\t|\t이동 손실 : 3.1855330864588414\n",
      "배치 인덱스 : 42\t|\t이동 손실 : 3.1878575114316714\n",
      "배치 인덱스 : 43\t|\t이동 손실 : 3.184984131292863\n",
      "배치 인덱스 : 44\t|\t이동 손실 : 3.182164022657606\n",
      "배치 인덱스 : 45\t|\t이동 손실 : 3.18078965726106\n",
      "배치 인덱스 : 46\t|\t이동 손실 : 3.181817977986437\n",
      "배치 인덱스 : 47\t|\t이동 손실 : 3.181964149077733\n",
      "배치 인덱스 : 48\t|\t이동 손실 : 3.182912714627324\n",
      "배치 인덱스 : 49\t|\t이동 손실 : 3.1812206935882563\n",
      "배치 인덱스 : 50\t|\t이동 손실 : 3.177515343123791\n",
      "배치 인덱스 : 51\t|\t이동 손실 : 3.1734076325709997\n",
      "배치 인덱스 : 52\t|\t이동 손실 : 3.171012253131506\n",
      "배치 인덱스 : 53\t|\t이동 손실 : 3.1672384827225293\n",
      "배치 인덱스 : 54\t|\t이동 손실 : 3.164319428530606\n",
      "배치 인덱스 : 55\t|\t이동 손실 : 3.163167855569294\n",
      "배치 인덱스 : 56\t|\t이동 손실 : 3.159545262654622\n",
      "배치 인덱스 : 57\t|\t이동 손실 : 3.1573458581135188\n",
      "배치 인덱스 : 58\t|\t이동 손실 : 3.1558254815764344\n",
      "배치 인덱스 : 59\t|\t이동 손실 : 3.154171061515808\n",
      "배치 인덱스 : 60\t|\t이동 손실 : 3.1510538781275512\n",
      "배치 인덱스 : 61\t|\t이동 손실 : 3.1495142829033633\n",
      "배치 인덱스 : 62\t|\t이동 손실 : 3.1472957172091043\n",
      "배치 인덱스 : 63\t|\t이동 손실 : 3.145757082849741\n",
      "배치 인덱스 : 64\t|\t이동 손실 : 3.1467477615063006\n",
      "배치 인덱스 : 65\t|\t이동 손실 : 3.1448844273885093\n",
      "배치 인덱스 : 66\t|\t이동 손실 : 3.1428929407205155\n",
      "배치 인덱스 : 67\t|\t이동 손실 : 3.1419762232724358\n",
      "배치 인덱스 : 68\t|\t이동 손실 : 3.1397086952043614\n",
      "배치 인덱스 : 69\t|\t이동 손실 : 3.138301004682268\n",
      "배치 인덱스 : 70\t|\t이동 손실 : 3.1374546306234006\n",
      "배치 인덱스 : 71\t|\t이동 손실 : 3.1359222630659733\n",
      "배치 인덱스 : 72\t|\t이동 손실 : 3.135814065802587\n",
      "배치 인덱스 : 73\t|\t이동 손실 : 3.1327051955300402\n",
      "배치 인덱스 : 74\t|\t이동 손실 : 3.1303086916605625\n",
      "배치 인덱스 : 75\t|\t이동 손실 : 3.1299412093664465\n",
      "배치 인덱스 : 76\t|\t이동 손실 : 3.12756805296068\n",
      "배치 인덱스 : 77\t|\t이동 손실 : 3.125021903942792\n",
      "배치 인덱스 : 78\t|\t이동 손실 : 3.123968127407604\n",
      "배치 인덱스 : 79\t|\t이동 손실 : 3.1218086779117575\n",
      "배치 인덱스 : 80\t|\t이동 손실 : 3.1206125653820265\n",
      "배치 인덱스 : 81\t|\t이동 손실 : 3.1190146731167294\n",
      "배치 인덱스 : 82\t|\t이동 손실 : 3.118262865457189\n",
      "배치 인덱스 : 83\t|\t이동 손실 : 3.1171530683835336\n",
      "배치 인덱스 : 84\t|\t이동 손실 : 3.1159003706539368\n",
      "배치 인덱스 : 85\t|\t이동 손실 : 3.11426930372105\n",
      "배치 인덱스 : 86\t|\t이동 손실 : 3.111411198802377\n",
      "배치 인덱스 : 87\t|\t이동 손실 : 3.1088395335457535\n",
      "배치 인덱스 : 88\t|\t이동 손실 : 3.1064931060490975\n",
      "배치 인덱스 : 89\t|\t이동 손실 : 3.105324379603067\n",
      "배치 인덱스 : 90\t|\t이동 손실 : 3.104049792656531\n",
      "배치 인덱스 : 91\t|\t이동 손실 : 3.102025197899859\n",
      "배치 인덱스 : 92\t|\t이동 손실 : 3.0998079494763435\n",
      "배치 인덱스 : 93\t|\t이동 손실 : 3.0979939952809747\n",
      "배치 인덱스 : 94\t|\t이동 손실 : 3.097473681600469\n",
      "배치 인덱스 : 95\t|\t이동 손실 : 3.0954352592428513\n",
      "배치 인덱스 : 96\t|\t이동 손실 : 3.0935548679115836\n",
      "배치 인덱스 : 97\t|\t이동 손실 : 3.092189346040997\n",
      "배치 인덱스 : 98\t|\t이동 손실 : 3.0921894829682617\n",
      "배치 인덱스 : 99\t|\t이동 손실 : 3.089743192195891\n",
      "배치 인덱스 : 100\t|\t이동 손실 : 3.0886303056584716\n",
      "배치 인덱스 : 101\t|\t이동 손실 : 3.087952202441645\n",
      "배치 인덱스 : 102\t|\t이동 손실 : 3.087218307754368\n",
      "배치 인덱스 : 103\t|\t이동 손실 : 3.0855815594012914\n",
      "배치 인덱스 : 104\t|\t이동 손실 : 3.0849395502181274\n",
      "배치 인덱스 : 105\t|\t이동 손실 : 3.081804190041883\n",
      "배치 인덱스 : 106\t|\t이동 손실 : 3.0805730708291588\n",
      "배치 인덱스 : 107\t|\t이동 손실 : 3.0793613062964535\n",
      "배치 인덱스 : 108\t|\t이동 손실 : 3.076876248788395\n",
      "배치 인덱스 : 109\t|\t이동 손실 : 3.0744586619463825\n",
      "배치 인덱스 : 110\t|\t이동 손실 : 3.0727915828292427\n",
      "배치 인덱스 : 111\t|\t이동 손실 : 3.0708235182932437\n",
      "배치 인덱스 : 112\t|\t이동 손실 : 3.0686466187502424\n",
      "배치 인덱스 : 113\t|\t이동 손실 : 3.0675159797333826\n",
      "배치 인덱스 : 114\t|\t이동 손실 : 3.0652580489283014\n",
      "배치 인덱스 : 115\t|\t이동 손실 : 3.063838742930313\n",
      "배치 인덱스 : 116\t|\t이동 손실 : 3.0624935137919884\n",
      "배치 인덱스 : 117\t|\t이동 손실 : 3.061620190992193\n",
      "배치 인덱스 : 118\t|\t이동 손실 : 3.0596498260978886\n",
      "배치 인덱스 : 119\t|\t이동 손실 : 3.0566293259461714\n",
      "배치 인덱스 : 120\t|\t이동 손실 : 3.056099954715444\n",
      "배치 인덱스 : 121\t|\t이동 손실 : 3.0549933519519734\n",
      "배치 인덱스 : 122\t|\t이동 손실 : 3.052810544890116\n",
      "배치 인덱스 : 123\t|\t이동 손실 : 3.051441969410065\n",
      "배치 인덱스 : 124\t|\t이동 손실 : 3.0493163719177243\n",
      "배치 인덱스 : 125\t|\t이동 손실 : 3.0472087065378823\n",
      "배치 인덱스 : 126\t|\t이동 손실 : 3.0450272466254047\n",
      "배치 인덱스 : 127\t|\t이동 손실 : 3.0430318024009466\n",
      "배치 인덱스 : 128\t|\t이동 손실 : 3.0412673377251442\n",
      "배치 인덱스 : 129\t|\t이동 손실 : 3.040014327489413\n",
      "배치 인덱스 : 130\t|\t이동 손실 : 3.0384572862668806\n",
      "배치 인덱스 : 131\t|\t이동 손실 : 3.0359330791415595\n",
      "배치 인덱스 : 132\t|\t이동 손실 : 3.0346884637846987\n",
      "배치 인덱스 : 133\t|\t이동 손실 : 3.033363100308091\n",
      "배치 인덱스 : 134\t|\t이동 손실 : 3.0319208145141605\n",
      "배치 인덱스 : 135\t|\t이동 손실 : 3.030329721815446\n",
      "배치 인덱스 : 136\t|\t이동 손실 : 3.028516609303273\n",
      "배치 인덱스 : 137\t|\t이동 손실 : 3.027044408563255\n",
      "배치 인덱스 : 138\t|\t이동 손실 : 3.024293565064026\n",
      "배치 인덱스 : 139\t|\t이동 손실 : 3.02276566028595\n",
      "배치 인덱스 : 140\t|\t이동 손실 : 3.02157839477485\n",
      "배치 인덱스 : 141\t|\t이동 손실 : 3.020789571211372\n",
      "배치 인덱스 : 142\t|\t이동 손실 : 3.019272847609087\n",
      "배치 인덱스 : 143\t|\t이동 손실 : 3.016657282908758\n",
      "배치 인덱스 : 144\t|\t이동 손실 : 3.0153368456610323\n",
      "배치 인덱스 : 145\t|\t이동 손실 : 3.013824879306637\n",
      "배치 인덱스 : 146\t|\t이동 손실 : 3.011996001613384\n",
      "배치 인덱스 : 147\t|\t이동 손실 : 3.010192210609849\n",
      "배치 인덱스 : 148\t|\t이동 손실 : 3.0081015721263507\n",
      "배치 인덱스 : 149\t|\t이동 손실 : 3.0077980327606206\n",
      "배치 인덱스 : 150\t|\t이동 손실 : 3.005234737269926\n",
      "배치 인덱스 : 151\t|\t이동 손실 : 3.0048846116191466\n",
      "배치 인덱스 : 152\t|\t이동 손실 : 3.003610928853353\n",
      "배치 인덱스 : 153\t|\t이동 손실 : 3.0015710344562283\n",
      "배치 인덱스 : 154\t|\t이동 손실 : 3.0001100663215885\n",
      "배치 인덱스 : 155\t|\t이동 손실 : 2.998503104234353\n",
      "배치 인덱스 : 156\t|\t이동 손실 : 2.997698622904006\n",
      "배치 인덱스 : 157\t|\t이동 손실 : 2.995928874498681\n",
      "배치 인덱스 : 158\t|\t이동 손실 : 2.9936710723541067\n",
      "배치 인덱스 : 159\t|\t이동 손실 : 2.992901648581028\n",
      "배치 인덱스 : 160\t|\t이동 손실 : 2.9912571048144225\n",
      "배치 인덱스 : 161\t|\t이동 손실 : 2.990727052276517\n",
      "배치 인덱스 : 162\t|\t이동 손실 : 2.989724051001613\n",
      "배치 인덱스 : 163\t|\t이동 손실 : 2.988121666559359\n",
      "배치 인덱스 : 164\t|\t이동 손실 : 2.9866784225810656\n",
      "배치 인덱스 : 165\t|\t이동 손실 : 2.9852642869374835\n",
      "배치 인덱스 : 166\t|\t이동 손실 : 2.9835104942321773\n",
      "배치 인덱스 : 167\t|\t이동 손실 : 2.981610616048177\n",
      "배치 인덱스 : 168\t|\t이동 손실 : 2.9805601870519873\n",
      "배치 인덱스 : 169\t|\t이동 손실 : 2.978750258333543\n",
      "배치 인덱스 : 170\t|\t이동 손실 : 2.9778854944552595\n",
      "배치 인덱스 : 171\t|\t이동 손실 : 2.9770119314969974\n",
      "배치 인덱스 : 172\t|\t이동 손실 : 2.9762580932220284\n",
      "배치 인덱스 : 173\t|\t이동 손실 : 2.9744384466916665\n",
      "배치 인덱스 : 174\t|\t이동 손실 : 2.9730407633100238\n",
      "배치 인덱스 : 175\t|\t이동 손실 : 2.972060738639398\n",
      "배치 인덱스 : 176\t|\t이동 손실 : 2.972125251414412\n",
      "배치 인덱스 : 177\t|\t이동 손실 : 2.9705968197811856\n",
      "배치 인덱스 : 178\t|\t이동 손실 : 2.970004831612443\n",
      "배치 인덱스 : 179\t|\t이동 손실 : 2.9694819529851277\n",
      "배치 인덱스 : 180\t|\t이동 손실 : 2.9670033889580827\n",
      "배치 인덱스 : 181\t|\t이동 손실 : 2.9664157026416653\n",
      "배치 인덱스 : 182\t|\t이동 손실 : 2.9647949002479597\n",
      "배치 인덱스 : 183\t|\t이동 손실 : 2.9636326017587082\n",
      "배치 인덱스 : 184\t|\t이동 손실 : 2.9619554236128525\n",
      "배치 인덱스 : 185\t|\t이동 손실 : 2.9597493615201724\n",
      "배치 인덱스 : 186\t|\t이동 손실 : 2.957652264100345\n",
      "배치 인덱스 : 187\t|\t이동 손실 : 2.9565980738781867\n",
      "배치 인덱스 : 188\t|\t이동 손실 : 2.955037685929152\n",
      "배치 인덱스 : 189\t|\t이동 손실 : 2.9531152398962726\n",
      "배치 인덱스 : 190\t|\t이동 손실 : 2.9512192741114434\n",
      "배치 인덱스 : 191\t|\t이동 손실 : 2.9494533762335777\n",
      "배치 인덱스 : 192\t|\t이동 손실 : 2.947805456546922\n",
      "배치 인덱스 : 193\t|\t이동 손실 : 2.946550433168706\n",
      "배치 인덱스 : 194\t|\t이동 손실 : 2.9451402737544132\n",
      "배치 인덱스 : 195\t|\t이동 손실 : 2.94406703540257\n",
      "배치 인덱스 : 196\t|\t이동 손실 : 2.9427196096042687\n",
      "배치 인덱스 : 197\t|\t이동 손실 : 2.941159418134978\n",
      "배치 인덱스 : 198\t|\t이동 손실 : 2.939400621395015\n",
      "배치 인덱스 : 199\t|\t이동 손실 : 2.9379433429241177\n",
      "배치 인덱스 : 200\t|\t이동 손실 : 2.9372286879601166\n",
      "배치 인덱스 : 201\t|\t이동 손실 : 2.9365152215013404\n",
      "배치 인덱스 : 202\t|\t이동 손실 : 2.9349234162880276\n",
      "배치 인덱스 : 203\t|\t이동 손실 : 2.934401826531279\n",
      "배치 인덱스 : 204\t|\t이동 손실 : 2.932609902358636\n",
      "배치 인덱스 : 205\t|\t이동 손실 : 2.9314998191537205\n",
      "배치 인덱스 : 206\t|\t이동 손실 : 2.9304083372659724\n",
      "배치 인덱스 : 207\t|\t이동 손실 : 2.9286860972642894\n",
      "배치 인덱스 : 208\t|\t이동 손실 : 2.9280687462199815\n",
      "배치 인덱스 : 209\t|\t이동 손실 : 2.926528172265915\n",
      "배치 인덱스 : 210\t|\t이동 손실 : 2.92531312020469\n",
      "배치 인덱스 : 211\t|\t이동 손실 : 2.923568056439453\n",
      "배치 인덱스 : 212\t|\t이동 손실 : 2.921675460439332\n",
      "배치 인덱스 : 213\t|\t이동 손실 : 2.9201507601782533\n",
      "배치 인덱스 : 214\t|\t이동 손실 : 2.9198383963385286\n",
      "배치 인덱스 : 215\t|\t이동 손실 : 2.9178763142338497\n",
      "배치 인덱스 : 216\t|\t이동 손실 : 2.9167977247369996\n",
      "배치 인덱스 : 217\t|\t이동 손실 : 2.9153801268393833\n",
      "배치 인덱스 : 218\t|\t이동 손실 : 2.9139344920850774\n",
      "배치 인덱스 : 219\t|\t이동 손실 : 2.9127166368744586\n",
      "배치 인덱스 : 220\t|\t이동 손실 : 2.9110129192404073\n",
      "배치 인덱스 : 221\t|\t이동 손실 : 2.9104015870137254\n",
      "배치 인덱스 : 222\t|\t이동 손실 : 2.9091597800832156\n",
      "배치 인덱스 : 223\t|\t이동 손실 : 2.907798615949494\n",
      "배치 인덱스 : 224\t|\t이동 손실 : 2.9070471996731224\n",
      "배치 인덱스 : 225\t|\t이동 손실 : 2.905792586571347\n",
      "배치 인덱스 : 226\t|\t이동 손실 : 2.904883274422868\n",
      "Epoch: 02 | Time: 15m 39s\n",
      "\tTrain Loss: 2.905 | Train PPL: 18.263\n",
      "\tValidation Loss: 2.554 | Validation PPL: 12.864\n",
      "에폭 : 2\n",
      "배치 인덱스 : 0\t|\t이동 손실 : 2.5671842098236084\n",
      "배치 인덱스 : 1\t|\t이동 손실 : 2.387397289276123\n",
      "배치 인덱스 : 2\t|\t이동 손실 : 2.4130261739095054\n",
      "배치 인덱스 : 3\t|\t이동 손실 : 2.4239864349365234\n",
      "배치 인덱스 : 4\t|\t이동 손실 : 2.4001200199127197\n",
      "배치 인덱스 : 5\t|\t이동 손실 : 2.381046255429586\n",
      "배치 인덱스 : 6\t|\t이동 손실 : 2.3993723392486572\n",
      "배치 인덱스 : 7\t|\t이동 손실 : 2.415142387151718\n",
      "배치 인덱스 : 8\t|\t이동 손실 : 2.421366718080309\n",
      "배치 인덱스 : 9\t|\t이동 손실 : 2.4096132040023805\n",
      "배치 인덱스 : 10\t|\t이동 손실 : 2.4183400544253266\n",
      "배치 인덱스 : 11\t|\t이동 손실 : 2.4285854101181035\n",
      "배치 인덱스 : 12\t|\t이동 손실 : 2.4274038168100214\n",
      "배치 인덱스 : 13\t|\t이동 손실 : 2.429034130913871\n",
      "배치 인덱스 : 14\t|\t이동 손실 : 2.4235724290212\n",
      "배치 인덱스 : 15\t|\t이동 손실 : 2.428107455372811\n",
      "배치 인덱스 : 16\t|\t이동 손실 : 2.4286427077125103\n",
      "배치 인덱스 : 17\t|\t이동 손실 : 2.4277901781929865\n",
      "배치 인덱스 : 18\t|\t이동 손실 : 2.4261441607224317\n",
      "배치 인덱스 : 19\t|\t이동 손실 : 2.4244423389434817\n",
      "배치 인덱스 : 20\t|\t이동 손실 : 2.4336257435026627\n",
      "배치 인덱스 : 21\t|\t이동 손실 : 2.4377788196910517\n",
      "배치 인덱스 : 22\t|\t이동 손실 : 2.4384527102760654\n",
      "배치 인덱스 : 23\t|\t이동 손실 : 2.437504539887111\n",
      "배치 인덱스 : 24\t|\t이동 손실 : 2.4358684253692635\n",
      "배치 인덱스 : 25\t|\t이동 손실 : 2.4286865087655882\n",
      "배치 인덱스 : 26\t|\t이동 손실 : 2.4245864285363097\n",
      "배치 인덱스 : 27\t|\t이동 손실 : 2.4226584179060806\n",
      "배치 인덱스 : 28\t|\t이동 손실 : 2.422418117523194\n",
      "배치 인덱스 : 29\t|\t이동 손실 : 2.4225577910741176\n",
      "배치 인덱스 : 30\t|\t이동 손실 : 2.420864351334111\n",
      "배치 인덱스 : 31\t|\t이동 손실 : 2.4207589551806454\n",
      "배치 인덱스 : 32\t|\t이동 손실 : 2.4172269647771665\n",
      "배치 인덱스 : 33\t|\t이동 손실 : 2.4160128761740296\n",
      "배치 인덱스 : 34\t|\t이동 손실 : 2.415794924327306\n",
      "배치 인덱스 : 35\t|\t이동 손실 : 2.413485043578678\n",
      "배치 인덱스 : 36\t|\t이동 손실 : 2.4127920576044035\n",
      "배치 인덱스 : 37\t|\t이동 손실 : 2.4121043807581857\n",
      "배치 인덱스 : 38\t|\t이동 손실 : 2.408308530465151\n",
      "배치 인덱스 : 39\t|\t이동 손실 : 2.407835912704468\n",
      "배치 인덱스 : 40\t|\t이동 손실 : 2.4044473287535877\n",
      "배치 인덱스 : 41\t|\t이동 손실 : 2.403367723737444\n",
      "배치 인덱스 : 42\t|\t이동 손실 : 2.402376230372939\n",
      "배치 인덱스 : 43\t|\t이동 손실 : 2.401759310202165\n",
      "배치 인덱스 : 44\t|\t이동 손실 : 2.3991471979353163\n",
      "배치 인덱스 : 45\t|\t이동 손실 : 2.397405634755674\n",
      "배치 인덱스 : 46\t|\t이동 손실 : 2.3959250602316353\n",
      "배치 인덱스 : 47\t|\t이동 손실 : 2.3907000472148265\n",
      "배치 인덱스 : 48\t|\t이동 손실 : 2.3907318066577528\n",
      "배치 인덱스 : 49\t|\t이동 손실 : 2.391208148002625\n",
      "배치 인덱스 : 50\t|\t이동 손실 : 2.3891368005789966\n",
      "배치 인덱스 : 51\t|\t이동 손실 : 2.3859155178070073\n",
      "배치 인덱스 : 52\t|\t이동 손실 : 2.386044119888882\n",
      "배치 인덱스 : 53\t|\t이동 손실 : 2.3843605650795836\n",
      "배치 인덱스 : 54\t|\t이동 손실 : 2.3831017190759836\n",
      "배치 인덱스 : 55\t|\t이동 손실 : 2.381715595722199\n",
      "배치 인덱스 : 56\t|\t이동 손실 : 2.3791429034450604\n",
      "배치 인덱스 : 57\t|\t이동 손실 : 2.3774450770739857\n",
      "배치 인덱스 : 58\t|\t이동 손실 : 2.376572823120376\n",
      "배치 인덱스 : 59\t|\t이동 손실 : 2.3763370553652448\n",
      "배치 인덱스 : 60\t|\t이동 손실 : 2.376219921424741\n",
      "배치 인덱스 : 61\t|\t이동 손실 : 2.375215299667851\n",
      "배치 인덱스 : 62\t|\t이동 손실 : 2.3759517821054614\n",
      "배치 인덱스 : 63\t|\t이동 손실 : 2.3746845535933976\n",
      "배치 인덱스 : 64\t|\t이동 손실 : 2.3724883886484003\n",
      "배치 인덱스 : 65\t|\t이동 손실 : 2.374112822792747\n",
      "배치 인덱스 : 66\t|\t이동 손실 : 2.3732646330079037\n",
      "배치 인덱스 : 67\t|\t이동 손실 : 2.3713490752612842\n",
      "배치 인덱스 : 68\t|\t이동 손실 : 2.3687903535538823\n",
      "배치 인덱스 : 69\t|\t이동 손실 : 2.367943443570818\n",
      "배치 인덱스 : 70\t|\t이동 손실 : 2.365910073401223\n",
      "배치 인덱스 : 71\t|\t이동 손실 : 2.365529785553614\n",
      "배치 인덱스 : 72\t|\t이동 손실 : 2.3655866727437056\n",
      "배치 인덱스 : 73\t|\t이동 손실 : 2.3645809792183536\n",
      "배치 인덱스 : 74\t|\t이동 손실 : 2.3635628573099767\n",
      "배치 인덱스 : 75\t|\t이동 손실 : 2.362389520594948\n",
      "배치 인덱스 : 76\t|\t이동 손실 : 2.36093470338103\n",
      "배치 인덱스 : 77\t|\t이동 손실 : 2.3597353880222025\n",
      "배치 인덱스 : 78\t|\t이동 손실 : 2.3594399192665194\n",
      "배치 인덱스 : 79\t|\t이동 손실 : 2.361095407605171\n",
      "배치 인덱스 : 80\t|\t이동 손실 : 2.3596425262498264\n",
      "배치 인덱스 : 81\t|\t이동 손실 : 2.3605307922130674\n",
      "배치 인덱스 : 82\t|\t이동 손실 : 2.3591204752405\n",
      "배치 인덱스 : 83\t|\t이동 손실 : 2.359654369808378\n",
      "배치 인덱스 : 84\t|\t이동 손실 : 2.3584277770098514\n",
      "배치 인덱스 : 85\t|\t이동 손실 : 2.357209610384564\n",
      "배치 인덱스 : 86\t|\t이동 손실 : 2.3552590101614763\n",
      "배치 인덱스 : 87\t|\t이동 손실 : 2.356256674636494\n",
      "배치 인덱스 : 88\t|\t이동 손실 : 2.3552208000354553\n",
      "배치 인덱스 : 89\t|\t이동 손실 : 2.35614218711853\n",
      "배치 인덱스 : 90\t|\t이동 손실 : 2.3541683783897986\n",
      "배치 인덱스 : 91\t|\t이동 손실 : 2.3538074493408203\n",
      "배치 인덱스 : 92\t|\t이동 손실 : 2.3526347990958922\n",
      "배치 인덱스 : 93\t|\t이동 손실 : 2.3507169814819986\n",
      "배치 인덱스 : 94\t|\t이동 손실 : 2.3493615024968197\n",
      "배치 인덱스 : 95\t|\t이동 손실 : 2.3488563696543374\n",
      "배치 인덱스 : 96\t|\t이동 손실 : 2.347117942633088\n",
      "배치 인덱스 : 97\t|\t이동 손실 : 2.346901616271661\n",
      "배치 인덱스 : 98\t|\t이동 손실 : 2.3468865409041895\n",
      "배치 인덱스 : 99\t|\t이동 손실 : 2.346940047740936\n",
      "배치 인덱스 : 100\t|\t이동 손실 : 2.346438655758848\n",
      "배치 인덱스 : 101\t|\t이동 손실 : 2.347760469305749\n",
      "배치 인덱스 : 102\t|\t이동 손실 : 2.3455021335083304\n",
      "배치 인덱스 : 103\t|\t이동 손실 : 2.344975852049314\n",
      "배치 인덱스 : 104\t|\t이동 손실 : 2.344425448917207\n",
      "배치 인덱스 : 105\t|\t이동 손실 : 2.3450406002548503\n",
      "배치 인덱스 : 106\t|\t이동 손실 : 2.3443567997941344\n",
      "배치 인덱스 : 107\t|\t이동 손실 : 2.3427246036352933\n",
      "배치 인덱스 : 108\t|\t이동 손실 : 2.3399442248388165\n",
      "배치 인덱스 : 109\t|\t이동 손실 : 2.3398274746808134\n",
      "배치 인덱스 : 110\t|\t이동 손실 : 2.3391583223600643\n",
      "배치 인덱스 : 111\t|\t이동 손실 : 2.3386740067175453\n",
      "배치 인덱스 : 112\t|\t이동 손실 : 2.3374570766381453\n",
      "배치 인덱스 : 113\t|\t이동 손실 : 2.3368434424985915\n",
      "배치 인덱스 : 114\t|\t이동 손실 : 2.3365827892137605\n",
      "배치 인덱스 : 115\t|\t이동 손실 : 2.3350495654961154\n",
      "배치 인덱스 : 116\t|\t이동 손실 : 2.334103270473643\n",
      "배치 인덱스 : 117\t|\t이동 손실 : 2.333786542132749\n",
      "배치 인덱스 : 118\t|\t이동 손실 : 2.3325761766994697\n",
      "배치 인덱스 : 119\t|\t이동 손실 : 2.3317318022251126\n",
      "배치 인덱스 : 120\t|\t이동 손실 : 2.3313951610533654\n",
      "배치 인덱스 : 121\t|\t이동 손실 : 2.3311304186211252\n",
      "배치 인덱스 : 122\t|\t이동 손실 : 2.330550428328475\n",
      "배치 인덱스 : 123\t|\t이동 손실 : 2.3295029171051516\n",
      "배치 인덱스 : 124\t|\t이동 손실 : 2.3285396251678465\n",
      "배치 인덱스 : 125\t|\t이동 손실 : 2.32870914822533\n",
      "배치 인덱스 : 126\t|\t이동 손실 : 2.326827374030286\n",
      "배치 인덱스 : 127\t|\t이동 손실 : 2.326597822830081\n",
      "배치 인덱스 : 128\t|\t이동 손실 : 2.3265837717425915\n",
      "배치 인덱스 : 129\t|\t이동 손실 : 2.32552728836353\n",
      "배치 인덱스 : 130\t|\t이동 손실 : 2.324556802065318\n",
      "배치 인덱스 : 131\t|\t이동 손실 : 2.3237092314344467\n",
      "배치 인덱스 : 132\t|\t이동 손실 : 2.3235543921477815\n",
      "배치 인덱스 : 133\t|\t이동 손실 : 2.323103997244764\n",
      "배치 인덱스 : 134\t|\t이동 손실 : 2.3227561986004863\n",
      "배치 인덱스 : 135\t|\t이동 손실 : 2.3221870836089638\n",
      "배치 인덱스 : 136\t|\t이동 손실 : 2.321382151903027\n",
      "배치 인덱스 : 137\t|\t이동 손실 : 2.3199064627937647\n",
      "배치 인덱스 : 138\t|\t이동 손실 : 2.318563603668762\n",
      "배치 인덱스 : 139\t|\t이동 손실 : 2.3179683276585172\n",
      "배치 인덱스 : 140\t|\t이동 손실 : 2.31800918207101\n",
      "배치 인덱스 : 141\t|\t이동 손실 : 2.317063242616788\n",
      "배치 인덱스 : 142\t|\t이동 손실 : 2.3166218987711664\n",
      "배치 인덱스 : 143\t|\t이동 손실 : 2.31584763692485\n",
      "배치 인덱스 : 144\t|\t이동 손실 : 2.3155135943971836\n",
      "배치 인덱스 : 145\t|\t이동 손실 : 2.313546316264427\n",
      "배치 인덱스 : 146\t|\t이동 손실 : 2.31351409315252\n",
      "배치 인덱스 : 147\t|\t이동 손실 : 2.3125345529736703\n",
      "배치 인덱스 : 148\t|\t이동 손실 : 2.3126572842565962\n",
      "배치 인덱스 : 149\t|\t이동 손실 : 2.3117512830098472\n",
      "배치 인덱스 : 150\t|\t이동 손실 : 2.3092798681448627\n",
      "배치 인덱스 : 151\t|\t이동 손실 : 2.3101748133960522\n",
      "배치 인덱스 : 152\t|\t이동 손실 : 2.3093251558690286\n",
      "배치 인덱스 : 153\t|\t이동 손실 : 2.309371842966451\n",
      "배치 인덱스 : 154\t|\t이동 손실 : 2.3090477082037153\n",
      "배치 인덱스 : 155\t|\t이동 손실 : 2.308264185220767\n",
      "배치 인덱스 : 156\t|\t이동 손실 : 2.307761102724986\n",
      "배치 인덱스 : 157\t|\t이동 손실 : 2.3076629789569707\n",
      "배치 인덱스 : 158\t|\t이동 손실 : 2.308100827834891\n",
      "배치 인덱스 : 159\t|\t이동 손실 : 2.3076399743556975\n",
      "배치 인덱스 : 160\t|\t이동 손실 : 2.308457300529717\n",
      "배치 인덱스 : 161\t|\t이동 손실 : 2.307283397074099\n",
      "배치 인덱스 : 162\t|\t이동 손실 : 2.3063788501762903\n",
      "배치 인덱스 : 163\t|\t이동 손실 : 2.305729223460686\n",
      "배치 인덱스 : 164\t|\t이동 손실 : 2.304678588924986\n",
      "배치 인덱스 : 165\t|\t이동 손실 : 2.3040048156876165\n",
      "배치 인덱스 : 166\t|\t이동 손실 : 2.3030932763379495\n",
      "배치 인덱스 : 167\t|\t이동 손실 : 2.302640497684479\n",
      "배치 인덱스 : 168\t|\t이동 손실 : 2.302524338107138\n",
      "배치 인덱스 : 169\t|\t이동 손실 : 2.30116637173821\n",
      "배치 인덱스 : 170\t|\t이동 손실 : 2.300728210928845\n",
      "배치 인덱스 : 171\t|\t이동 손실 : 2.3006954567376963\n",
      "배치 인덱스 : 172\t|\t이동 손실 : 2.3000865533861816\n",
      "배치 인덱스 : 173\t|\t이동 손실 : 2.2996477943727345\n",
      "배치 인덱스 : 174\t|\t이동 손실 : 2.2996746403830395\n",
      "배치 인덱스 : 175\t|\t이동 손실 : 2.298772531476888\n",
      "배치 인덱스 : 176\t|\t이동 손실 : 2.297526795985335\n",
      "배치 인덱스 : 177\t|\t이동 손실 : 2.297161005855946\n",
      "배치 인덱스 : 178\t|\t이동 손실 : 2.2970958395377217\n",
      "배치 인덱스 : 179\t|\t이동 손실 : 2.2968997054629856\n",
      "배치 인덱스 : 180\t|\t이동 손실 : 2.29683518409729\n",
      "배치 인덱스 : 181\t|\t이동 손실 : 2.296153058062543\n",
      "배치 인덱스 : 182\t|\t이동 손실 : 2.2957375218959455\n",
      "배치 인덱스 : 183\t|\t이동 손실 : 2.2954890779826953\n",
      "배치 인덱스 : 184\t|\t이동 손실 : 2.293845633558325\n",
      "배치 인덱스 : 185\t|\t이동 손실 : 2.2934572113457548\n",
      "배치 인덱스 : 186\t|\t이동 손실 : 2.2928968986725424\n",
      "배치 인덱스 : 187\t|\t이동 손실 : 2.2917324894286217\n",
      "배치 인덱스 : 188\t|\t이동 손실 : 2.2903048216350497\n",
      "배치 인덱스 : 189\t|\t이동 손실 : 2.29030167366329\n",
      "배치 인덱스 : 190\t|\t이동 손실 : 2.290435296078627\n",
      "배치 인덱스 : 191\t|\t이동 손실 : 2.2899659158041077\n",
      "배치 인덱스 : 192\t|\t이동 손실 : 2.28922050542782\n",
      "배치 인덱스 : 193\t|\t이동 손실 : 2.288996092437469\n",
      "배치 인덱스 : 194\t|\t이동 손실 : 2.2884041951252865\n",
      "배치 인덱스 : 195\t|\t이동 손실 : 2.2872174996502546\n",
      "배치 인덱스 : 196\t|\t이동 손실 : 2.2864668109090194\n",
      "배치 인덱스 : 197\t|\t이동 손실 : 2.286937993584257\n",
      "배치 인덱스 : 198\t|\t이동 손실 : 2.2860938214776505\n",
      "배치 인덱스 : 199\t|\t이동 손실 : 2.285308160185814\n",
      "배치 인덱스 : 200\t|\t이동 손실 : 2.284704239807319\n",
      "배치 인덱스 : 201\t|\t이동 손실 : 2.28370080903025\n",
      "배치 인덱스 : 202\t|\t이동 손실 : 2.282844131803278\n",
      "배치 인덱스 : 203\t|\t이동 손실 : 2.281602163525189\n",
      "배치 인덱스 : 204\t|\t이동 손실 : 2.280871236033556\n",
      "배치 인덱스 : 205\t|\t이동 손실 : 2.2802283121544185\n",
      "배치 인덱스 : 206\t|\t이동 손실 : 2.2801199206983416\n",
      "배치 인덱스 : 207\t|\t이동 손실 : 2.2792111583627195\n",
      "배치 인덱스 : 208\t|\t이동 손실 : 2.279084338525837\n",
      "배치 인덱스 : 209\t|\t이동 손실 : 2.2778947268213554\n",
      "배치 인덱스 : 210\t|\t이동 손실 : 2.2769101937235257\n",
      "배치 인덱스 : 211\t|\t이동 손실 : 2.276569219692699\n",
      "배치 인덱스 : 212\t|\t이동 손실 : 2.276773726436455\n",
      "배치 인덱스 : 213\t|\t이동 손실 : 2.2754208005477348\n",
      "배치 인덱스 : 214\t|\t이동 손실 : 2.274304771423341\n",
      "배치 인덱스 : 215\t|\t이동 손실 : 2.273797634575103\n",
      "배치 인덱스 : 216\t|\t이동 손실 : 2.2741917607971063\n",
      "배치 인덱스 : 217\t|\t이동 손실 : 2.2734510614237666\n",
      "배치 인덱스 : 218\t|\t이동 손실 : 2.2726533532686988\n",
      "배치 인덱스 : 219\t|\t이동 손실 : 2.272428878870879\n",
      "배치 인덱스 : 220\t|\t이동 손실 : 2.272152800365812\n",
      "배치 인덱스 : 221\t|\t이동 손실 : 2.270723350950191\n",
      "배치 인덱스 : 222\t|\t이동 손실 : 2.270035209677146\n",
      "배치 인덱스 : 223\t|\t이동 손실 : 2.270466657089337\n",
      "배치 인덱스 : 224\t|\t이동 손실 : 2.2700025818083036\n",
      "배치 인덱스 : 225\t|\t이동 손실 : 2.2694645608420934\n",
      "배치 인덱스 : 226\t|\t이동 손실 : 2.268666500036938\n",
      "Epoch: 03 | Time: 15m 24s\n",
      "\tTrain Loss: 2.269 | Train PPL: 9.667\n",
      "\tValidation Loss: 2.248 | Validation PPL: 9.465\n",
      "에폭 : 3\n",
      "배치 인덱스 : 0\t|\t이동 손실 : 2.0132596492767334\n",
      "배치 인덱스 : 1\t|\t이동 손실 : 1.9833816289901733\n",
      "배치 인덱스 : 2\t|\t이동 손실 : 1.9352679252624512\n",
      "배치 인덱스 : 3\t|\t이동 손실 : 1.928625226020813\n",
      "배치 인덱스 : 4\t|\t이동 손실 : 1.9039101600646973\n",
      "배치 인덱스 : 5\t|\t이동 손실 : 1.920854647954305\n",
      "배치 인덱스 : 6\t|\t이동 손실 : 1.8867290360586983\n",
      "배치 인덱스 : 7\t|\t이동 손실 : 1.890985980629921\n",
      "배치 인덱스 : 8\t|\t이동 손실 : 1.8834742175208197\n",
      "배치 인덱스 : 9\t|\t이동 손실 : 1.8826282143592834\n",
      "배치 인덱스 : 10\t|\t이동 손실 : 1.8776752840388904\n",
      "배치 인덱스 : 11\t|\t이동 손실 : 1.8822168707847595\n",
      "배치 인덱스 : 12\t|\t이동 손실 : 1.8829906445283155\n",
      "배치 인덱스 : 13\t|\t이동 손실 : 1.8781941788537162\n",
      "배치 인덱스 : 14\t|\t이동 손실 : 1.8719613154729207\n",
      "배치 인덱스 : 15\t|\t이동 손실 : 1.871409349143505\n",
      "배치 인덱스 : 16\t|\t이동 손실 : 1.8645592296824736\n",
      "배치 인덱스 : 17\t|\t이동 손실 : 1.8700166079733107\n",
      "배치 인덱스 : 18\t|\t이동 손실 : 1.8753402484090704\n",
      "배치 인덱스 : 19\t|\t이동 손실 : 1.8758580744266509\n",
      "배치 인덱스 : 20\t|\t이동 손실 : 1.8839722190584454\n",
      "배치 인덱스 : 21\t|\t이동 손실 : 1.8874615105715664\n",
      "배치 인덱스 : 22\t|\t이동 손실 : 1.8831111192703247\n",
      "배치 인덱스 : 23\t|\t이동 손실 : 1.887341558933258\n",
      "배치 인덱스 : 24\t|\t이동 손실 : 1.881269211769104\n",
      "배치 인덱스 : 25\t|\t이동 손실 : 1.8836551583730259\n",
      "배치 인덱스 : 26\t|\t이동 손실 : 1.8862233780048514\n",
      "배치 인덱스 : 27\t|\t이동 손실 : 1.8858838336808343\n",
      "배치 인덱스 : 28\t|\t이동 손실 : 1.8873546863424369\n",
      "배치 인덱스 : 29\t|\t이동 손실 : 1.8913871129353843\n",
      "배치 인덱스 : 30\t|\t이동 손실 : 1.8950915413518108\n",
      "배치 인덱스 : 31\t|\t이동 손실 : 1.8946006037294867\n",
      "배치 인덱스 : 32\t|\t이동 손실 : 1.895989031502695\n",
      "배치 인덱스 : 33\t|\t이동 손실 : 1.8983714896089894\n",
      "배치 인덱스 : 34\t|\t이동 손실 : 1.8967919860567368\n",
      "배치 인덱스 : 35\t|\t이동 손실 : 1.8941595024532745\n",
      "배치 인덱스 : 36\t|\t이동 손실 : 1.8931411698057847\n",
      "배치 인덱스 : 37\t|\t이동 손실 : 1.891530686303189\n",
      "배치 인덱스 : 38\t|\t이동 손실 : 1.8925261252965684\n",
      "배치 인덱스 : 39\t|\t이동 손실 : 1.8959642291069032\n",
      "배치 인덱스 : 40\t|\t이동 손실 : 1.894803047180176\n",
      "배치 인덱스 : 41\t|\t이동 손실 : 1.892584406194233\n",
      "배치 인덱스 : 42\t|\t이동 손실 : 1.88988963116047\n",
      "배치 인덱스 : 43\t|\t이동 손실 : 1.8915002887899226\n",
      "배치 인덱스 : 44\t|\t이동 손실 : 1.8889203919304742\n",
      "배치 인덱스 : 45\t|\t이동 손실 : 1.8901950483736785\n",
      "배치 인덱스 : 46\t|\t이동 손실 : 1.8900716862779983\n",
      "배치 인덱스 : 47\t|\t이동 손실 : 1.8885931571324666\n",
      "배치 인덱스 : 48\t|\t이동 손실 : 1.8903146836222433\n",
      "배치 인덱스 : 49\t|\t이동 손실 : 1.8883651399612424\n",
      "배치 인덱스 : 50\t|\t이동 손실 : 1.887078568047168\n",
      "배치 인덱스 : 51\t|\t이동 손실 : 1.888729739647645\n",
      "배치 인덱스 : 52\t|\t이동 손실 : 1.8866274199395807\n",
      "배치 인덱스 : 53\t|\t이동 손실 : 1.8889447340258843\n",
      "배치 인덱스 : 54\t|\t이동 손실 : 1.8899509408257222\n",
      "배치 인덱스 : 55\t|\t이동 손실 : 1.889760883791106\n",
      "배치 인덱스 : 56\t|\t이동 손실 : 1.8924351554167897\n",
      "배치 인덱스 : 57\t|\t이동 손실 : 1.8907872500090763\n",
      "배치 인덱스 : 58\t|\t이동 손실 : 1.8895763199208147\n",
      "배치 인덱스 : 59\t|\t이동 손실 : 1.8882594803969066\n",
      "배치 인덱스 : 60\t|\t이동 손실 : 1.8880711246709356\n",
      "배치 인덱스 : 61\t|\t이동 손실 : 1.8903218296266373\n",
      "배치 인덱스 : 62\t|\t이동 손실 : 1.890673701725309\n",
      "배치 인덱스 : 63\t|\t이동 손실 : 1.8898214027285578\n",
      "배치 인덱스 : 64\t|\t이동 손실 : 1.8910334715476405\n",
      "배치 인덱스 : 65\t|\t이동 손실 : 1.8909683931957593\n",
      "배치 인덱스 : 66\t|\t이동 손실 : 1.8912297825315105\n",
      "배치 인덱스 : 67\t|\t이동 손실 : 1.8930875904419844\n",
      "배치 인덱스 : 68\t|\t이동 손실 : 1.8937783103058305\n",
      "배치 인덱스 : 69\t|\t이동 손실 : 1.892751411029271\n",
      "배치 인덱스 : 70\t|\t이동 손실 : 1.8920069328496156\n",
      "배치 인덱스 : 71\t|\t이동 손실 : 1.891750150256687\n",
      "배치 인덱스 : 72\t|\t이동 손실 : 1.8917404070292436\n",
      "배치 인덱스 : 73\t|\t이동 손실 : 1.8929489367717023\n",
      "배치 인덱스 : 74\t|\t이동 손실 : 1.8926399358113608\n",
      "배치 인덱스 : 75\t|\t이동 손실 : 1.8933644263367906\n",
      "배치 인덱스 : 76\t|\t이동 손실 : 1.894974299839565\n",
      "배치 인덱스 : 77\t|\t이동 손실 : 1.8945731963866799\n",
      "배치 인덱스 : 78\t|\t이동 손실 : 1.896555767783636\n",
      "배치 인덱스 : 79\t|\t이동 손실 : 1.8968764021992686\n",
      "배치 인덱스 : 80\t|\t이동 손실 : 1.8978862953774724\n",
      "배치 인덱스 : 81\t|\t이동 손실 : 1.8962033303772532\n",
      "배치 인덱스 : 82\t|\t이동 손실 : 1.8962647426559265\n",
      "배치 인덱스 : 83\t|\t이동 손실 : 1.8968134749503363\n",
      "배치 인덱스 : 84\t|\t이동 손실 : 1.8961575620314655\n",
      "배치 인덱스 : 85\t|\t이동 손실 : 1.8961009452509325\n",
      "배치 인덱스 : 86\t|\t이동 손실 : 1.8949588317980712\n",
      "배치 인덱스 : 87\t|\t이동 손실 : 1.894722713665529\n",
      "배치 인덱스 : 88\t|\t이동 손실 : 1.8942289727457455\n",
      "배치 인덱스 : 89\t|\t이동 손실 : 1.893357997470432\n",
      "배치 인덱스 : 90\t|\t이동 손실 : 1.8942999813582873\n",
      "배치 인덱스 : 91\t|\t이동 손실 : 1.893813384615857\n",
      "배치 인덱스 : 92\t|\t이동 손실 : 1.8943835778902938\n",
      "배치 인덱스 : 93\t|\t이동 손실 : 1.8949870860322995\n",
      "배치 인덱스 : 94\t|\t이동 손실 : 1.8948278514962449\n",
      "배치 인덱스 : 95\t|\t이동 손실 : 1.894431207329035\n",
      "배치 인덱스 : 96\t|\t이동 손실 : 1.894289586961884\n",
      "배치 인덱스 : 97\t|\t이동 손실 : 1.893674157103714\n",
      "배치 인덱스 : 98\t|\t이동 손실 : 1.8936803232539785\n",
      "배치 인덱스 : 99\t|\t이동 손실 : 1.8931383180618286\n",
      "배치 인덱스 : 100\t|\t이동 손실 : 1.894174320863025\n",
      "배치 인덱스 : 101\t|\t이동 손실 : 1.89314851807613\n",
      "배치 인덱스 : 102\t|\t이동 손실 : 1.894003964164882\n",
      "배치 인덱스 : 103\t|\t이동 손실 : 1.8929920334082384\n",
      "배치 인덱스 : 104\t|\t이동 손실 : 1.8929951690492177\n",
      "배치 인덱스 : 105\t|\t이동 손실 : 1.8923933742181311\n",
      "배치 인덱스 : 106\t|\t이동 손실 : 1.8935101043398137\n",
      "배치 인덱스 : 107\t|\t이동 손실 : 1.8933358413201793\n",
      "배치 인덱스 : 108\t|\t이동 손실 : 1.8930487370272298\n",
      "배치 인덱스 : 109\t|\t이동 손실 : 1.892373276840557\n",
      "배치 인덱스 : 110\t|\t이동 손실 : 1.8925483065682491\n",
      "배치 인덱스 : 111\t|\t이동 손실 : 1.8928614194904059\n",
      "배치 인덱스 : 112\t|\t이동 손실 : 1.892498762206694\n",
      "배치 인덱스 : 113\t|\t이동 손실 : 1.8922912760784756\n",
      "배치 인덱스 : 114\t|\t이동 손실 : 1.8932605992192812\n",
      "배치 인덱스 : 115\t|\t이동 손실 : 1.8930747056829524\n",
      "배치 인덱스 : 116\t|\t이동 손실 : 1.8923569377670946\n",
      "배치 인덱스 : 117\t|\t이동 손실 : 1.8929632265689016\n",
      "배치 인덱스 : 118\t|\t이동 손실 : 1.8930536448454662\n",
      "배치 인덱스 : 119\t|\t이동 손실 : 1.8932759602864588\n",
      "배치 인덱스 : 120\t|\t이동 손실 : 1.8926489372883952\n",
      "배치 인덱스 : 121\t|\t이동 손실 : 1.8928108352129582\n",
      "배치 인덱스 : 122\t|\t이동 손실 : 1.8921941509091762\n",
      "배치 인덱스 : 123\t|\t이동 손실 : 1.8914141856854967\n",
      "배치 인덱스 : 124\t|\t이동 손실 : 1.8914413528442389\n",
      "배치 인덱스 : 125\t|\t이동 손실 : 1.8910831771199672\n",
      "배치 인덱스 : 126\t|\t이동 손실 : 1.8902861480637805\n",
      "배치 인덱스 : 127\t|\t이동 손실 : 1.8897684691473848\n",
      "배치 인덱스 : 128\t|\t이동 손실 : 1.889676121778267\n",
      "배치 인덱스 : 129\t|\t이동 손실 : 1.8896880984306341\n",
      "배치 인덱스 : 130\t|\t이동 손실 : 1.8895556226031476\n",
      "배치 인덱스 : 131\t|\t이동 손실 : 1.888146683122173\n",
      "배치 인덱스 : 132\t|\t이동 손실 : 1.8876024771453748\n",
      "배치 인덱스 : 133\t|\t이동 손실 : 1.8868774700520647\n",
      "배치 인덱스 : 134\t|\t이동 손실 : 1.8859699893880777\n",
      "배치 인덱스 : 135\t|\t이동 손실 : 1.886374191326254\n",
      "배치 인덱스 : 136\t|\t이동 손실 : 1.885484238610651\n",
      "배치 인덱스 : 137\t|\t이동 손실 : 1.8846887436465944\n",
      "배치 인덱스 : 138\t|\t이동 손실 : 1.8843386825040094\n",
      "배치 인덱스 : 139\t|\t이동 손실 : 1.8847945732729778\n",
      "배치 인덱스 : 140\t|\t이동 손실 : 1.8847323309445214\n",
      "배치 인덱스 : 141\t|\t이동 손실 : 1.8848229671867802\n",
      "배치 인덱스 : 142\t|\t이동 손실 : 1.8848497350732765\n",
      "배치 인덱스 : 143\t|\t이동 손실 : 1.8837263236443202\n",
      "배치 인덱스 : 144\t|\t이동 손실 : 1.8829097550490808\n",
      "배치 인덱스 : 145\t|\t이동 손실 : 1.8829779584113866\n",
      "배치 인덱스 : 146\t|\t이동 손실 : 1.8826740371937656\n",
      "배치 인덱스 : 147\t|\t이동 손실 : 1.8831725321911479\n",
      "배치 인덱스 : 148\t|\t이동 손실 : 1.883390948276392\n",
      "배치 인덱스 : 149\t|\t이동 손실 : 1.8835030738512677\n",
      "배치 인덱스 : 150\t|\t이동 손실 : 1.8827239464450358\n",
      "배치 인덱스 : 151\t|\t이동 손실 : 1.8826686167403273\n",
      "배치 인덱스 : 152\t|\t이동 손실 : 1.8827327076905693\n",
      "배치 인덱스 : 153\t|\t이동 손실 : 1.8828935700577576\n",
      "배치 인덱스 : 154\t|\t이동 손실 : 1.8823109388351442\n",
      "배치 인덱스 : 155\t|\t이동 손실 : 1.883129235261526\n",
      "배치 인덱스 : 156\t|\t이동 손실 : 1.8815947573655731\n",
      "배치 인덱스 : 157\t|\t이동 손실 : 1.8823461027085029\n",
      "배치 인덱스 : 158\t|\t이동 손실 : 1.8815177634077254\n",
      "배치 인덱스 : 159\t|\t이동 손실 : 1.8817819476127626\n",
      "배치 인덱스 : 160\t|\t이동 손실 : 1.8809471493181977\n",
      "배치 인덱스 : 161\t|\t이동 손실 : 1.8807024514233628\n",
      "배치 인덱스 : 162\t|\t이동 손실 : 1.8806468862697394\n",
      "배치 인덱스 : 163\t|\t이동 손실 : 1.8802552993704635\n",
      "배치 인덱스 : 164\t|\t이동 손실 : 1.8804513266592318\n",
      "배치 인덱스 : 165\t|\t이동 손실 : 1.8802977276135642\n",
      "배치 인덱스 : 166\t|\t이동 손실 : 1.880454366792462\n",
      "배치 인덱스 : 167\t|\t이동 손실 : 1.879743312086378\n",
      "배치 인덱스 : 168\t|\t이동 손실 : 1.8786095867495567\n",
      "배치 인덱스 : 169\t|\t이동 손실 : 1.878104846617755\n",
      "배치 인덱스 : 170\t|\t이동 손실 : 1.8772075008927733\n",
      "배치 인덱스 : 171\t|\t이동 손실 : 1.8765348175237349\n",
      "배치 인덱스 : 172\t|\t이동 손실 : 1.8761104414228762\n",
      "배치 인덱스 : 173\t|\t이동 손실 : 1.8768372583663329\n",
      "배치 인덱스 : 174\t|\t이동 손실 : 1.8762245464324954\n",
      "배치 인덱스 : 175\t|\t이동 손실 : 1.8766121159900322\n",
      "배치 인덱스 : 176\t|\t이동 손실 : 1.8769112320269572\n",
      "배치 인덱스 : 177\t|\t이동 손실 : 1.876818253752891\n",
      "배치 인덱스 : 178\t|\t이동 손실 : 1.877077964431081\n",
      "배치 인덱스 : 179\t|\t이동 손실 : 1.8765720234976877\n",
      "배치 인덱스 : 180\t|\t이동 손실 : 1.876265199803516\n",
      "배치 인덱스 : 181\t|\t이동 손실 : 1.8764154740742278\n",
      "배치 인덱스 : 182\t|\t이동 손실 : 1.8759359733654506\n",
      "배치 인덱스 : 183\t|\t이동 손실 : 1.8762092149775966\n",
      "배치 인덱스 : 184\t|\t이동 손실 : 1.875400302216814\n",
      "배치 인덱스 : 185\t|\t이동 손실 : 1.8745712009809357\n",
      "배치 인덱스 : 186\t|\t이동 손실 : 1.8743991826307334\n",
      "배치 인덱스 : 187\t|\t이동 손실 : 1.8742460640186964\n",
      "배치 인덱스 : 188\t|\t이동 손실 : 1.8741394300309444\n",
      "배치 인덱스 : 189\t|\t이동 손실 : 1.8748995567622944\n",
      "배치 인덱스 : 190\t|\t이동 손실 : 1.8743071543608667\n",
      "배치 인덱스 : 191\t|\t이동 손실 : 1.873580864941081\n",
      "배치 인덱스 : 192\t|\t이동 손실 : 1.8736019851012558\n",
      "배치 인덱스 : 193\t|\t이동 손실 : 1.8739205353038833\n",
      "배치 인덱스 : 194\t|\t이동 손실 : 1.873504191789872\n",
      "배치 인덱스 : 195\t|\t이동 손실 : 1.8730753495985153\n",
      "배치 인덱스 : 196\t|\t이동 손실 : 1.8726120775726245\n",
      "배치 인덱스 : 197\t|\t이동 손실 : 1.8721102638678122\n",
      "배치 인덱스 : 198\t|\t이동 손실 : 1.8710764820252237\n",
      "배치 인덱스 : 199\t|\t이동 손실 : 1.8699893057346348\n",
      "배치 인덱스 : 200\t|\t이동 손실 : 1.8702405833486304\n",
      "배치 인덱스 : 201\t|\t이동 손실 : 1.8699934405855616\n",
      "배치 인덱스 : 202\t|\t이동 손실 : 1.8710128738375136\n",
      "배치 인덱스 : 203\t|\t이동 손실 : 1.8708623893120713\n",
      "배치 인덱스 : 204\t|\t이동 손실 : 1.8706438111095898\n",
      "배치 인덱스 : 205\t|\t이동 손실 : 1.8700512630268211\n",
      "배치 인덱스 : 206\t|\t이동 손실 : 1.86959373375068\n",
      "배치 인덱스 : 207\t|\t이동 손실 : 1.869222145241041\n",
      "배치 인덱스 : 208\t|\t이동 손실 : 1.8685513289921596\n",
      "배치 인덱스 : 209\t|\t이동 손실 : 1.868398707821256\n",
      "배치 인덱스 : 210\t|\t이동 손실 : 1.8682638581895155\n",
      "배치 인덱스 : 211\t|\t이동 손실 : 1.8675887607178603\n",
      "배치 인덱스 : 212\t|\t이동 손실 : 1.8670851434340505\n",
      "배치 인덱스 : 213\t|\t이동 손실 : 1.867557212014065\n",
      "배치 인덱스 : 214\t|\t이동 손실 : 1.8676958194998812\n",
      "배치 인덱스 : 215\t|\t이동 손실 : 1.8679800022531443\n",
      "배치 인덱스 : 216\t|\t이동 손실 : 1.8679767473502098\n",
      "배치 인덱스 : 217\t|\t이동 손실 : 1.867072587166358\n",
      "배치 인덱스 : 218\t|\t이동 손실 : 1.8670874948370952\n",
      "배치 인덱스 : 219\t|\t이동 손실 : 1.866850020668724\n",
      "배치 인덱스 : 220\t|\t이동 손실 : 1.867547318946183\n",
      "배치 인덱스 : 221\t|\t이동 손실 : 1.8673969990498318\n",
      "배치 인덱스 : 222\t|\t이동 손실 : 1.8673833223736347\n",
      "배치 인덱스 : 223\t|\t이동 손실 : 1.8671110203223575\n",
      "배치 인덱스 : 224\t|\t이동 손실 : 1.8672491741180426\n",
      "배치 인덱스 : 225\t|\t이동 손실 : 1.8673222692666862\n",
      "배치 인덱스 : 226\t|\t이동 손실 : 1.866785768370272\n",
      "Epoch: 04 | Time: 14m 59s\n",
      "\tTrain Loss: 1.867 | Train PPL: 6.467\n",
      "\tValidation Loss: 2.082 | Validation PPL: 8.018\n",
      "에폭 : 4\n",
      "배치 인덱스 : 0\t|\t이동 손실 : 1.6484609842300415\n",
      "배치 인덱스 : 1\t|\t이동 손실 : 1.6020947694778442\n",
      "배치 인덱스 : 2\t|\t이동 손실 : 1.6562141577402751\n",
      "배치 인덱스 : 3\t|\t이동 손실 : 1.6682428419589996\n",
      "배치 인덱스 : 4\t|\t이동 손실 : 1.6299869298934937\n",
      "배치 인덱스 : 5\t|\t이동 손실 : 1.605828881263733\n",
      "배치 인덱스 : 6\t|\t이동 손실 : 1.5994412217821394\n",
      "배치 인덱스 : 7\t|\t이동 손실 : 1.5916886776685715\n",
      "배치 인덱스 : 8\t|\t이동 손실 : 1.5918292336993747\n",
      "배치 인덱스 : 9\t|\t이동 손실 : 1.5994632005691527\n",
      "배치 인덱스 : 10\t|\t이동 손실 : 1.6023914380507034\n",
      "배치 인덱스 : 11\t|\t이동 손실 : 1.6017114420731862\n",
      "배치 인덱스 : 12\t|\t이동 손실 : 1.6034165162306564\n",
      "배치 인덱스 : 13\t|\t이동 손실 : 1.6016449672835211\n",
      "배치 인덱스 : 14\t|\t이동 손실 : 1.6120597998301185\n",
      "배치 인덱스 : 15\t|\t이동 손실 : 1.5997493937611578\n",
      "배치 인덱스 : 16\t|\t이동 손실 : 1.5984632968902586\n",
      "배치 인덱스 : 17\t|\t이동 손실 : 1.5970606936348808\n",
      "배치 인덱스 : 18\t|\t이동 손실 : 1.5922387399171527\n",
      "배치 인덱스 : 19\t|\t이동 손실 : 1.5951198399066924\n",
      "배치 인덱스 : 20\t|\t이동 손실 : 1.5929443211782546\n",
      "배치 인덱스 : 21\t|\t이동 손실 : 1.5923301089893687\n",
      "배치 인덱스 : 22\t|\t이동 손실 : 1.5907499323720515\n",
      "배치 인덱스 : 23\t|\t이동 손실 : 1.5893096923828123\n",
      "배치 인덱스 : 24\t|\t이동 손실 : 1.592439246177673\n",
      "배치 인덱스 : 25\t|\t이동 손실 : 1.5894733621523929\n",
      "배치 인덱스 : 26\t|\t이동 손실 : 1.5922108270503854\n",
      "배치 인덱스 : 27\t|\t이동 손실 : 1.591451287269592\n",
      "배치 인덱스 : 28\t|\t이동 손실 : 1.5893812837271852\n",
      "배치 인덱스 : 29\t|\t이동 손실 : 1.5872312068939207\n",
      "배치 인덱스 : 30\t|\t이동 손실 : 1.588204679950591\n",
      "배치 인덱스 : 31\t|\t이동 손실 : 1.588873293250799\n",
      "배치 인덱스 : 32\t|\t이동 손실 : 1.5892579555511472\n",
      "배치 인덱스 : 33\t|\t이동 손실 : 1.5904500870143663\n",
      "배치 인덱스 : 34\t|\t이동 손실 : 1.5926146643502368\n",
      "배치 인덱스 : 35\t|\t이동 손실 : 1.5900738437970476\n",
      "배치 인덱스 : 36\t|\t이동 손실 : 1.5905256529112117\n",
      "배치 인덱스 : 37\t|\t이동 손실 : 1.5915103523354779\n",
      "배치 인덱스 : 38\t|\t이동 손실 : 1.591847560344598\n",
      "배치 인덱스 : 39\t|\t이동 손실 : 1.593905088305473\n",
      "배치 인덱스 : 40\t|\t이동 손실 : 1.5938338012230102\n",
      "배치 인덱스 : 41\t|\t이동 손실 : 1.593772558938889\n",
      "배치 인덱스 : 42\t|\t이동 손실 : 1.5940250186033023\n",
      "배치 인덱스 : 43\t|\t이동 손실 : 1.5955614230849522\n",
      "배치 인덱스 : 44\t|\t이동 손실 : 1.59814301861657\n",
      "배치 인덱스 : 45\t|\t이동 손실 : 1.5969990336376683\n",
      "배치 인덱스 : 46\t|\t이동 손실 : 1.598181397356885\n",
      "배치 인덱스 : 47\t|\t이동 손실 : 1.5988142366210614\n",
      "배치 인덱스 : 48\t|\t이동 손실 : 1.5969769249157024\n",
      "배치 인덱스 : 49\t|\t이동 손실 : 1.5948497390747065\n",
      "배치 인덱스 : 50\t|\t이동 손실 : 1.595969302981507\n",
      "배치 인덱스 : 51\t|\t이동 손실 : 1.5957668217328873\n",
      "배치 인덱스 : 52\t|\t이동 손실 : 1.594332096711644\n",
      "배치 인덱스 : 53\t|\t이동 손실 : 1.5911297091731313\n",
      "배치 인덱스 : 54\t|\t이동 손실 : 1.5904017925262446\n",
      "배치 인덱스 : 55\t|\t이동 손실 : 1.591092339583805\n",
      "배치 인덱스 : 56\t|\t이동 손실 : 1.5911955582468127\n",
      "배치 인덱스 : 57\t|\t이동 손실 : 1.5904697858054055\n",
      "배치 인덱스 : 58\t|\t이동 손실 : 1.5905741796655164\n",
      "배치 인덱스 : 59\t|\t이동 손실 : 1.5916418135166162\n",
      "배치 인덱스 : 60\t|\t이동 손실 : 1.5909974809552796\n",
      "배치 인덱스 : 61\t|\t이동 손실 : 1.5898619601803434\n",
      "배치 인덱스 : 62\t|\t이동 손실 : 1.5892958357220597\n",
      "배치 인덱스 : 63\t|\t이동 손실 : 1.5913110561668866\n",
      "배치 인덱스 : 64\t|\t이동 손실 : 1.5931657002522388\n",
      "배치 인덱스 : 65\t|\t이동 손실 : 1.5930538213614254\n",
      "배치 인덱스 : 66\t|\t이동 손실 : 1.592814824474391\n",
      "배치 인덱스 : 67\t|\t이동 손실 : 1.5898954132023972\n",
      "배치 인덱스 : 68\t|\t이동 손실 : 1.5908514779546978\n",
      "배치 인덱스 : 69\t|\t이동 손실 : 1.5917324849537433\n",
      "배치 인덱스 : 70\t|\t이동 손실 : 1.5921303856540727\n",
      "배치 인덱스 : 71\t|\t이동 손실 : 1.5928271859884255\n",
      "배치 인덱스 : 72\t|\t이동 손실 : 1.59221144081795\n",
      "배치 인덱스 : 73\t|\t이동 손실 : 1.5921180779869486\n",
      "배치 인덱스 : 74\t|\t이동 손실 : 1.5935483900705967\n",
      "배치 인덱스 : 75\t|\t이동 손실 : 1.5928418134388165\n",
      "배치 인덱스 : 76\t|\t이동 손실 : 1.5921071969069438\n",
      "배치 인덱스 : 77\t|\t이동 손실 : 1.5907220748754642\n",
      "배치 인덱스 : 78\t|\t이동 손실 : 1.5903592924528478\n",
      "배치 인덱스 : 79\t|\t이동 손실 : 1.5906038343906397\n",
      "배치 인덱스 : 80\t|\t이동 손실 : 1.5906665295730398\n",
      "배치 인덱스 : 81\t|\t이동 손실 : 1.5906680546155785\n",
      "배치 인덱스 : 82\t|\t이동 손실 : 1.5905665791178318\n",
      "배치 인덱스 : 83\t|\t이동 손실 : 1.5900567344256804\n",
      "배치 인덱스 : 84\t|\t이동 손실 : 1.590302127950331\n",
      "배치 인덱스 : 85\t|\t이동 손실 : 1.591261956580849\n",
      "배치 인덱스 : 86\t|\t이동 손실 : 1.592254640042096\n",
      "배치 인덱스 : 87\t|\t이동 손실 : 1.592359005050225\n",
      "배치 인덱스 : 88\t|\t이동 손실 : 1.5916497359115078\n",
      "배치 인덱스 : 89\t|\t이동 손실 : 1.5907813429832451\n",
      "배치 인덱스 : 90\t|\t이동 손실 : 1.590564037417317\n",
      "배치 인덱스 : 91\t|\t이동 손실 : 1.5909972501837684\n",
      "배치 인덱스 : 92\t|\t이동 손실 : 1.5911944873871338\n",
      "배치 인덱스 : 93\t|\t이동 손실 : 1.5909058565789076\n",
      "배치 인덱스 : 94\t|\t이동 손실 : 1.5908816877164333\n",
      "배치 인덱스 : 95\t|\t이동 손실 : 1.5916159215072785\n",
      "배치 인덱스 : 96\t|\t이동 손실 : 1.5921256357861542\n",
      "배치 인덱스 : 97\t|\t이동 손실 : 1.5906799703228225\n",
      "배치 인덱스 : 98\t|\t이동 손실 : 1.5907558094371443\n",
      "배치 인덱스 : 99\t|\t이동 손실 : 1.5907953453063959\n",
      "배치 인덱스 : 100\t|\t이동 손실 : 1.5899903727049869\n",
      "배치 인덱스 : 101\t|\t이동 손실 : 1.58828613687964\n",
      "배치 인덱스 : 102\t|\t이동 손실 : 1.5883705731734483\n",
      "배치 인덱스 : 103\t|\t이동 손실 : 1.5872473796972857\n",
      "배치 인덱스 : 104\t|\t이동 손실 : 1.5870059240432008\n",
      "배치 인덱스 : 105\t|\t이동 손실 : 1.587059953302707\n",
      "배치 인덱스 : 106\t|\t이동 손실 : 1.5875279012127455\n",
      "배치 인덱스 : 107\t|\t이동 손실 : 1.5874540629210292\n",
      "배치 인덱스 : 108\t|\t이동 손실 : 1.5864153509839956\n",
      "배치 인덱스 : 109\t|\t이동 손실 : 1.586825719746676\n",
      "배치 인덱스 : 110\t|\t이동 손실 : 1.5863505354872691\n",
      "배치 인덱스 : 111\t|\t이동 손실 : 1.5881990109171182\n",
      "배치 인덱스 : 112\t|\t이동 손실 : 1.5879590659014944\n",
      "배치 인덱스 : 113\t|\t이동 손실 : 1.5885932048161822\n",
      "배치 인덱스 : 114\t|\t이동 손실 : 1.5886540267778477\n",
      "배치 인덱스 : 115\t|\t이동 손실 : 1.5878224876420248\n",
      "배치 인덱스 : 116\t|\t이동 손실 : 1.5871856864700966\n",
      "배치 인덱스 : 117\t|\t이동 손실 : 1.5871565725843781\n",
      "배치 인덱스 : 118\t|\t이동 손실 : 1.5868864750661766\n",
      "배치 인덱스 : 119\t|\t이동 손실 : 1.585991497834523\n",
      "배치 인덱스 : 120\t|\t이동 손실 : 1.5867070117272617\n",
      "배치 인덱스 : 121\t|\t이동 손실 : 1.5869217661560555\n",
      "배치 인덱스 : 122\t|\t이동 손실 : 1.5867482666077648\n",
      "배치 인덱스 : 123\t|\t이동 손실 : 1.5864207129324632\n",
      "배치 인덱스 : 124\t|\t이동 손실 : 1.5873544425964352\n",
      "배치 인덱스 : 125\t|\t이동 손실 : 1.5872605386234462\n",
      "배치 인덱스 : 126\t|\t이동 손실 : 1.5870449158150377\n",
      "배치 인덱스 : 127\t|\t이동 손실 : 1.587402934208512\n",
      "배치 인덱스 : 128\t|\t이동 손실 : 1.5871537572653716\n",
      "배치 인덱스 : 129\t|\t이동 손실 : 1.5868413329124447\n",
      "배치 인덱스 : 130\t|\t이동 손실 : 1.5872123086725478\n",
      "배치 인덱스 : 131\t|\t이동 손실 : 1.5869752755670832\n",
      "배치 인덱스 : 132\t|\t이동 손실 : 1.5877991645856007\n",
      "배치 인덱스 : 133\t|\t이동 손실 : 1.5873404047382407\n",
      "배치 인덱스 : 134\t|\t이동 손실 : 1.58726432941578\n",
      "배치 인덱스 : 135\t|\t이동 손실 : 1.5870290679090158\n",
      "배치 인덱스 : 136\t|\t이동 손실 : 1.5865542018500551\n",
      "배치 인덱스 : 137\t|\t이동 손실 : 1.586632785589798\n",
      "배치 인덱스 : 138\t|\t이동 손실 : 1.5863276059678983\n",
      "배치 인덱스 : 139\t|\t이동 손실 : 1.5854214719363615\n",
      "배치 인덱스 : 140\t|\t이동 손실 : 1.585382904566771\n",
      "배치 인덱스 : 141\t|\t이동 손실 : 1.585542483229032\n",
      "배치 인덱스 : 142\t|\t이동 손실 : 1.5849003525047027\n",
      "배치 인덱스 : 143\t|\t이동 손실 : 1.5845736786723128\n",
      "배치 인덱스 : 144\t|\t이동 손실 : 1.5844063060037012\n",
      "배치 인덱스 : 145\t|\t이동 손실 : 1.5839358731491917\n",
      "배치 인덱스 : 146\t|\t이동 손실 : 1.5835835130847222\n",
      "배치 인덱스 : 147\t|\t이동 손실 : 1.5829448611349666\n",
      "배치 인덱스 : 148\t|\t이동 손실 : 1.5834255914560094\n",
      "배치 인덱스 : 149\t|\t이동 손실 : 1.5837752493222548\n",
      "배치 인덱스 : 150\t|\t이동 손실 : 1.5841402857508873\n",
      "배치 인덱스 : 151\t|\t이동 손실 : 1.5843781672025974\n",
      "배치 인덱스 : 152\t|\t이동 손실 : 1.5839257614285331\n",
      "배치 인덱스 : 153\t|\t이동 손실 : 1.583482068080406\n",
      "배치 인덱스 : 154\t|\t이동 손실 : 1.583557458846799\n",
      "배치 인덱스 : 155\t|\t이동 손실 : 1.5837380626262756\n",
      "배치 인덱스 : 156\t|\t이동 손실 : 1.5831992557853642\n",
      "배치 인덱스 : 157\t|\t이동 손실 : 1.5836454403551312\n",
      "배치 인덱스 : 158\t|\t이동 손실 : 1.5833379517561228\n",
      "배치 인덱스 : 159\t|\t이동 손실 : 1.583531027287244\n",
      "배치 인덱스 : 160\t|\t이동 손실 : 1.583167119796231\n",
      "배치 인덱스 : 161\t|\t이동 손실 : 1.5830741215635222\n",
      "배치 인덱스 : 162\t|\t이동 손실 : 1.5831711672566413\n",
      "배치 인덱스 : 163\t|\t이동 손실 : 1.5838782583794937\n",
      "배치 인덱스 : 164\t|\t이동 손실 : 1.5848772923151646\n",
      "배치 인덱스 : 165\t|\t이동 손실 : 1.584426151700766\n",
      "배치 인덱스 : 166\t|\t이동 손실 : 1.584346861182572\n",
      "배치 인덱스 : 167\t|\t이동 손실 : 1.5846151510874424\n",
      "배치 인덱스 : 168\t|\t이동 손실 : 1.5846828328081837\n",
      "배치 인덱스 : 169\t|\t이동 손실 : 1.5846072877154624\n",
      "배치 인덱스 : 170\t|\t이동 손실 : 1.5855459344317335\n",
      "배치 인덱스 : 171\t|\t이동 손실 : 1.5853974569675529\n",
      "배치 인덱스 : 172\t|\t이동 손실 : 1.584600088224245\n",
      "배치 인덱스 : 173\t|\t이동 손실 : 1.5846605280349988\n",
      "배치 인덱스 : 174\t|\t이동 손실 : 1.5843417269842959\n",
      "배치 인덱스 : 175\t|\t이동 손실 : 1.5841335647485466\n",
      "배치 인덱스 : 176\t|\t이동 손실 : 1.5840922378550808\n",
      "배치 인덱스 : 177\t|\t이동 손실 : 1.584508721078379\n",
      "배치 인덱스 : 178\t|\t이동 손실 : 1.5843455684917591\n",
      "배치 인덱스 : 179\t|\t이동 손실 : 1.584088456630706\n",
      "배치 인덱스 : 180\t|\t이동 손실 : 1.5836459233615932\n",
      "배치 인덱스 : 181\t|\t이동 손실 : 1.5838752140055639\n",
      "배치 인덱스 : 182\t|\t이동 손실 : 1.5836894492634\n",
      "배치 인덱스 : 183\t|\t이동 손실 : 1.5836032013530308\n",
      "배치 인덱스 : 184\t|\t이동 손실 : 1.5837987841786556\n",
      "배치 인덱스 : 185\t|\t이동 손실 : 1.5829441714030432\n",
      "배치 인덱스 : 186\t|\t이동 손실 : 1.5833256595274974\n",
      "배치 인덱스 : 187\t|\t이동 손실 : 1.5833459027270045\n",
      "배치 인덱스 : 188\t|\t이동 손실 : 1.5825579816071436\n",
      "배치 인덱스 : 189\t|\t이동 손실 : 1.582445398129914\n",
      "배치 인덱스 : 190\t|\t이동 손실 : 1.5824942463979663\n",
      "배치 인덱스 : 191\t|\t이동 손실 : 1.582917151351769\n",
      "배치 인덱스 : 192\t|\t이동 손실 : 1.582376214506712\n",
      "배치 인덱스 : 193\t|\t이동 손실 : 1.5823035277042186\n",
      "배치 인덱스 : 194\t|\t이동 손실 : 1.5825623506154762\n",
      "배치 인덱스 : 195\t|\t이동 손실 : 1.5818643886215826\n",
      "배치 인덱스 : 196\t|\t이동 손실 : 1.581297652370433\n",
      "배치 인덱스 : 197\t|\t이동 손실 : 1.5813445352544682\n",
      "배치 인덱스 : 198\t|\t이동 손실 : 1.5810297997153577\n",
      "배치 인덱스 : 199\t|\t이동 손실 : 1.5807402402162545\n",
      "배치 인덱스 : 200\t|\t이동 손실 : 1.580130804237441\n",
      "배치 인덱스 : 201\t|\t이동 손실 : 1.5806730684667523\n",
      "배치 인덱스 : 202\t|\t이동 손실 : 1.5805724125190312\n",
      "배치 인덱스 : 203\t|\t이동 손실 : 1.5808707218544147\n",
      "배치 인덱스 : 204\t|\t이동 손실 : 1.5808451239655648\n",
      "배치 인덱스 : 205\t|\t이동 손실 : 1.58061287877629\n",
      "배치 인덱스 : 206\t|\t이동 손실 : 1.5804367946541817\n",
      "배치 인덱스 : 207\t|\t이동 손실 : 1.5804963364050928\n",
      "배치 인덱스 : 208\t|\t이동 손실 : 1.5801521203164268\n",
      "배치 인덱스 : 209\t|\t이동 손실 : 1.5796990655717384\n",
      "배치 인덱스 : 210\t|\t이동 손실 : 1.5795219356979793\n",
      "배치 인덱스 : 211\t|\t이동 손실 : 1.5791014376676296\n",
      "배치 인덱스 : 212\t|\t이동 손실 : 1.5793172356108534\n",
      "배치 인덱스 : 213\t|\t이동 손실 : 1.579303539244927\n",
      "배치 인덱스 : 214\t|\t이동 손실 : 1.5792852739955094\n",
      "배치 인덱스 : 215\t|\t이동 손실 : 1.5792207541289143\n",
      "배치 인덱스 : 216\t|\t이동 손실 : 1.578838791166032\n",
      "배치 인덱스 : 217\t|\t이동 손실 : 1.5783928660077775\n",
      "배치 인덱스 : 218\t|\t이동 손실 : 1.5781177217013205\n",
      "배치 인덱스 : 219\t|\t이동 손실 : 1.5782138109207142\n",
      "배치 인덱스 : 220\t|\t이동 손실 : 1.5781123816157887\n",
      "배치 인덱스 : 221\t|\t이동 손실 : 1.5776125042288143\n",
      "배치 인덱스 : 222\t|\t이동 손실 : 1.5779036112430374\n",
      "배치 인덱스 : 223\t|\t이동 손실 : 1.5775852602507376\n",
      "배치 인덱스 : 224\t|\t이동 손실 : 1.577478413052028\n",
      "배치 인덱스 : 225\t|\t이동 손실 : 1.577394029735463\n",
      "배치 인덱스 : 226\t|\t이동 손실 : 1.5774892006676617\n",
      "Epoch: 05 | Time: 14m 57s\n",
      "\tTrain Loss: 1.577 | Train PPL: 4.843\n",
      "\tValidation Loss: 2.006 | Validation PPL: 7.434\n",
      "에폭 : 5\n",
      "배치 인덱스 : 0\t|\t이동 손실 : 1.3948267698287964\n",
      "배치 인덱스 : 1\t|\t이동 손실 : 1.324039101600647\n",
      "배치 인덱스 : 2\t|\t이동 손실 : 1.3249700864156086\n",
      "배치 인덱스 : 3\t|\t이동 손실 : 1.344305396080017\n",
      "배치 인덱스 : 4\t|\t이동 손실 : 1.347467803955078\n",
      "배치 인덱스 : 5\t|\t이동 손실 : 1.3429320653279622\n",
      "배치 인덱스 : 6\t|\t이동 손실 : 1.3298560551234653\n",
      "배치 인덱스 : 7\t|\t이동 손실 : 1.3248315304517746\n",
      "배치 인덱스 : 8\t|\t이동 손실 : 1.3306021690368652\n",
      "배치 인덱스 : 9\t|\t이동 손실 : 1.337401306629181\n",
      "배치 인덱스 : 10\t|\t이동 손실 : 1.3395197174765847\n",
      "배치 인덱스 : 11\t|\t이동 손실 : 1.3370405038197835\n",
      "배치 인덱스 : 12\t|\t이동 손실 : 1.3248618199275088\n",
      "배치 인덱스 : 13\t|\t이동 손실 : 1.3224641510418482\n",
      "배치 인덱스 : 14\t|\t이동 손실 : 1.3296714623769124\n",
      "배치 인덱스 : 15\t|\t이동 손실 : 1.3337874710559845\n",
      "배치 인덱스 : 16\t|\t이동 손실 : 1.3326829531613518\n",
      "배치 인덱스 : 17\t|\t이동 손실 : 1.3235627346568637\n",
      "배치 인덱스 : 18\t|\t이동 손실 : 1.3224503993988037\n",
      "배치 인덱스 : 19\t|\t이동 손실 : 1.3202060222625733\n",
      "배치 인덱스 : 20\t|\t이동 손실 : 1.3237755923044114\n",
      "배치 인덱스 : 21\t|\t이동 손실 : 1.3209594867446206\n",
      "배치 인덱스 : 22\t|\t이동 손실 : 1.322958194691202\n",
      "배치 인덱스 : 23\t|\t이동 손실 : 1.3247015625238419\n",
      "배치 인덱스 : 24\t|\t이동 손실 : 1.3257306051254272\n",
      "배치 인덱스 : 25\t|\t이동 손실 : 1.3293807827509365\n",
      "배치 인덱스 : 26\t|\t이동 손실 : 1.3305338709442702\n",
      "배치 인덱스 : 27\t|\t이동 손실 : 1.331295290163585\n",
      "배치 인덱스 : 28\t|\t이동 손실 : 1.3308048207184364\n",
      "배치 인덱스 : 29\t|\t이동 손실 : 1.3299432873725892\n",
      "배치 인덱스 : 30\t|\t이동 손실 : 1.3312956825379403\n",
      "배치 인덱스 : 31\t|\t이동 손실 : 1.3312132060527802\n",
      "배치 인덱스 : 32\t|\t이동 손실 : 1.3247284455732866\n",
      "배치 인덱스 : 33\t|\t이동 손실 : 1.3233794815400068\n",
      "배치 인덱스 : 34\t|\t이동 손실 : 1.32221018246242\n",
      "배치 인덱스 : 35\t|\t이동 손실 : 1.3256328470177121\n",
      "배치 인덱스 : 36\t|\t이동 손실 : 1.3251427766439077\n",
      "배치 인덱스 : 37\t|\t이동 손실 : 1.3278066892372935\n",
      "배치 인덱스 : 38\t|\t이동 손실 : 1.3294409452340543\n",
      "배치 인덱스 : 39\t|\t이동 손실 : 1.3292788803577424\n",
      "배치 인덱스 : 40\t|\t이동 손실 : 1.3302562294936764\n",
      "배치 인덱스 : 41\t|\t이동 손실 : 1.3325283442224778\n",
      "배치 인덱스 : 42\t|\t이동 손실 : 1.334606400755949\n",
      "배치 인덱스 : 43\t|\t이동 손실 : 1.3339449383995752\n",
      "배치 인덱스 : 44\t|\t이동 손실 : 1.3347240474489002\n",
      "배치 인덱스 : 45\t|\t이동 손실 : 1.3358356771261797\n",
      "배치 인덱스 : 46\t|\t이동 손실 : 1.3354236115800575\n",
      "배치 인덱스 : 47\t|\t이동 손실 : 1.3355195447802546\n",
      "배치 인덱스 : 48\t|\t이동 손실 : 1.3346925925235362\n",
      "배치 인덱스 : 49\t|\t이동 손실 : 1.3345154166221622\n",
      "배치 인덱스 : 50\t|\t이동 손실 : 1.3353196031907029\n",
      "배치 인덱스 : 51\t|\t이동 손실 : 1.33501953803576\n",
      "배치 인덱스 : 52\t|\t이동 손실 : 1.3351548730202445\n",
      "배치 인덱스 : 53\t|\t이동 손실 : 1.337499093126368\n",
      "배치 인덱스 : 54\t|\t이동 손실 : 1.3371342268857092\n",
      "배치 인덱스 : 55\t|\t이동 손실 : 1.3386902234383995\n",
      "배치 인덱스 : 56\t|\t이동 손실 : 1.3380097025319153\n",
      "배치 인덱스 : 57\t|\t이동 손실 : 1.3394253274490098\n",
      "배치 인덱스 : 58\t|\t이동 손실 : 1.338499178320675\n",
      "배치 인덱스 : 59\t|\t이동 손실 : 1.3376194616158807\n",
      "배치 인덱스 : 60\t|\t이동 손실 : 1.3371230344303322\n",
      "배치 인덱스 : 61\t|\t이동 손실 : 1.3397211893912289\n",
      "배치 인덱스 : 62\t|\t이동 손실 : 1.3397894378692388\n",
      "배치 인덱스 : 63\t|\t이동 손실 : 1.339976128190756\n",
      "배치 인덱스 : 64\t|\t이동 손실 : 1.3412308271114646\n",
      "배치 인덱스 : 65\t|\t이동 손실 : 1.342386466084105\n",
      "배치 인덱스 : 66\t|\t이동 손실 : 1.3415834512283555\n",
      "배치 인덱스 : 67\t|\t이동 손실 : 1.3422520967090834\n",
      "배치 인덱스 : 68\t|\t이동 손실 : 1.343851739081784\n",
      "배치 인덱스 : 69\t|\t이동 손실 : 1.345332891600473\n",
      "배치 인덱스 : 70\t|\t이동 손실 : 1.3445951955419195\n",
      "배치 인덱스 : 71\t|\t이동 손실 : 1.3437015861272816\n",
      "배치 인덱스 : 72\t|\t이동 손실 : 1.3433921386117809\n",
      "배치 인덱스 : 73\t|\t이동 손실 : 1.3432333195531694\n",
      "배치 인덱스 : 74\t|\t이동 손실 : 1.3440429894129438\n",
      "배치 인덱스 : 75\t|\t이동 손실 : 1.3439653437388572\n",
      "배치 인덱스 : 76\t|\t이동 손실 : 1.3441790512629919\n",
      "배치 인덱스 : 77\t|\t이동 손실 : 1.3434469745709348\n",
      "배치 인덱스 : 78\t|\t이동 손실 : 1.3442615798757047\n",
      "배치 인덱스 : 79\t|\t이동 손실 : 1.3449672251939775\n",
      "배치 인덱스 : 80\t|\t이동 손실 : 1.3456905520992515\n",
      "배치 인덱스 : 81\t|\t이동 손실 : 1.3451951713096806\n",
      "배치 인덱스 : 82\t|\t이동 손실 : 1.3449369697685702\n",
      "배치 인덱스 : 83\t|\t이동 손실 : 1.344993892170134\n",
      "배치 인덱스 : 84\t|\t이동 손실 : 1.34523302527035\n",
      "배치 인덱스 : 85\t|\t이동 손실 : 1.3463413424270099\n",
      "배치 인덱스 : 86\t|\t이동 손실 : 1.345062407953986\n",
      "배치 인덱스 : 87\t|\t이동 손실 : 1.3449501015923242\n",
      "배치 인덱스 : 88\t|\t이동 손실 : 1.3446556811922055\n",
      "배치 인덱스 : 89\t|\t이동 손실 : 1.344770599736108\n",
      "배치 인덱스 : 90\t|\t이동 손실 : 1.344012995342632\n",
      "배치 인덱스 : 91\t|\t이동 손실 : 1.3437694933103481\n",
      "배치 인덱스 : 92\t|\t이동 손실 : 1.3427510748627367\n",
      "배치 인덱스 : 93\t|\t이동 손실 : 1.3429201093125853\n",
      "배치 인덱스 : 94\t|\t이동 손실 : 1.343814600141425\n",
      "배치 인덱스 : 95\t|\t이동 손실 : 1.3441773628195128\n",
      "배치 인덱스 : 96\t|\t이동 손실 : 1.3441265735429588\n",
      "배치 인덱스 : 97\t|\t이동 손실 : 1.3445404780154326\n",
      "배치 인덱스 : 98\t|\t이동 손실 : 1.3444315508158522\n",
      "배치 인덱스 : 99\t|\t이동 손실 : 1.343950597047806\n",
      "배치 인덱스 : 100\t|\t이동 손실 : 1.3427091494645225\n",
      "배치 인덱스 : 101\t|\t이동 손실 : 1.3417616334615972\n",
      "배치 인덱스 : 102\t|\t이동 손실 : 1.3423353468330164\n",
      "배치 인덱스 : 103\t|\t이동 손실 : 1.3427843462962372\n",
      "배치 인덱스 : 104\t|\t이동 손실 : 1.3436116434278944\n",
      "배치 인덱스 : 105\t|\t이동 손실 : 1.343884253276969\n",
      "배치 인덱스 : 106\t|\t이동 손실 : 1.344161256451473\n",
      "배치 인덱스 : 107\t|\t이동 손실 : 1.3438770947632968\n",
      "배치 인덱스 : 108\t|\t이동 손실 : 1.3429061885273785\n",
      "배치 인덱스 : 109\t|\t이동 손실 : 1.3435077157887547\n",
      "배치 인덱스 : 110\t|\t이동 손실 : 1.3445046753496739\n",
      "배치 인덱스 : 111\t|\t이동 손실 : 1.3444004740033833\n",
      "배치 인덱스 : 112\t|\t이동 손실 : 1.3440482236642755\n",
      "배치 인덱스 : 113\t|\t이동 손실 : 1.3427500337885139\n",
      "배치 인덱스 : 114\t|\t이동 손실 : 1.3424385568369992\n",
      "배치 인덱스 : 115\t|\t이동 손실 : 1.3439544922318953\n",
      "배치 인덱스 : 116\t|\t이동 손실 : 1.3438716352495375\n",
      "배치 인덱스 : 117\t|\t이동 손실 : 1.3432310435731534\n",
      "배치 인덱스 : 118\t|\t이동 손실 : 1.3427240878594022\n",
      "배치 인덱스 : 119\t|\t이동 손실 : 1.3423903952042262\n",
      "배치 인덱스 : 120\t|\t이동 손실 : 1.3424111919954789\n",
      "배치 인덱스 : 121\t|\t이동 손실 : 1.343046464880959\n",
      "배치 인덱스 : 122\t|\t이동 손실 : 1.343515867140235\n",
      "배치 인덱스 : 123\t|\t이동 손실 : 1.3448706932606236\n",
      "배치 인덱스 : 124\t|\t이동 손실 : 1.344621563911438\n",
      "배치 인덱스 : 125\t|\t이동 손실 : 1.3445706679707483\n",
      "배치 인덱스 : 126\t|\t이동 손실 : 1.3448633255921012\n",
      "배치 인덱스 : 127\t|\t이동 손실 : 1.3446485018357635\n",
      "배치 인덱스 : 128\t|\t이동 손실 : 1.344726332398348\n",
      "배치 인덱스 : 129\t|\t이동 손실 : 1.3449391768528864\n",
      "배치 인덱스 : 130\t|\t이동 손실 : 1.3449431539491843\n",
      "배치 인덱스 : 131\t|\t이동 손실 : 1.3451400859789415\n",
      "배치 인덱스 : 132\t|\t이동 손실 : 1.3447446500448357\n",
      "배치 인덱스 : 133\t|\t이동 손실 : 1.3449259969725538\n",
      "배치 인덱스 : 134\t|\t이동 손실 : 1.34460785124037\n",
      "배치 인덱스 : 135\t|\t이동 손실 : 1.3443572924417608\n",
      "배치 인덱스 : 136\t|\t이동 손실 : 1.3441494146402735\n",
      "배치 인덱스 : 137\t|\t이동 손실 : 1.344617007435232\n",
      "배치 인덱스 : 138\t|\t이동 손실 : 1.3444380039791408\n",
      "배치 인덱스 : 139\t|\t이동 손실 : 1.3442616598946706\n",
      "배치 인덱스 : 140\t|\t이동 손실 : 1.3445422252019246\n",
      "배치 인덱스 : 141\t|\t이동 손실 : 1.345154497824924\n",
      "배치 인덱스 : 142\t|\t이동 손실 : 1.3449579969152703\n",
      "배치 인덱스 : 143\t|\t이동 손실 : 1.3458289437823825\n",
      "배치 인덱스 : 144\t|\t이동 손실 : 1.3475363986245517\n",
      "배치 인덱스 : 145\t|\t이동 손실 : 1.3476817942645452\n",
      "배치 인덱스 : 146\t|\t이동 손실 : 1.3477232529192555\n",
      "배치 인덱스 : 147\t|\t이동 손실 : 1.3483495808936454\n",
      "배치 인덱스 : 148\t|\t이동 손실 : 1.3483153837639215\n",
      "배치 인덱스 : 149\t|\t이동 손실 : 1.3477881280581157\n",
      "배치 인덱스 : 150\t|\t이동 손실 : 1.347345677432635\n",
      "배치 인덱스 : 151\t|\t이동 손실 : 1.3477258603823812\n",
      "배치 인덱스 : 152\t|\t이동 손실 : 1.3473893139097426\n",
      "배치 인덱스 : 153\t|\t이동 손실 : 1.3469538061649768\n",
      "배치 인덱스 : 154\t|\t이동 손실 : 1.3464124325783022\n",
      "배치 인덱스 : 155\t|\t이동 손실 : 1.346273192228415\n",
      "배치 인덱스 : 156\t|\t이동 손실 : 1.345910110291402\n",
      "배치 인덱스 : 157\t|\t이동 손실 : 1.3461588938024978\n",
      "배치 인덱스 : 158\t|\t이동 손실 : 1.345826817758428\n",
      "배치 인덱스 : 159\t|\t이동 손실 : 1.3457721978425978\n",
      "배치 인덱스 : 160\t|\t이동 손실 : 1.345961917261159\n",
      "배치 인덱스 : 161\t|\t이동 손실 : 1.3458360676412227\n",
      "배치 인덱스 : 162\t|\t이동 손실 : 1.3464832123071866\n",
      "배치 인덱스 : 163\t|\t이동 손실 : 1.3465967643551706\n",
      "배치 인덱스 : 164\t|\t이동 손실 : 1.3464171337358875\n",
      "배치 인덱스 : 165\t|\t이동 손실 : 1.3467341783535045\n",
      "배치 인덱스 : 166\t|\t이동 손실 : 1.3463769344512568\n",
      "배치 인덱스 : 167\t|\t이동 손실 : 1.34645816825685\n",
      "배치 인덱스 : 168\t|\t이동 손실 : 1.346618603672501\n",
      "배치 인덱스 : 169\t|\t이동 손실 : 1.3466458460863893\n",
      "배치 인덱스 : 170\t|\t이동 손실 : 1.346109791805869\n",
      "배치 인덱스 : 171\t|\t이동 손실 : 1.3464226632617236\n",
      "배치 인덱스 : 172\t|\t이동 손실 : 1.3468106406272486\n",
      "배치 인덱스 : 173\t|\t이동 손실 : 1.347227631629198\n",
      "배치 인덱스 : 174\t|\t이동 손실 : 1.3473694617407659\n",
      "배치 인덱스 : 175\t|\t이동 손실 : 1.3473676869815043\n",
      "배치 인덱스 : 176\t|\t이동 손실 : 1.3468937436066102\n",
      "배치 인덱스 : 177\t|\t이동 손실 : 1.346456933557317\n",
      "배치 인덱스 : 178\t|\t이동 손실 : 1.3467137001080216\n",
      "배치 인덱스 : 179\t|\t이동 손실 : 1.3468558973736229\n",
      "배치 인덱스 : 180\t|\t이동 손실 : 1.3465517917390681\n",
      "배치 인덱스 : 181\t|\t이동 손실 : 1.346373605204152\n",
      "배치 인덱스 : 182\t|\t이동 손실 : 1.346225076685837\n",
      "배치 인덱스 : 183\t|\t이동 손실 : 1.3463426977396005\n",
      "배치 인덱스 : 184\t|\t이동 손실 : 1.3466740981952559\n",
      "배치 인덱스 : 185\t|\t이동 손실 : 1.3469643868425836\n",
      "배치 인덱스 : 186\t|\t이동 손실 : 1.3474632246609035\n",
      "배치 인덱스 : 187\t|\t이동 손실 : 1.347369606190539\n",
      "배치 인덱스 : 188\t|\t이동 손실 : 1.3469927418168886\n",
      "배치 인덱스 : 189\t|\t이동 손실 : 1.3476545038976162\n",
      "배치 인덱스 : 190\t|\t이동 손실 : 1.3475900395378386\n",
      "배치 인덱스 : 191\t|\t이동 손실 : 1.3477954349170123\n",
      "배치 인덱스 : 192\t|\t이동 손실 : 1.347621614451235\n",
      "배치 인덱스 : 193\t|\t이동 손실 : 1.3474470125031222\n",
      "배치 인덱스 : 194\t|\t이동 손실 : 1.34774578045576\n",
      "배치 인덱스 : 195\t|\t이동 손실 : 1.348735646933925\n",
      "배치 인덱스 : 196\t|\t이동 손실 : 1.348228040685508\n",
      "배치 인덱스 : 197\t|\t이동 손실 : 1.348130219512515\n",
      "배치 인덱스 : 198\t|\t이동 손실 : 1.3482271444857414\n",
      "배치 인덱스 : 199\t|\t이동 손실 : 1.348301305174827\n",
      "배치 인덱스 : 200\t|\t이동 손실 : 1.3481854805305815\n",
      "배치 인덱스 : 201\t|\t이동 손실 : 1.3486192078873656\n",
      "배치 인덱스 : 202\t|\t이동 손실 : 1.3483043697667232\n",
      "배치 인덱스 : 203\t|\t이동 손실 : 1.34844116486755\n",
      "배치 인덱스 : 204\t|\t이동 손실 : 1.3491541560103246\n",
      "배치 인덱스 : 205\t|\t이동 손실 : 1.3492005073908455\n",
      "배치 인덱스 : 206\t|\t이동 손실 : 1.3492306113818986\n",
      "배치 인덱스 : 207\t|\t이동 손실 : 1.3486140112464238\n",
      "배치 인덱스 : 208\t|\t이동 손실 : 1.3487446216875278\n",
      "배치 인덱스 : 209\t|\t이동 손실 : 1.3491091410319003\n",
      "배치 인덱스 : 210\t|\t이동 손실 : 1.349254670301319\n",
      "배치 인덱스 : 211\t|\t이동 손실 : 1.3496184287206174\n",
      "배치 인덱스 : 212\t|\t이동 손실 : 1.349486959372327\n",
      "배치 인덱스 : 213\t|\t이동 손실 : 1.3495233443295835\n",
      "배치 인덱스 : 214\t|\t이동 손실 : 1.349655486262121\n",
      "배치 인덱스 : 215\t|\t이동 손실 : 1.3502170366269564\n",
      "배치 인덱스 : 216\t|\t이동 손실 : 1.3498637703706584\n",
      "배치 인덱스 : 217\t|\t이동 손실 : 1.3499526643971778\n",
      "배치 인덱스 : 218\t|\t이동 손실 : 1.3497301291113024\n",
      "배치 인덱스 : 219\t|\t이동 손실 : 1.3498967739668752\n",
      "배치 인덱스 : 220\t|\t이동 손실 : 1.3499128926393666\n",
      "배치 인덱스 : 221\t|\t이동 손실 : 1.349645409498128\n",
      "배치 인덱스 : 222\t|\t이동 손실 : 1.3494628331051806\n",
      "배치 인덱스 : 223\t|\t이동 손실 : 1.3498584404587737\n",
      "배치 인덱스 : 224\t|\t이동 손실 : 1.3497903850343484\n",
      "배치 인덱스 : 225\t|\t이동 손실 : 1.3495744060626065\n",
      "배치 인덱스 : 226\t|\t이동 손실 : 1.3496363625127306\n",
      "Epoch: 06 | Time: 14m 49s\n",
      "\tTrain Loss: 1.350 | Train PPL: 3.856\n",
      "\tValidation Loss: 1.978 | Validation PPL: 7.229\n",
      "에폭 : 6\n",
      "배치 인덱스 : 0\t|\t이동 손실 : 1.1705987453460693\n",
      "배치 인덱스 : 1\t|\t이동 손실 : 1.155554711818695\n",
      "배치 인덱스 : 2\t|\t이동 손실 : 1.1379153331120808\n",
      "배치 인덱스 : 3\t|\t이동 손실 : 1.1505529880523682\n",
      "배치 인덱스 : 4\t|\t이동 손실 : 1.142930006980896\n",
      "배치 인덱스 : 5\t|\t이동 손실 : 1.1488954226175945\n",
      "배치 인덱스 : 6\t|\t이동 손실 : 1.1363320861543929\n",
      "배치 인덱스 : 7\t|\t이동 손실 : 1.142825961112976\n",
      "배치 인덱스 : 8\t|\t이동 손실 : 1.144852187898424\n",
      "배치 인덱스 : 9\t|\t이동 손실 : 1.1370665788650514\n",
      "배치 인덱스 : 10\t|\t이동 손실 : 1.131847609173168\n",
      "배치 인덱스 : 11\t|\t이동 손실 : 1.1368711690107982\n",
      "배치 인덱스 : 12\t|\t이동 손실 : 1.1427076137982883\n",
      "배치 인덱스 : 13\t|\t이동 손실 : 1.1434655274663654\n",
      "배치 인덱스 : 14\t|\t이동 손실 : 1.145771106084188\n",
      "배치 인덱스 : 15\t|\t이동 손실 : 1.143847167491913\n",
      "배치 인덱스 : 16\t|\t이동 손실 : 1.1428201899808998\n",
      "배치 인덱스 : 17\t|\t이동 손실 : 1.1463702585962086\n",
      "배치 인덱스 : 18\t|\t이동 손실 : 1.1475723291698257\n",
      "배치 인덱스 : 19\t|\t이동 손실 : 1.1493767559528352\n",
      "배치 인덱스 : 20\t|\t이동 손실 : 1.1468011424655007\n",
      "배치 인덱스 : 21\t|\t이동 손실 : 1.1510483026504517\n",
      "배치 인덱스 : 22\t|\t이동 손실 : 1.1432656049728394\n",
      "배치 인덱스 : 23\t|\t이동 손실 : 1.1451738774776459\n",
      "배치 인덱스 : 24\t|\t이동 손실 : 1.1439275646209717\n",
      "배치 인덱스 : 25\t|\t이동 손실 : 1.1438612112632165\n",
      "배치 인덱스 : 26\t|\t이동 손실 : 1.1435026769284848\n",
      "배치 인덱스 : 27\t|\t이동 손실 : 1.1424701469285148\n",
      "배치 인덱스 : 28\t|\t이동 손실 : 1.1410238208441899\n",
      "배치 인덱스 : 29\t|\t이동 손실 : 1.1414822697639466\n",
      "배치 인덱스 : 30\t|\t이동 손실 : 1.1434684991836548\n",
      "배치 인덱스 : 31\t|\t이동 손실 : 1.1443476304411888\n",
      "배치 인덱스 : 32\t|\t이동 손실 : 1.1451772848765056\n",
      "배치 인덱스 : 33\t|\t이동 손실 : 1.1474954135277693\n",
      "배치 인덱스 : 34\t|\t이동 손실 : 1.1494407619748797\n",
      "배치 인덱스 : 35\t|\t이동 손실 : 1.1476544539133708\n",
      "배치 인덱스 : 36\t|\t이동 손실 : 1.1489375346415753\n",
      "배치 인덱스 : 37\t|\t이동 손실 : 1.1492090193848863\n",
      "배치 인덱스 : 38\t|\t이동 손실 : 1.1482314054782576\n",
      "배치 인덱스 : 39\t|\t이동 손실 : 1.1473719686269763\n",
      "배치 인덱스 : 40\t|\t이동 손실 : 1.14769980093328\n",
      "배치 인덱스 : 41\t|\t이동 손실 : 1.1446574500628883\n",
      "배치 인덱스 : 42\t|\t이동 손실 : 1.1450265618257747\n",
      "배치 인덱스 : 43\t|\t이동 손실 : 1.1462318680503154\n",
      "배치 인덱스 : 44\t|\t이동 손실 : 1.147176750500997\n",
      "배치 인덱스 : 45\t|\t이동 손실 : 1.147342746672423\n",
      "배치 인덱스 : 46\t|\t이동 손실 : 1.1484714442111077\n",
      "배치 인덱스 : 47\t|\t이동 손실 : 1.1459331264098487\n",
      "배치 인덱스 : 48\t|\t이동 손실 : 1.1445702509004243\n",
      "배치 인덱스 : 49\t|\t이동 손실 : 1.145265052318573\n",
      "배치 인덱스 : 50\t|\t이동 손실 : 1.1443548459632724\n",
      "배치 인덱스 : 51\t|\t이동 손실 : 1.14713765336917\n",
      "배치 인덱스 : 52\t|\t이동 손실 : 1.1462795509482329\n",
      "배치 인덱스 : 53\t|\t이동 손실 : 1.1440445295086612\n",
      "배치 인덱스 : 54\t|\t이동 손실 : 1.1434423663399436\n",
      "배치 인덱스 : 55\t|\t이동 손실 : 1.1432897980724062\n",
      "배치 인덱스 : 56\t|\t이동 손실 : 1.1448407131328917\n",
      "배치 인덱스 : 57\t|\t이동 손실 : 1.145403109747788\n",
      "배치 인덱스 : 58\t|\t이동 손실 : 1.1447772555432076\n",
      "배치 인덱스 : 59\t|\t이동 손실 : 1.1442484994729358\n",
      "배치 인덱스 : 60\t|\t이동 손실 : 1.1451655645839502\n",
      "배치 인덱스 : 61\t|\t이동 손실 : 1.1470509767532349\n",
      "배치 인덱스 : 62\t|\t이동 손실 : 1.1462566341672624\n",
      "배치 인덱스 : 63\t|\t이동 손실 : 1.1471523325890303\n",
      "배치 인덱스 : 64\t|\t이동 손실 : 1.1474712023368248\n",
      "배치 인덱스 : 65\t|\t이동 손실 : 1.1467765479376821\n",
      "배치 인덱스 : 66\t|\t이동 손실 : 1.1470524054854663\n",
      "배치 인덱스 : 67\t|\t이동 손실 : 1.1471773456124699\n",
      "배치 인덱스 : 68\t|\t이동 손실 : 1.1483546357223953\n",
      "배치 인덱스 : 69\t|\t이동 손실 : 1.1497924123491559\n",
      "배치 인덱스 : 70\t|\t이동 손실 : 1.1515218489606613\n",
      "배치 인덱스 : 71\t|\t이동 손실 : 1.150834129916297\n",
      "배치 인덱스 : 72\t|\t이동 손실 : 1.14969002384029\n",
      "배치 인덱스 : 73\t|\t이동 손실 : 1.150937268862853\n",
      "배치 인덱스 : 74\t|\t이동 손실 : 1.1523040707906085\n",
      "배치 인덱스 : 75\t|\t이동 손실 : 1.1519910473572579\n",
      "배치 인덱스 : 76\t|\t이동 손실 : 1.1504423153864871\n",
      "배치 인덱스 : 77\t|\t이동 손실 : 1.1511305692868352\n",
      "배치 인덱스 : 78\t|\t이동 손실 : 1.1513529080378855\n",
      "배치 인덱스 : 79\t|\t이동 손실 : 1.1504782423377033\n",
      "배치 인덱스 : 80\t|\t이동 손실 : 1.1506893178563056\n",
      "배치 인덱스 : 81\t|\t이동 손실 : 1.150224553375709\n",
      "배치 인덱스 : 82\t|\t이동 손실 : 1.1500455011804416\n",
      "배치 인덱스 : 83\t|\t이동 손실 : 1.1508701174032117\n",
      "배치 인덱스 : 84\t|\t이동 손실 : 1.1508858792922072\n",
      "배치 인덱스 : 85\t|\t이동 손실 : 1.1523965209029439\n",
      "배치 인덱스 : 86\t|\t이동 손실 : 1.1526400042676375\n",
      "배치 인덱스 : 87\t|\t이동 손실 : 1.1531378789381546\n",
      "배치 인덱스 : 88\t|\t이동 손실 : 1.1530012468273718\n",
      "배치 인덱스 : 89\t|\t이동 손실 : 1.1529567533069185\n",
      "배치 인덱스 : 90\t|\t이동 손실 : 1.1523855138611006\n",
      "배치 인덱스 : 91\t|\t이동 손실 : 1.152528660452884\n",
      "배치 인덱스 : 92\t|\t이동 손실 : 1.1521548032760618\n",
      "배치 인덱스 : 93\t|\t이동 손실 : 1.1521019276152265\n",
      "배치 인덱스 : 94\t|\t이동 손실 : 1.1518019563273378\n",
      "배치 인덱스 : 95\t|\t이동 손실 : 1.152279771864414\n",
      "배치 인덱스 : 96\t|\t이동 손실 : 1.1526495857337085\n",
      "배치 인덱스 : 97\t|\t이동 손실 : 1.152801922389439\n",
      "배치 인덱스 : 98\t|\t이동 손실 : 1.1524277793036566\n",
      "배치 인덱스 : 99\t|\t이동 손실 : 1.1522104501724242\n",
      "배치 인덱스 : 100\t|\t이동 손실 : 1.1527285292597098\n",
      "배치 인덱스 : 101\t|\t이동 손실 : 1.1531815084756587\n",
      "배치 인덱스 : 102\t|\t이동 손실 : 1.1537473988764493\n",
      "배치 인덱스 : 103\t|\t이동 손실 : 1.152692417685802\n",
      "배치 인덱스 : 104\t|\t이동 손실 : 1.1535053196407499\n",
      "배치 인덱스 : 105\t|\t이동 손실 : 1.1536220244641573\n",
      "배치 인덱스 : 106\t|\t이동 손실 : 1.1542352493678296\n",
      "배치 인덱스 : 107\t|\t이동 손실 : 1.1542115443282654\n",
      "배치 인덱스 : 108\t|\t이동 손실 : 1.1539616442601612\n",
      "배치 인덱스 : 109\t|\t이동 손실 : 1.1545342770489777\n",
      "배치 인덱스 : 110\t|\t이동 손실 : 1.155189615112167\n",
      "배치 인덱스 : 111\t|\t이동 손실 : 1.155298432069165\n",
      "배치 인덱스 : 112\t|\t이동 손실 : 1.1561672286649718\n",
      "배치 인덱스 : 113\t|\t이동 손실 : 1.157145189611535\n",
      "배치 인덱스 : 114\t|\t이동 손실 : 1.1578278531198913\n",
      "배치 인덱스 : 115\t|\t이동 손실 : 1.1579886459071058\n",
      "배치 인덱스 : 116\t|\t이동 손실 : 1.1580464473137486\n",
      "배치 인덱스 : 117\t|\t이동 손실 : 1.1586479837611567\n",
      "배치 인덱스 : 118\t|\t이동 손실 : 1.1581822603690521\n",
      "배치 인덱스 : 119\t|\t이동 손실 : 1.157930548985799\n",
      "배치 인덱스 : 120\t|\t이동 손실 : 1.1581189395967593\n",
      "배치 인덱스 : 121\t|\t이동 손실 : 1.1588434870125817\n",
      "배치 인덱스 : 122\t|\t이동 손실 : 1.1590440748183708\n",
      "배치 인덱스 : 123\t|\t이동 손실 : 1.1586652849951098\n",
      "배치 인덱스 : 124\t|\t이동 손실 : 1.1576080055236817\n",
      "배치 인덱스 : 125\t|\t이동 손실 : 1.1576990948783028\n",
      "배치 인덱스 : 126\t|\t이동 손실 : 1.157930962682709\n",
      "배치 인덱스 : 127\t|\t이동 손실 : 1.15802389010787\n",
      "배치 인덱스 : 128\t|\t이동 손실 : 1.1584802265315093\n",
      "배치 인덱스 : 129\t|\t이동 손실 : 1.1583213980381306\n",
      "배치 인덱스 : 130\t|\t이동 손실 : 1.1577826874856731\n",
      "배치 인덱스 : 131\t|\t이동 손실 : 1.1576428964282528\n",
      "배치 인덱스 : 132\t|\t이동 손실 : 1.1580623253843838\n",
      "배치 인덱스 : 133\t|\t이동 손실 : 1.1579384207725525\n",
      "배치 인덱스 : 134\t|\t이동 손실 : 1.1577909999423557\n",
      "배치 인덱스 : 135\t|\t이동 손실 : 1.157672322848264\n",
      "배치 인덱스 : 136\t|\t이동 손실 : 1.1584439617003839\n",
      "배치 인덱스 : 137\t|\t이동 손실 : 1.1588493257329084\n",
      "배치 인덱스 : 138\t|\t이동 손실 : 1.1593197172494243\n",
      "배치 인덱스 : 139\t|\t이동 손실 : 1.158750089577266\n",
      "배치 인덱스 : 140\t|\t이동 손실 : 1.1590096214984325\n",
      "배치 인덱스 : 141\t|\t이동 손실 : 1.1585450122054193\n",
      "배치 인덱스 : 142\t|\t이동 손실 : 1.1582240049655619\n",
      "배치 인덱스 : 143\t|\t이동 손실 : 1.158464641206794\n",
      "배치 인덱스 : 144\t|\t이동 손실 : 1.1586799580475378\n",
      "배치 인덱스 : 145\t|\t이동 손실 : 1.1582641087166248\n",
      "배치 인덱스 : 146\t|\t이동 손실 : 1.158508576503416\n",
      "배치 인덱스 : 147\t|\t이동 손실 : 1.158226435248916\n",
      "배치 인덱스 : 148\t|\t이동 손실 : 1.1579838751146456\n",
      "배치 인덱스 : 149\t|\t이동 손실 : 1.1581807645161946\n",
      "배치 인덱스 : 150\t|\t이동 손실 : 1.1583951119555542\n",
      "배치 인덱스 : 151\t|\t이동 손실 : 1.1584568384446596\n",
      "배치 인덱스 : 152\t|\t이동 손실 : 1.1589764785143286\n",
      "배치 인덱스 : 153\t|\t이동 손실 : 1.15944789988654\n",
      "배치 인덱스 : 154\t|\t이동 손실 : 1.1597083284008889\n",
      "배치 인덱스 : 155\t|\t이동 손실 : 1.1597973857170498\n",
      "배치 인덱스 : 156\t|\t이동 손실 : 1.1601560138593057\n",
      "배치 인덱스 : 157\t|\t이동 손실 : 1.1601414476768883\n",
      "배치 인덱스 : 158\t|\t이동 손실 : 1.1598436562520156\n",
      "배치 인덱스 : 159\t|\t이동 손실 : 1.1602368369698528\n",
      "배치 인덱스 : 160\t|\t이동 손실 : 1.1603417596461614\n",
      "배치 인덱스 : 161\t|\t이동 손실 : 1.160127601505798\n",
      "배치 인덱스 : 162\t|\t이동 손실 : 1.1601096720783262\n",
      "배치 인덱스 : 163\t|\t이동 손실 : 1.1603405991705458\n",
      "배치 인덱스 : 164\t|\t이동 손실 : 1.1604576016917378\n",
      "배치 인덱스 : 165\t|\t이동 손실 : 1.1608967766704335\n",
      "배치 인덱스 : 166\t|\t이동 손실 : 1.1615056591833428\n",
      "배치 인덱스 : 167\t|\t이동 손실 : 1.1614604556844352\n",
      "배치 인덱스 : 168\t|\t이동 손실 : 1.1615125004356435\n",
      "배치 인덱스 : 169\t|\t이동 손실 : 1.161478666698232\n",
      "배치 인덱스 : 170\t|\t이동 손실 : 1.161547880423697\n",
      "배치 인덱스 : 171\t|\t이동 손실 : 1.1617527458556869\n",
      "배치 인덱스 : 172\t|\t이동 손실 : 1.1619289252110305\n",
      "배치 인덱스 : 173\t|\t이동 손실 : 1.1617299900657836\n",
      "배치 인덱스 : 174\t|\t이동 손실 : 1.16146678856441\n",
      "배치 인덱스 : 175\t|\t이동 손실 : 1.1612443361770028\n",
      "배치 인덱스 : 176\t|\t이동 손실 : 1.161070307769345\n",
      "배치 인덱스 : 177\t|\t이동 손실 : 1.1616106582491592\n",
      "배치 인덱스 : 178\t|\t이동 손실 : 1.1618957353037835\n",
      "배치 인덱스 : 179\t|\t이동 손실 : 1.1617604030503172\n",
      "배치 인덱스 : 180\t|\t이동 손실 : 1.161802332045624\n",
      "배치 인덱스 : 181\t|\t이동 손실 : 1.162060800489489\n",
      "배치 인덱스 : 182\t|\t이동 손실 : 1.1623480990936201\n",
      "배치 인덱스 : 183\t|\t이동 손실 : 1.162433397510778\n",
      "배치 인덱스 : 184\t|\t이동 손실 : 1.162694043726535\n",
      "배치 인덱스 : 185\t|\t이동 손실 : 1.1622353555053797\n",
      "배치 인덱스 : 186\t|\t이동 손실 : 1.1622162693962061\n",
      "배치 인덱스 : 187\t|\t이동 손실 : 1.161928648644306\n",
      "배치 인덱스 : 188\t|\t이동 손실 : 1.1618321648350474\n",
      "배치 인덱스 : 189\t|\t이동 손실 : 1.161319041879554\n",
      "배치 인덱스 : 190\t|\t이동 손실 : 1.1620302169110768\n",
      "배치 인덱스 : 191\t|\t이동 손실 : 1.1625540281335518\n",
      "배치 인덱스 : 192\t|\t이동 손실 : 1.1627344683661984\n",
      "배치 인덱스 : 193\t|\t이동 손실 : 1.162353177046039\n",
      "배치 인덱스 : 194\t|\t이동 손실 : 1.1618450390986912\n",
      "배치 인덱스 : 195\t|\t이동 손실 : 1.1622184660969952\n",
      "배치 인덱스 : 196\t|\t이동 손실 : 1.1630865220491056\n",
      "배치 인덱스 : 197\t|\t이동 손실 : 1.1633387244108957\n",
      "배치 인덱스 : 198\t|\t이동 손실 : 1.1634103676781589\n",
      "배치 인덱스 : 199\t|\t이동 손실 : 1.1639882051944739\n",
      "배치 인덱스 : 200\t|\t이동 손실 : 1.1644531512141827\n",
      "배치 인덱스 : 201\t|\t이동 손실 : 1.164450670823013\n",
      "배치 인덱스 : 202\t|\t이동 손실 : 1.1644591697918376\n",
      "배치 인덱스 : 203\t|\t이동 손실 : 1.1646060815044483\n",
      "배치 인덱스 : 204\t|\t이동 손실 : 1.1648446269151647\n",
      "배치 인덱스 : 205\t|\t이동 손실 : 1.165270030498505\n",
      "배치 인덱스 : 206\t|\t이동 손실 : 1.1653266960871973\n",
      "배치 인덱스 : 207\t|\t이동 손실 : 1.1653582608470554\n",
      "배치 인덱스 : 208\t|\t이동 손실 : 1.1661886261981074\n",
      "배치 인덱스 : 209\t|\t이동 손실 : 1.1661158482233687\n",
      "배치 인덱스 : 210\t|\t이동 손실 : 1.1662585023455148\n",
      "배치 인덱스 : 211\t|\t이동 손실 : 1.1665008197415552\n",
      "배치 인덱스 : 212\t|\t이동 손실 : 1.166194045487704\n",
      "배치 인덱스 : 213\t|\t이동 손실 : 1.166135061567075\n",
      "배치 인덱스 : 214\t|\t이동 손실 : 1.166524386405945\n",
      "배치 인덱스 : 215\t|\t이동 손실 : 1.1659643903926569\n",
      "배치 인덱스 : 216\t|\t이동 손실 : 1.1656523003556214\n",
      "배치 인덱스 : 217\t|\t이동 손실 : 1.165956829665998\n",
      "배치 인덱스 : 218\t|\t이동 손실 : 1.1656229332701802\n",
      "배치 인덱스 : 219\t|\t이동 손실 : 1.1652108398350804\n",
      "배치 인덱스 : 220\t|\t이동 손실 : 1.164905204492457\n",
      "배치 인덱스 : 221\t|\t이동 손실 : 1.165260523289174\n",
      "배치 인덱스 : 222\t|\t이동 손실 : 1.1651910586207441\n",
      "배치 인덱스 : 223\t|\t이동 손실 : 1.1653132550418381\n",
      "배치 인덱스 : 224\t|\t이동 손실 : 1.1659445815616187\n",
      "배치 인덱스 : 225\t|\t이동 손실 : 1.1664143162491052\n",
      "배치 인덱스 : 226\t|\t이동 손실 : 1.1662084809483941\n",
      "Epoch: 07 | Time: 15m 11s\n",
      "\tTrain Loss: 1.166 | Train PPL: 3.210\n",
      "\tValidation Loss: 1.959 | Validation PPL: 7.090\n",
      "에폭 : 7\n",
      "배치 인덱스 : 0\t|\t이동 손실 : 0.9764540195465088\n",
      "배치 인덱스 : 1\t|\t이동 손실 : 0.9591546952724457\n",
      "배치 인덱스 : 2\t|\t이동 손실 : 0.9637775421142578\n",
      "배치 인덱스 : 3\t|\t이동 손실 : 0.9612614065408707\n",
      "배치 인덱스 : 4\t|\t이동 손실 : 0.9621771693229675\n",
      "배치 인덱스 : 5\t|\t이동 손실 : 0.9642317096392313\n",
      "배치 인덱스 : 6\t|\t이동 손실 : 0.9527650901249477\n",
      "배치 인덱스 : 7\t|\t이동 손실 : 0.9562157392501831\n",
      "배치 인덱스 : 8\t|\t이동 손실 : 0.9513269795311822\n",
      "배치 인덱스 : 9\t|\t이동 손실 : 0.9506814062595368\n",
      "배치 인덱스 : 10\t|\t이동 손실 : 0.9582001783631066\n",
      "배치 인덱스 : 11\t|\t이동 손실 : 0.9592177122831346\n",
      "배치 인덱스 : 12\t|\t이동 손실 : 0.9571738793299749\n",
      "배치 인덱스 : 13\t|\t이동 손실 : 0.964783217225756\n",
      "배치 인덱스 : 14\t|\t이동 손실 : 0.962891427675883\n",
      "배치 인덱스 : 15\t|\t이동 손실 : 0.9582031928002834\n",
      "배치 인덱스 : 16\t|\t이동 손실 : 0.9606566359015072\n",
      "배치 인덱스 : 17\t|\t이동 손실 : 0.9637167784902785\n",
      "배치 인덱스 : 18\t|\t이동 손실 : 0.9690202349110654\n",
      "배치 인덱스 : 19\t|\t이동 손실 : 0.9676143229007721\n",
      "배치 인덱스 : 20\t|\t이동 손실 : 0.9693845964613415\n",
      "배치 인덱스 : 21\t|\t이동 손실 : 0.9719680872830477\n",
      "배치 인덱스 : 22\t|\t이동 손실 : 0.9714942133944967\n",
      "배치 인덱스 : 23\t|\t이동 손실 : 0.9736073811848958\n",
      "배치 인덱스 : 24\t|\t이동 손실 : 0.9753491735458373\n",
      "배치 인덱스 : 25\t|\t이동 손실 : 0.9770551507289592\n",
      "배치 인덱스 : 26\t|\t이동 손실 : 0.9766672010774965\n",
      "배치 인덱스 : 27\t|\t이동 손실 : 0.979112786906106\n",
      "배치 인덱스 : 28\t|\t이동 손실 : 0.9768258497632782\n",
      "배치 인덱스 : 29\t|\t이동 손실 : 0.9752798676490783\n",
      "배치 인덱스 : 30\t|\t이동 손실 : 0.974560216549904\n",
      "배치 인덱스 : 31\t|\t이동 손실 : 0.9714340586215257\n",
      "배치 인덱스 : 32\t|\t이동 손실 : 0.9723565885514923\n",
      "배치 인덱스 : 33\t|\t이동 손실 : 0.9724067817716037\n",
      "배치 인덱스 : 34\t|\t이동 손실 : 0.9710102762494768\n",
      "배치 인덱스 : 35\t|\t이동 손실 : 0.9720194041728972\n",
      "배치 인덱스 : 36\t|\t이동 손실 : 0.9713525514344911\n",
      "배치 인덱스 : 37\t|\t이동 손실 : 0.9730902471040423\n",
      "배치 인덱스 : 38\t|\t이동 손실 : 0.9755045114419398\n",
      "배치 인덱스 : 39\t|\t이동 손실 : 0.9777874141931533\n",
      "배치 인덱스 : 40\t|\t이동 손실 : 0.9782895940106089\n",
      "배치 인덱스 : 41\t|\t이동 손실 : 0.9782780181793939\n",
      "배치 인덱스 : 42\t|\t이동 손실 : 0.9769673929658046\n",
      "배치 인덱스 : 43\t|\t이동 손실 : 0.9760536375370892\n",
      "배치 인덱스 : 44\t|\t이동 손실 : 0.9748527155982123\n",
      "배치 인덱스 : 45\t|\t이동 손실 : 0.9761636179426442\n",
      "배치 인덱스 : 46\t|\t이동 손실 : 0.9765818347322179\n",
      "배치 인덱스 : 47\t|\t이동 손실 : 0.977594236532847\n",
      "배치 인덱스 : 48\t|\t이동 손실 : 0.9775195012287218\n",
      "배치 인덱스 : 49\t|\t이동 손실 : 0.9779635202884674\n",
      "배치 인덱스 : 50\t|\t이동 손실 : 0.9796342323808109\n",
      "배치 인덱스 : 51\t|\t이동 손실 : 0.9789008417954812\n",
      "배치 인덱스 : 52\t|\t이동 손실 : 0.9805930256843567\n",
      "배치 인덱스 : 53\t|\t이동 손실 : 0.9793430787545664\n",
      "배치 인덱스 : 54\t|\t이동 손실 : 0.979739319194447\n",
      "배치 인덱스 : 55\t|\t이동 손실 : 0.9803170519215721\n",
      "배치 인덱스 : 56\t|\t이동 손실 : 0.9806789808106006\n",
      "배치 인덱스 : 57\t|\t이동 손실 : 0.9797909239242818\n",
      "배치 인덱스 : 58\t|\t이동 손실 : 0.9810923600600939\n",
      "배치 인덱스 : 59\t|\t이동 손실 : 0.981087233622869\n",
      "배치 인덱스 : 60\t|\t이동 손실 : 0.9829782716563492\n",
      "배치 인덱스 : 61\t|\t이동 손실 : 0.9815176648478355\n",
      "배치 인덱스 : 62\t|\t이동 손실 : 0.9812224838468765\n",
      "배치 인덱스 : 63\t|\t이동 손실 : 0.9810720765963198\n",
      "배치 인덱스 : 64\t|\t이동 손실 : 0.981719641502087\n",
      "배치 인덱스 : 65\t|\t이동 손실 : 0.9824086978580013\n",
      "배치 인덱스 : 66\t|\t이동 손실 : 0.9830858307098276\n",
      "배치 인덱스 : 67\t|\t이동 손실 : 0.9825121453579735\n",
      "배치 인덱스 : 68\t|\t이동 손실 : 0.9831926520319954\n",
      "배치 인덱스 : 69\t|\t이동 손실 : 0.9830326080322267\n",
      "배치 인덱스 : 70\t|\t이동 손실 : 0.9830556998790151\n",
      "배치 인덱스 : 71\t|\t이동 손실 : 0.982860780424542\n",
      "배치 인덱스 : 72\t|\t이동 손실 : 0.9827499675424132\n",
      "배치 인덱스 : 73\t|\t이동 손실 : 0.9832781641869932\n",
      "배치 인덱스 : 74\t|\t이동 손실 : 0.9833314569791158\n",
      "배치 인덱스 : 75\t|\t이동 손실 : 0.9839491867705396\n",
      "배치 인덱스 : 76\t|\t이동 손실 : 0.9841140454465693\n",
      "배치 인덱스 : 77\t|\t이동 손실 : 0.9833577802548042\n",
      "배치 인덱스 : 78\t|\t이동 손실 : 0.9837893647483633\n",
      "배치 인덱스 : 79\t|\t이동 손실 : 0.9835341691970826\n",
      "배치 인덱스 : 80\t|\t이동 손실 : 0.9853276941511366\n",
      "배치 인덱스 : 81\t|\t이동 손실 : 0.9860195110483868\n",
      "배치 인덱스 : 82\t|\t이동 손실 : 0.9876020730259908\n",
      "배치 인덱스 : 83\t|\t이동 손실 : 0.9872609930379052\n",
      "배치 인덱스 : 84\t|\t이동 손실 : 0.9872062753228582\n",
      "배치 인덱스 : 85\t|\t이동 손실 : 0.9868671991104305\n",
      "배치 인덱스 : 86\t|\t이동 손실 : 0.9875936672605319\n",
      "배치 인덱스 : 87\t|\t이동 손실 : 0.9870086529038171\n",
      "배치 인덱스 : 88\t|\t이동 손실 : 0.9878257191583014\n",
      "배치 인덱스 : 89\t|\t이동 손실 : 0.9885207626554703\n",
      "배치 인덱스 : 90\t|\t이동 손실 : 0.9883709851202076\n",
      "배치 인덱스 : 91\t|\t이동 손실 : 0.9900452527015108\n",
      "배치 인덱스 : 92\t|\t이동 손실 : 0.9898065982326387\n",
      "배치 인덱스 : 93\t|\t이동 손실 : 0.9903829478202985\n",
      "배치 인덱스 : 94\t|\t이동 손실 : 0.9889931371337491\n",
      "배치 인덱스 : 95\t|\t이동 손실 : 0.9887416219959658\n",
      "배치 인덱스 : 96\t|\t이동 손실 : 0.9896975233382788\n",
      "배치 인덱스 : 97\t|\t이동 손실 : 0.9897893752370565\n",
      "배치 인덱스 : 98\t|\t이동 손실 : 0.990044859924702\n",
      "배치 인덱스 : 99\t|\t이동 손실 : 0.9904644739627841\n",
      "배치 인덱스 : 100\t|\t이동 손실 : 0.9902424688386449\n",
      "배치 인덱스 : 101\t|\t이동 손실 : 0.9909261681285563\n",
      "배치 인덱스 : 102\t|\t이동 손실 : 0.9906764481831527\n",
      "배치 인덱스 : 103\t|\t이동 손실 : 0.9916632817341735\n",
      "배치 인덱스 : 104\t|\t이동 손실 : 0.9917084279514499\n",
      "배치 인덱스 : 105\t|\t이동 손실 : 0.9923403853515413\n",
      "배치 인덱스 : 106\t|\t이동 손실 : 0.9925160669834818\n",
      "배치 인덱스 : 107\t|\t이동 손실 : 0.9928563154406022\n",
      "배치 인덱스 : 108\t|\t이동 손실 : 0.9930908390141412\n",
      "배치 인덱스 : 109\t|\t이동 손실 : 0.9932678683237599\n",
      "배치 인덱스 : 110\t|\t이동 손실 : 0.9930674868661007\n",
      "배치 인덱스 : 111\t|\t이동 손실 : 0.9930740232978551\n",
      "배치 인덱스 : 112\t|\t이동 손실 : 0.993025451107363\n",
      "배치 인덱스 : 113\t|\t이동 손실 : 0.992747708893659\n",
      "배치 인덱스 : 114\t|\t이동 손실 : 0.9935846593068995\n",
      "배치 인덱스 : 115\t|\t이동 손실 : 0.9933760952332926\n",
      "배치 인덱스 : 116\t|\t이동 손실 : 0.9938841299114066\n",
      "배치 인덱스 : 117\t|\t이동 손실 : 0.9934247641240138\n",
      "배치 인덱스 : 118\t|\t이동 손실 : 0.9935053867452287\n",
      "배치 인덱스 : 119\t|\t이동 손실 : 0.9945172260204953\n",
      "배치 인덱스 : 120\t|\t이동 손실 : 0.9949945595638813\n",
      "배치 인덱스 : 121\t|\t이동 손실 : 0.9950443017678184\n",
      "배치 인덱스 : 122\t|\t이동 손실 : 0.995243370048399\n",
      "배치 인덱스 : 123\t|\t이동 손실 : 0.9959708548361257\n",
      "배치 인덱스 : 124\t|\t이동 손실 : 0.9961322717666627\n",
      "배치 인덱스 : 125\t|\t이동 손실 : 0.9962858983448575\n",
      "배치 인덱스 : 126\t|\t이동 손실 : 0.9960375611237655\n",
      "배치 인덱스 : 127\t|\t이동 손실 : 0.9956149440258742\n",
      "배치 인덱스 : 128\t|\t이동 손실 : 0.9959280047305796\n",
      "배치 인덱스 : 129\t|\t이동 손실 : 0.996296079342182\n",
      "배치 인덱스 : 130\t|\t이동 손실 : 0.9956899662964218\n",
      "배치 인덱스 : 131\t|\t이동 손실 : 0.9962045414881274\n",
      "배치 인덱스 : 132\t|\t이동 손실 : 0.9967021610503808\n",
      "배치 인덱스 : 133\t|\t이동 손실 : 0.9966928278332328\n",
      "배치 인덱스 : 134\t|\t이동 손실 : 0.9973874008214034\n",
      "배치 인덱스 : 135\t|\t이동 손실 : 0.9975751292179614\n",
      "배치 인덱스 : 136\t|\t이동 손실 : 0.9978870340507398\n",
      "배치 인덱스 : 137\t|\t이동 손실 : 0.9983940137469252\n",
      "배치 인덱스 : 138\t|\t이동 손실 : 0.998628047301615\n",
      "배치 인덱스 : 139\t|\t이동 손실 : 0.9986602404287884\n",
      "배치 인덱스 : 140\t|\t이동 손실 : 0.9989376385161218\n",
      "배치 인덱스 : 141\t|\t이동 손실 : 0.9996597980949242\n",
      "배치 인덱스 : 142\t|\t이동 손실 : 1.0001629428430039\n",
      "배치 인덱스 : 143\t|\t이동 손실 : 1.0001937610407672\n",
      "배치 인덱스 : 144\t|\t이동 손실 : 1.0011426773564571\n",
      "배치 인덱스 : 145\t|\t이동 손실 : 1.0013253047858202\n",
      "배치 인덱스 : 146\t|\t이동 손실 : 1.0012688320510243\n",
      "배치 인덱스 : 147\t|\t이동 손실 : 1.001718141742655\n",
      "배치 인덱스 : 148\t|\t이동 손실 : 1.001524722016098\n",
      "배치 인덱스 : 149\t|\t이동 손실 : 1.0021225341161095\n",
      "배치 인덱스 : 150\t|\t이동 손실 : 1.0026381599982057\n",
      "배치 인덱스 : 151\t|\t이동 손실 : 1.0027711924753695\n",
      "배치 인덱스 : 152\t|\t이동 손실 : 1.003435146574881\n",
      "배치 인덱스 : 153\t|\t이동 손실 : 1.0035176764835014\n",
      "배치 인덱스 : 154\t|\t이동 손실 : 1.0033499187038795\n",
      "배치 인덱스 : 155\t|\t이동 손실 : 1.0030671950334162\n",
      "배치 인덱스 : 156\t|\t이동 손실 : 1.0033689847417702\n",
      "배치 인덱스 : 157\t|\t이동 손실 : 1.0027910844434669\n",
      "배치 인덱스 : 158\t|\t이동 손실 : 1.0033367006283889\n",
      "배치 인덱스 : 159\t|\t이동 손실 : 1.003150734305382\n",
      "배치 인덱스 : 160\t|\t이동 손실 : 1.0031340188861637\n",
      "배치 인덱스 : 161\t|\t이동 손실 : 1.0036644030500346\n",
      "배치 인덱스 : 162\t|\t이동 손실 : 1.0037018930985158\n",
      "배치 인덱스 : 163\t|\t이동 손실 : 1.0035538935079813\n",
      "배치 인덱스 : 164\t|\t이동 손실 : 1.0036075527017772\n",
      "배치 인덱스 : 165\t|\t이동 손실 : 1.0039901762123573\n",
      "배치 인덱스 : 166\t|\t이동 손실 : 1.0041958350621303\n",
      "배치 인덱스 : 167\t|\t이동 손실 : 1.004497402480671\n",
      "배치 인덱스 : 168\t|\t이동 손실 : 1.005250575274406\n",
      "배치 인덱스 : 169\t|\t이동 손실 : 1.0056295436971334\n",
      "배치 인덱스 : 170\t|\t이동 손실 : 1.005422418926195\n",
      "배치 인덱스 : 171\t|\t이동 손실 : 1.0051176728204245\n",
      "배치 인덱스 : 172\t|\t이동 손실 : 1.0057283812175601\n",
      "배치 인덱스 : 173\t|\t이동 손실 : 1.0061502710156063\n",
      "배치 인덱스 : 174\t|\t이동 손실 : 1.0065309299741478\n",
      "배치 인덱스 : 175\t|\t이동 손실 : 1.0065686242146932\n",
      "배치 인덱스 : 176\t|\t이동 손실 : 1.0059814550782333\n",
      "배치 인덱스 : 177\t|\t이동 손실 : 1.0060139295090456\n",
      "배치 인덱스 : 178\t|\t이동 손실 : 1.00592936317348\n",
      "배치 인덱스 : 179\t|\t이동 손실 : 1.0055068718062512\n",
      "배치 인덱스 : 180\t|\t이동 손실 : 1.0056951790224786\n",
      "배치 인덱스 : 181\t|\t이동 손실 : 1.0057149974854442\n",
      "배치 인덱스 : 182\t|\t이동 손실 : 1.0049991731435228\n",
      "배치 인덱스 : 183\t|\t이동 손실 : 1.0056493049082553\n",
      "배치 인덱스 : 184\t|\t이동 손실 : 1.0056332794395657\n",
      "배치 인덱스 : 185\t|\t이동 손실 : 1.0058784683545434\n",
      "배치 인덱스 : 186\t|\t이동 손실 : 1.0058183160057683\n",
      "배치 인덱스 : 187\t|\t이동 손실 : 1.0059301479065674\n",
      "배치 인덱스 : 188\t|\t이동 손실 : 1.006068895733546\n",
      "배치 인덱스 : 189\t|\t이동 손실 : 1.0064468339869854\n",
      "배치 인덱스 : 190\t|\t이동 손실 : 1.0068333972811079\n",
      "배치 인덱스 : 191\t|\t이동 손실 : 1.0068124526490771\n",
      "배치 인덱스 : 192\t|\t이동 손실 : 1.006671992608303\n",
      "배치 인덱스 : 193\t|\t이동 손실 : 1.0067279019306619\n",
      "배치 인덱스 : 194\t|\t이동 손실 : 1.0071352133384122\n",
      "배치 인덱스 : 195\t|\t이동 손실 : 1.0070527174643111\n",
      "배치 인덱스 : 196\t|\t이동 손실 : 1.0072194104872383\n",
      "배치 인덱스 : 197\t|\t이동 손실 : 1.0077123855701604\n",
      "배치 인덱스 : 198\t|\t이동 손실 : 1.007772566385605\n",
      "배치 인덱스 : 199\t|\t이동 손실 : 1.008232297599316\n",
      "배치 인덱스 : 200\t|\t이동 손실 : 1.0089193899833153\n",
      "배치 인덱스 : 201\t|\t이동 손실 : 1.0092015658864886\n",
      "배치 인덱스 : 202\t|\t이동 손실 : 1.008943808489833\n",
      "배치 인덱스 : 203\t|\t이동 손실 : 1.0089419729569384\n",
      "배치 인덱스 : 204\t|\t이동 손실 : 1.0088859534845125\n",
      "배치 인덱스 : 205\t|\t이동 손실 : 1.0089697212848854\n",
      "배치 인덱스 : 206\t|\t이동 손실 : 1.0090183503385908\n",
      "배치 인덱스 : 207\t|\t이동 손실 : 1.009281256451057\n",
      "배치 인덱스 : 208\t|\t이동 손실 : 1.0092662162187571\n",
      "배치 인덱스 : 209\t|\t이동 손실 : 1.0088911953426547\n",
      "배치 인덱스 : 210\t|\t이동 손실 : 1.009497930088315\n",
      "배치 인덱스 : 211\t|\t이동 손실 : 1.009416708687567\n",
      "배치 인덱스 : 212\t|\t이동 손실 : 1.0098397555485583\n",
      "배치 인덱스 : 213\t|\t이동 손실 : 1.0104590166952014\n",
      "배치 인덱스 : 214\t|\t이동 손실 : 1.0106801834217343\n",
      "배치 인덱스 : 215\t|\t이동 손실 : 1.0108422860503201\n",
      "배치 인덱스 : 216\t|\t이동 손실 : 1.0109313866509824\n",
      "배치 인덱스 : 217\t|\t이동 손실 : 1.0112817328457442\n",
      "배치 인덱스 : 218\t|\t이동 손실 : 1.0111354202984677\n",
      "배치 인덱스 : 219\t|\t이동 손실 : 1.010904203761708\n",
      "배치 인덱스 : 220\t|\t이동 손실 : 1.0108140520920044\n",
      "배치 인덱스 : 221\t|\t이동 손실 : 1.010575208578024\n",
      "배치 인덱스 : 222\t|\t이동 손실 : 1.0110169889681009\n",
      "배치 인덱스 : 223\t|\t이동 손실 : 1.0114248991012573\n",
      "배치 인덱스 : 224\t|\t이동 손실 : 1.0114819622039795\n",
      "배치 인덱스 : 225\t|\t이동 손실 : 1.0118871099126021\n",
      "배치 인덱스 : 226\t|\t이동 손실 : 1.0115361085022072\n",
      "Epoch: 08 | Time: 15m 4s\n",
      "\tTrain Loss: 1.012 | Train PPL: 2.750\n",
      "\tValidation Loss: 1.978 | Validation PPL: 7.225\n",
      "에폭 : 8\n",
      "배치 인덱스 : 0\t|\t이동 손실 : 0.7574161887168884\n",
      "배치 인덱스 : 1\t|\t이동 손실 : 0.7805591225624084\n",
      "배치 인덱스 : 2\t|\t이동 손실 : 0.7942442893981934\n",
      "배치 인덱스 : 3\t|\t이동 손실 : 0.8062463849782944\n",
      "배치 인덱스 : 4\t|\t이동 손실 : 0.8199925780296325\n",
      "배치 인덱스 : 5\t|\t이동 손실 : 0.8184306621551514\n",
      "배치 인덱스 : 6\t|\t이동 손실 : 0.8287788203784398\n",
      "배치 인덱스 : 7\t|\t이동 손실 : 0.8317010700702667\n",
      "배치 인덱스 : 8\t|\t이동 손실 : 0.8254939913749695\n",
      "배치 인덱스 : 9\t|\t이동 손실 : 0.8320367753505706\n",
      "배치 인덱스 : 10\t|\t이동 손실 : 0.8362347321076826\n",
      "배치 인덱스 : 11\t|\t이동 손실 : 0.8357224017381668\n",
      "배치 인덱스 : 12\t|\t이동 손실 : 0.8378199568161597\n",
      "배치 인덱스 : 13\t|\t이동 손실 : 0.8394361478941781\n",
      "배치 인덱스 : 14\t|\t이동 손실 : 0.8382525245348612\n",
      "배치 인덱스 : 15\t|\t이동 손실 : 0.837423499673605\n",
      "배치 인덱스 : 16\t|\t이동 손실 : 0.83289113816093\n",
      "배치 인덱스 : 17\t|\t이동 손실 : 0.8318850497404734\n",
      "배치 인덱스 : 18\t|\t이동 손실 : 0.8305657192280418\n",
      "배치 인덱스 : 19\t|\t이동 손실 : 0.8268773198127747\n",
      "배치 인덱스 : 20\t|\t이동 손실 : 0.8286416388693311\n",
      "배치 인덱스 : 21\t|\t이동 손실 : 0.8296783647753976\n",
      "배치 인덱스 : 22\t|\t이동 손실 : 0.830487292745839\n",
      "배치 인덱스 : 23\t|\t이동 손실 : 0.8297703415155411\n",
      "배치 인덱스 : 24\t|\t이동 손실 : 0.8290461468696594\n",
      "배치 인덱스 : 25\t|\t이동 손실 : 0.8280666447602785\n",
      "배치 인덱스 : 26\t|\t이동 손실 : 0.8272022229653817\n",
      "배치 인덱스 : 27\t|\t이동 손실 : 0.8289475589990616\n",
      "배치 인덱스 : 28\t|\t이동 손실 : 0.829344040360944\n",
      "배치 인덱스 : 29\t|\t이동 손실 : 0.830269992351532\n",
      "배치 인덱스 : 30\t|\t이동 손실 : 0.8301822466235007\n",
      "배치 인덱스 : 31\t|\t이동 손실 : 0.8300133980810642\n",
      "배치 인덱스 : 32\t|\t이동 손실 : 0.8326879504955176\n",
      "배치 인덱스 : 33\t|\t이동 손실 : 0.834171126870548\n",
      "배치 인덱스 : 34\t|\t이동 손실 : 0.8335187809807912\n",
      "배치 인덱스 : 35\t|\t이동 손실 : 0.8338966253730985\n",
      "배치 인덱스 : 36\t|\t이동 손실 : 0.8342149934253176\n",
      "배치 인덱스 : 37\t|\t이동 손실 : 0.8339988150094684\n",
      "배치 인덱스 : 38\t|\t이동 손실 : 0.8349546453891655\n",
      "배치 인덱스 : 39\t|\t이동 손실 : 0.8330851867794989\n",
      "배치 인덱스 : 40\t|\t이동 손실 : 0.8336252802755774\n",
      "배치 인덱스 : 41\t|\t이동 손실 : 0.8348331564948671\n",
      "배치 인덱스 : 42\t|\t이동 손실 : 0.8363520932752031\n",
      "배치 인덱스 : 43\t|\t이동 손실 : 0.8382940495556049\n",
      "배치 인덱스 : 44\t|\t이동 손실 : 0.8389036734898884\n",
      "배치 인덱스 : 45\t|\t이동 손실 : 0.8406329465949016\n",
      "배치 인덱스 : 46\t|\t이동 손실 : 0.8389426419075499\n",
      "배치 인덱스 : 47\t|\t이동 손실 : 0.8403433139125506\n",
      "배치 인덱스 : 48\t|\t이동 손실 : 0.8406032506300478\n",
      "배치 인덱스 : 49\t|\t이동 손실 : 0.8413771784305573\n",
      "배치 인덱스 : 50\t|\t이동 손실 : 0.84138376455681\n",
      "배치 인덱스 : 51\t|\t이동 손실 : 0.8421215793261161\n",
      "배치 인덱스 : 52\t|\t이동 손실 : 0.8413033451674119\n",
      "배치 인덱스 : 53\t|\t이동 손실 : 0.8423380840707708\n",
      "배치 인덱스 : 54\t|\t이동 손실 : 0.8422125046903437\n",
      "배치 인덱스 : 55\t|\t이동 손실 : 0.8439462408423424\n",
      "배치 인덱스 : 56\t|\t이동 손실 : 0.8438097845044052\n",
      "배치 인덱스 : 57\t|\t이동 손실 : 0.8436973084663523\n",
      "배치 인덱스 : 58\t|\t이동 손실 : 0.8438166905257661\n",
      "배치 인덱스 : 59\t|\t이동 손실 : 0.8441811919212341\n",
      "배치 인덱스 : 60\t|\t이동 손실 : 0.8453762687620568\n",
      "배치 인덱스 : 61\t|\t이동 손실 : 0.8453499972820281\n",
      "배치 인덱스 : 62\t|\t이동 손실 : 0.8463739336483062\n",
      "배치 인덱스 : 63\t|\t이동 손실 : 0.8467652983963488\n",
      "배치 인덱스 : 64\t|\t이동 손실 : 0.8465877276200513\n",
      "배치 인덱스 : 65\t|\t이동 손실 : 0.8468908477913248\n",
      "배치 인덱스 : 66\t|\t이동 손실 : 0.8465481649583844\n",
      "배치 인덱스 : 67\t|\t이동 손실 : 0.8462489299914415\n",
      "배치 인덱스 : 68\t|\t이동 손실 : 0.8455360747765803\n",
      "배치 인덱스 : 69\t|\t이동 손실 : 0.8455986976623535\n",
      "배치 인덱스 : 70\t|\t이동 손실 : 0.8449508430252612\n",
      "배치 인덱스 : 71\t|\t이동 손실 : 0.846517356733481\n",
      "배치 인덱스 : 72\t|\t이동 손실 : 0.847757877552346\n",
      "배치 인덱스 : 73\t|\t이동 손실 : 0.8480254339205252\n",
      "배치 인덱스 : 74\t|\t이동 손실 : 0.8480734928448995\n",
      "배치 인덱스 : 75\t|\t이동 손실 : 0.8485600022893203\n",
      "배치 인덱스 : 76\t|\t이동 손실 : 0.8495267064540417\n",
      "배치 인덱스 : 77\t|\t이동 손실 : 0.8505334212229803\n",
      "배치 인덱스 : 78\t|\t이동 손실 : 0.8505896827842616\n",
      "배치 인덱스 : 79\t|\t이동 손실 : 0.8506362564861775\n",
      "배치 인덱스 : 80\t|\t이동 손실 : 0.8514796723554164\n",
      "배치 인덱스 : 81\t|\t이동 손실 : 0.8512942318509266\n",
      "배치 인덱스 : 82\t|\t이동 손실 : 0.8516043359974782\n",
      "배치 인덱스 : 83\t|\t이동 손실 : 0.8523105375823522\n",
      "배치 인덱스 : 84\t|\t이동 손실 : 0.8523006635553698\n",
      "배치 인덱스 : 85\t|\t이동 손실 : 0.8519850906937623\n",
      "배치 인덱스 : 86\t|\t이동 손실 : 0.8516843236725907\n",
      "배치 인덱스 : 87\t|\t이동 손실 : 0.8512567952275277\n",
      "배치 인덱스 : 88\t|\t이동 손실 : 0.8512338815110454\n",
      "배치 인덱스 : 89\t|\t이동 손실 : 0.8516413251558941\n",
      "배치 인덱스 : 90\t|\t이동 손실 : 0.8519110823725607\n",
      "배치 인덱스 : 91\t|\t이동 손실 : 0.852304430111595\n",
      "배치 인덱스 : 92\t|\t이동 손실 : 0.8526343081587106\n",
      "배치 인덱스 : 93\t|\t이동 손실 : 0.8525793825058228\n",
      "배치 인덱스 : 94\t|\t이동 손실 : 0.8529037500682631\n",
      "배치 인덱스 : 95\t|\t이동 손실 : 0.8530145945648353\n",
      "배치 인덱스 : 96\t|\t이동 손실 : 0.8533706105861468\n",
      "배치 인덱스 : 97\t|\t이동 손실 : 0.8536625303784197\n",
      "배치 인덱스 : 98\t|\t이동 손실 : 0.8535850397264115\n",
      "배치 인덱스 : 99\t|\t이동 손실 : 0.8527474951744081\n",
      "배치 인덱스 : 100\t|\t이동 손실 : 0.8533998444528864\n",
      "배치 인덱스 : 101\t|\t이동 손실 : 0.8535341807440217\n",
      "배치 인덱스 : 102\t|\t이동 손실 : 0.8533590933651601\n",
      "배치 인덱스 : 103\t|\t이동 손실 : 0.8544450218860921\n",
      "배치 인덱스 : 104\t|\t이동 손실 : 0.8545111792428154\n",
      "배치 인덱스 : 105\t|\t이동 손실 : 0.8551344910882555\n",
      "배치 인덱스 : 106\t|\t이동 손실 : 0.855326367315845\n",
      "배치 인덱스 : 107\t|\t이동 손실 : 0.8551001686740805\n",
      "배치 인덱스 : 108\t|\t이동 손실 : 0.855201553314104\n",
      "배치 인덱스 : 109\t|\t이동 손실 : 0.8555741651491685\n",
      "배치 인덱스 : 110\t|\t이동 손실 : 0.8561730363347508\n",
      "배치 인덱스 : 111\t|\t이동 손실 : 0.8558200464716978\n",
      "배치 인덱스 : 112\t|\t이동 손실 : 0.856086620714812\n",
      "배치 인덱스 : 113\t|\t이동 손실 : 0.8561398031418782\n",
      "배치 인덱스 : 114\t|\t이동 손실 : 0.8560238817463749\n",
      "배치 인덱스 : 115\t|\t이동 손실 : 0.8564365233840612\n",
      "배치 인덱스 : 116\t|\t이동 손실 : 0.856274980255681\n",
      "배치 인덱스 : 117\t|\t이동 손실 : 0.8561432932393024\n",
      "배치 인덱스 : 118\t|\t이동 손실 : 0.856656723162707\n",
      "배치 인덱스 : 119\t|\t이동 손실 : 0.856907983124256\n",
      "배치 인덱스 : 120\t|\t이동 손실 : 0.8570101497587093\n",
      "배치 인덱스 : 121\t|\t이동 손실 : 0.8569575567714502\n",
      "배치 인덱스 : 122\t|\t이동 손실 : 0.857133842096096\n",
      "배치 인덱스 : 123\t|\t이동 손실 : 0.8573456983412464\n",
      "배치 인덱스 : 124\t|\t이동 손실 : 0.8572199335098265\n",
      "배치 인덱스 : 125\t|\t이동 손실 : 0.8581380631242478\n",
      "배치 인덱스 : 126\t|\t이동 손실 : 0.857633426433473\n",
      "배치 인덱스 : 127\t|\t이동 손실 : 0.8581896368414162\n",
      "배치 인덱스 : 128\t|\t이동 손실 : 0.8585435951402944\n",
      "배치 인덱스 : 129\t|\t이동 손실 : 0.8584500830907087\n",
      "배치 인덱스 : 130\t|\t이동 손실 : 0.8590410565601959\n",
      "배치 인덱스 : 131\t|\t이동 손실 : 0.8583844624685517\n",
      "배치 인덱스 : 132\t|\t이동 손실 : 0.8587448933070763\n",
      "배치 인덱스 : 133\t|\t이동 손실 : 0.8588980663178571\n",
      "배치 인덱스 : 134\t|\t이동 손실 : 0.8590779238277011\n",
      "배치 인덱스 : 135\t|\t이동 손실 : 0.8593651547151453\n",
      "배치 인덱스 : 136\t|\t이동 손실 : 0.8598110049310391\n",
      "배치 인덱스 : 137\t|\t이동 손실 : 0.8601724194443744\n",
      "배치 인덱스 : 138\t|\t이동 손실 : 0.8603980867125147\n",
      "배치 인덱스 : 139\t|\t이동 손실 : 0.8605391553470066\n",
      "배치 인덱스 : 140\t|\t이동 손실 : 0.8613142633269019\n",
      "배치 인덱스 : 141\t|\t이동 손실 : 0.8621828295815158\n",
      "배치 인덱스 : 142\t|\t이동 손실 : 0.8621884421868757\n",
      "배치 인덱스 : 143\t|\t이동 손실 : 0.8623708354102241\n",
      "배치 인덱스 : 144\t|\t이동 손실 : 0.862473148313062\n",
      "배치 인덱스 : 145\t|\t이동 손실 : 0.8625469554777015\n",
      "배치 인덱스 : 146\t|\t이동 손실 : 0.8625629710502366\n",
      "배치 인덱스 : 147\t|\t이동 손실 : 0.8624815223990261\n",
      "배치 인덱스 : 148\t|\t이동 손실 : 0.8627192638064392\n",
      "배치 인덱스 : 149\t|\t이동 손실 : 0.8630970366795858\n",
      "배치 인덱스 : 150\t|\t이동 손실 : 0.8630401417119614\n",
      "배치 인덱스 : 151\t|\t이동 손실 : 0.8633340632444935\n",
      "배치 인덱스 : 152\t|\t이동 손실 : 0.8635260883499595\n",
      "배치 인덱스 : 153\t|\t이동 손실 : 0.8633036307700269\n",
      "배치 인덱스 : 154\t|\t이동 손실 : 0.8637135713331161\n",
      "배치 인덱스 : 155\t|\t이동 손실 : 0.8637633121166474\n",
      "배치 인덱스 : 156\t|\t이동 손실 : 0.8638995502405106\n",
      "배치 인덱스 : 157\t|\t이동 손실 : 0.8645799827726581\n",
      "배치 인덱스 : 158\t|\t이동 손실 : 0.8647280968959976\n",
      "배치 인덱스 : 159\t|\t이동 손실 : 0.8647586513310671\n",
      "배치 인덱스 : 160\t|\t이동 손실 : 0.8650708568762548\n",
      "배치 인덱스 : 161\t|\t이동 손실 : 0.8652435180581647\n",
      "배치 인덱스 : 162\t|\t이동 손실 : 0.865826271794325\n",
      "배치 인덱스 : 163\t|\t이동 손실 : 0.8660552210924102\n",
      "배치 인덱스 : 164\t|\t이동 손실 : 0.8664250269080653\n",
      "배치 인덱스 : 165\t|\t이동 손실 : 0.8668820455849888\n",
      "배치 인덱스 : 166\t|\t이동 손실 : 0.8673075341178985\n",
      "배치 인덱스 : 167\t|\t이동 손실 : 0.8676340501932871\n",
      "배치 인덱스 : 168\t|\t이동 손실 : 0.8678901967917674\n",
      "배치 인덱스 : 169\t|\t이동 손실 : 0.868416656816707\n",
      "배치 인덱스 : 170\t|\t이동 손실 : 0.8688527220173886\n",
      "배치 인덱스 : 171\t|\t이동 손실 : 0.8690505959959918\n",
      "배치 인덱스 : 172\t|\t이동 손실 : 0.8689626937656734\n",
      "배치 인덱스 : 173\t|\t이동 손실 : 0.8694094265329427\n",
      "배치 인덱스 : 174\t|\t이동 손실 : 0.8698187419346401\n",
      "배치 인덱스 : 175\t|\t이동 손실 : 0.8697092370553451\n",
      "배치 인덱스 : 176\t|\t이동 손실 : 0.8698030646237951\n",
      "배치 인덱스 : 177\t|\t이동 손실 : 0.8697645429814801\n",
      "배치 인덱스 : 178\t|\t이동 손실 : 0.8693892882522926\n",
      "배치 인덱스 : 179\t|\t이동 손실 : 0.8693434907330408\n",
      "배치 인덱스 : 180\t|\t이동 손실 : 0.868861856710845\n",
      "배치 인덱스 : 181\t|\t이동 손실 : 0.8692839489533352\n",
      "배치 인덱스 : 182\t|\t이동 손실 : 0.8698825188021843\n",
      "배치 인덱스 : 183\t|\t이동 손실 : 0.8697445094585419\n",
      "배치 인덱스 : 184\t|\t이동 손실 : 0.8702019047092747\n",
      "배치 인덱스 : 185\t|\t이동 손실 : 0.8702272583720505\n",
      "배치 인덱스 : 186\t|\t이동 손실 : 0.8701994444597214\n",
      "배치 인덱스 : 187\t|\t이동 손실 : 0.8706185770161609\n",
      "배치 인덱스 : 188\t|\t이동 손실 : 0.8705013779105333\n",
      "배치 인덱스 : 189\t|\t이동 손실 : 0.8712991234503294\n",
      "배치 인덱스 : 190\t|\t이동 손실 : 0.8714998273949349\n",
      "배치 인덱스 : 191\t|\t이동 손실 : 0.8722890044252078\n",
      "배치 인덱스 : 192\t|\t이동 손실 : 0.8725464862863017\n",
      "배치 인덱스 : 193\t|\t이동 손실 : 0.8730515017337406\n",
      "배치 인덱스 : 194\t|\t이동 손실 : 0.8732924122076768\n",
      "배치 인덱스 : 195\t|\t이동 손실 : 0.8731353270764254\n",
      "배치 인덱스 : 196\t|\t이동 손실 : 0.8731686019050289\n",
      "배치 인덱스 : 197\t|\t이동 손실 : 0.8736984452815971\n",
      "배치 인덱스 : 198\t|\t이동 손실 : 0.873634138598514\n",
      "배치 인덱스 : 199\t|\t이동 손실 : 0.8735241043567658\n",
      "배치 인덱스 : 200\t|\t이동 손실 : 0.8737088604946042\n",
      "배치 인덱스 : 201\t|\t이동 손실 : 0.8742234863267087\n",
      "배치 인덱스 : 202\t|\t이동 손실 : 0.8743975876000127\n",
      "배치 인덱스 : 203\t|\t이동 손실 : 0.8747950243014916\n",
      "배치 인덱스 : 204\t|\t이동 손실 : 0.8746176271903806\n",
      "배치 인덱스 : 205\t|\t이동 손실 : 0.8750502276189119\n",
      "배치 인덱스 : 206\t|\t이동 손실 : 0.8754660213627101\n",
      "배치 인덱스 : 207\t|\t이동 손실 : 0.8752608901033034\n",
      "배치 인덱스 : 208\t|\t이동 손실 : 0.8752981815041537\n",
      "배치 인덱스 : 209\t|\t이동 손실 : 0.8755896145389194\n",
      "배치 인덱스 : 210\t|\t이동 손실 : 0.8763396816231064\n",
      "배치 인덱스 : 211\t|\t이동 손실 : 0.8765806004686176\n",
      "배치 인덱스 : 212\t|\t이동 손실 : 0.8765619802922711\n",
      "배치 인덱스 : 213\t|\t이동 손실 : 0.8767721201771889\n",
      "배치 인덱스 : 214\t|\t이동 손실 : 0.8769312315208968\n",
      "배치 인덱스 : 215\t|\t이동 손실 : 0.8772735512918897\n",
      "배치 인덱스 : 216\t|\t이동 손실 : 0.877648599960837\n",
      "배치 인덱스 : 217\t|\t이동 손실 : 0.8779620399715704\n",
      "배치 인덱스 : 218\t|\t이동 손실 : 0.8779246330805566\n",
      "배치 인덱스 : 219\t|\t이동 손실 : 0.8780427835204385\n",
      "배치 인덱스 : 220\t|\t이동 손실 : 0.8780904099412634\n",
      "배치 인덱스 : 221\t|\t이동 손실 : 0.8781399549664679\n",
      "배치 인덱스 : 222\t|\t이동 손실 : 0.8781322366453608\n",
      "배치 인덱스 : 223\t|\t이동 손실 : 0.8785896354487965\n",
      "배치 인덱스 : 224\t|\t이동 손실 : 0.8790414759847854\n",
      "배치 인덱스 : 225\t|\t이동 손실 : 0.8790388394773535\n",
      "배치 인덱스 : 226\t|\t이동 손실 : 0.8792226107110012\n",
      "Epoch: 09 | Time: 15m 9s\n",
      "\tTrain Loss: 0.879 | Train PPL: 2.409\n",
      "\tValidation Loss: 2.011 | Validation PPL: 7.472\n",
      "에폭 : 9\n",
      "배치 인덱스 : 0\t|\t이동 손실 : 0.7278428077697754\n",
      "배치 인덱스 : 1\t|\t이동 손실 : 0.7134747505187988\n",
      "배치 인덱스 : 2\t|\t이동 손실 : 0.7116209864616394\n",
      "배치 인덱스 : 3\t|\t이동 손실 : 0.7230651527643204\n",
      "배치 인덱스 : 4\t|\t이동 손실 : 0.724059522151947\n",
      "배치 인덱스 : 5\t|\t이동 손실 : 0.7244240343570709\n",
      "배치 인덱스 : 6\t|\t이동 손실 : 0.7193680916513715\n",
      "배치 인덱스 : 7\t|\t이동 손실 : 0.7203804180026054\n",
      "배치 인덱스 : 8\t|\t이동 손실 : 0.7075157827801175\n",
      "배치 인덱스 : 9\t|\t이동 손실 : 0.7123698115348817\n",
      "배치 인덱스 : 10\t|\t이동 손실 : 0.7059529586271807\n",
      "배치 인덱스 : 11\t|\t이동 손실 : 0.7100832164287567\n",
      "배치 인덱스 : 12\t|\t이동 손실 : 0.7097946588809674\n",
      "배치 인덱스 : 13\t|\t이동 손실 : 0.70512484226908\n",
      "배치 인덱스 : 14\t|\t이동 손실 : 0.7051721731821696\n",
      "배치 인덱스 : 15\t|\t이동 손실 : 0.7077508680522442\n",
      "배치 인덱스 : 16\t|\t이동 손실 : 0.7100925971479977\n",
      "배치 인덱스 : 17\t|\t이동 손실 : 0.713437236017651\n",
      "배치 인덱스 : 18\t|\t이동 손실 : 0.7161278850153873\n",
      "배치 인덱스 : 19\t|\t이동 손실 : 0.7179920583963394\n",
      "배치 인덱스 : 20\t|\t이동 손실 : 0.7193412865911211\n",
      "배치 인덱스 : 21\t|\t이동 손실 : 0.7178533212705092\n",
      "배치 인덱스 : 22\t|\t이동 손실 : 0.7207087874412537\n",
      "배치 인덱스 : 23\t|\t이동 손실 : 0.722526433567206\n",
      "배치 인덱스 : 24\t|\t이동 손실 : 0.7221791815757751\n",
      "배치 인덱스 : 25\t|\t이동 손실 : 0.7231763945176051\n",
      "배치 인덱스 : 26\t|\t이동 손실 : 0.7264883849355909\n",
      "배치 인덱스 : 27\t|\t이동 손실 : 0.7259860783815383\n",
      "배치 인덱스 : 28\t|\t이동 손실 : 0.7248450106587903\n",
      "배치 인덱스 : 29\t|\t이동 손실 : 0.7261181155840555\n",
      "배치 인덱스 : 30\t|\t이동 손실 : 0.7274196417100967\n",
      "배치 인덱스 : 31\t|\t이동 손실 : 0.7279463745653628\n",
      "배치 인덱스 : 32\t|\t이동 손실 : 0.7258625084703618\n",
      "배치 인덱스 : 33\t|\t이동 손실 : 0.7252592952812419\n",
      "배치 인덱스 : 34\t|\t이동 손실 : 0.7255749974931989\n",
      "배치 인덱스 : 35\t|\t이동 손실 : 0.7263209306531482\n",
      "배치 인덱스 : 36\t|\t이동 손실 : 0.7259932691986496\n",
      "배치 인덱스 : 37\t|\t이동 손실 : 0.726189241597527\n",
      "배치 인덱스 : 38\t|\t이동 손실 : 0.7275396509048266\n",
      "배치 인덱스 : 39\t|\t이동 손실 : 0.7289371013641357\n",
      "배치 인덱스 : 40\t|\t이동 손실 : 0.7296804305983753\n",
      "배치 인덱스 : 41\t|\t이동 손실 : 0.7304955621560415\n",
      "배치 인덱스 : 42\t|\t이동 손실 : 0.7304574237313382\n",
      "배치 인덱스 : 43\t|\t이동 손실 : 0.7284351804039695\n",
      "배치 인덱스 : 44\t|\t이동 손실 : 0.7293756484985351\n",
      "배치 인덱스 : 45\t|\t이동 손실 : 0.7278548634570577\n",
      "배치 인덱스 : 46\t|\t이동 손실 : 0.7274203769704128\n",
      "배치 인덱스 : 47\t|\t이동 손실 : 0.7268943910797436\n",
      "배치 인덱스 : 48\t|\t이동 손실 : 0.7272953585702545\n",
      "배치 인덱스 : 49\t|\t이동 손실 : 0.7269328916072845\n",
      "배치 인덱스 : 50\t|\t이동 손실 : 0.7262392908919091\n",
      "배치 인덱스 : 51\t|\t이동 손실 : 0.7279294717770356\n",
      "배치 인덱스 : 52\t|\t이동 손실 : 0.7284011278512342\n",
      "배치 인덱스 : 53\t|\t이동 손실 : 0.7282908084215941\n",
      "배치 인덱스 : 54\t|\t이동 손실 : 0.7284165707501498\n",
      "배치 인덱스 : 55\t|\t이동 손실 : 0.7286735304764338\n",
      "배치 인덱스 : 56\t|\t이동 손실 : 0.7275227465127643\n",
      "배치 인덱스 : 57\t|\t이동 손실 : 0.7277429925984349\n",
      "배치 인덱스 : 58\t|\t이동 손실 : 0.728217209799815\n",
      "배치 인덱스 : 59\t|\t이동 손실 : 0.728917767604192\n",
      "배치 인덱스 : 60\t|\t이동 손실 : 0.7298916666234125\n",
      "배치 인덱스 : 61\t|\t이동 손실 : 0.7303782307332561\n",
      "배치 인덱스 : 62\t|\t이동 손실 : 0.7311700601426382\n",
      "배치 인덱스 : 63\t|\t이동 손실 : 0.7314181514084339\n",
      "배치 인덱스 : 64\t|\t이동 손실 : 0.7312423045818622\n",
      "배치 인덱스 : 65\t|\t이동 손실 : 0.7309115222006133\n",
      "배치 인덱스 : 66\t|\t이동 손실 : 0.7308326372459752\n",
      "배치 인덱스 : 67\t|\t이동 손실 : 0.7304728609674116\n",
      "배치 인덱스 : 68\t|\t이동 손실 : 0.73122426305992\n",
      "배치 인덱스 : 69\t|\t이동 손실 : 0.7327356909002576\n",
      "배치 인덱스 : 70\t|\t이동 손실 : 0.7329034511472137\n",
      "배치 인덱스 : 71\t|\t이동 손실 : 0.732859573430485\n",
      "배치 인덱스 : 72\t|\t이동 손실 : 0.7329323144808205\n",
      "배치 인덱스 : 73\t|\t이동 손실 : 0.73384129598334\n",
      "배치 인덱스 : 74\t|\t이동 손실 : 0.7335724496841428\n",
      "배치 인덱스 : 75\t|\t이동 손실 : 0.7340299173405294\n",
      "배치 인덱스 : 76\t|\t이동 손실 : 0.735011347702571\n",
      "배치 인덱스 : 77\t|\t이동 손실 : 0.7362040006197413\n",
      "배치 인덱스 : 78\t|\t이동 손실 : 0.736956391153456\n",
      "배치 인덱스 : 79\t|\t이동 손실 : 0.7369667656719682\n",
      "배치 인덱스 : 80\t|\t이동 손실 : 0.7372070271291847\n",
      "배치 인덱스 : 81\t|\t이동 손실 : 0.7371710030043994\n",
      "배치 인덱스 : 82\t|\t이동 손실 : 0.7374121762183772\n",
      "배치 인덱스 : 83\t|\t이동 손실 : 0.7380470789614174\n",
      "배치 인덱스 : 84\t|\t이동 손실 : 0.737692973193\n",
      "배치 인덱스 : 85\t|\t이동 손실 : 0.737915597682775\n",
      "배치 인덱스 : 86\t|\t이동 손실 : 0.739499405882824\n",
      "배치 인덱스 : 87\t|\t이동 손실 : 0.7392468235709446\n",
      "배치 인덱스 : 88\t|\t이동 손실 : 0.7395527757955397\n",
      "배치 인덱스 : 89\t|\t이동 손실 : 0.740130821201536\n",
      "배치 인덱스 : 90\t|\t이동 손실 : 0.7395321936397757\n",
      "배치 인덱스 : 91\t|\t이동 손실 : 0.7393257786398344\n",
      "배치 인덱스 : 92\t|\t이동 손실 : 0.7403263699623842\n",
      "배치 인덱스 : 93\t|\t이동 손실 : 0.7399632486891236\n",
      "배치 인덱스 : 94\t|\t이동 손실 : 0.7401814372915967\n",
      "배치 인덱스 : 95\t|\t이동 손실 : 0.7404045294970271\n",
      "배치 인덱스 : 96\t|\t이동 손실 : 0.7407358645163857\n",
      "배치 인덱스 : 97\t|\t이동 손실 : 0.7406812936675788\n",
      "배치 인덱스 : 98\t|\t이동 손실 : 0.7411152497686517\n",
      "배치 인덱스 : 99\t|\t이동 손실 : 0.740756197571754\n",
      "배치 인덱스 : 100\t|\t이동 손실 : 0.7410558940160389\n",
      "배치 인덱스 : 101\t|\t이동 손실 : 0.7411921521027879\n",
      "배치 인덱스 : 102\t|\t이동 손실 : 0.7414171527890322\n",
      "배치 인덱스 : 103\t|\t이동 손실 : 0.7417531219812536\n",
      "배치 인덱스 : 104\t|\t이동 손실 : 0.7425874272982276\n",
      "배치 인덱스 : 105\t|\t이동 손실 : 0.7428541324048669\n",
      "배치 인덱스 : 106\t|\t이동 손실 : 0.7434295883802606\n",
      "배치 인덱스 : 107\t|\t이동 손실 : 0.7433274940208149\n",
      "배치 인덱스 : 108\t|\t이동 손실 : 0.742803383311\n",
      "배치 인덱스 : 109\t|\t이동 손실 : 0.7435032627799291\n",
      "배치 인덱스 : 110\t|\t이동 손실 : 0.7437138884991136\n",
      "배치 인덱스 : 111\t|\t이동 손실 : 0.744140442460775\n",
      "배치 인덱스 : 112\t|\t이동 손실 : 0.7441592643746229\n",
      "배치 인덱스 : 113\t|\t이동 손실 : 0.744282893444362\n",
      "배치 인덱스 : 114\t|\t이동 손실 : 0.7447534270908518\n",
      "배치 인덱스 : 115\t|\t이동 손실 : 0.7454070536227059\n",
      "배치 인덱스 : 116\t|\t이동 손실 : 0.7455015258911325\n",
      "배치 인덱스 : 117\t|\t이동 손실 : 0.7460296361123098\n",
      "배치 인덱스 : 118\t|\t이동 손실 : 0.7461891124228466\n",
      "배치 인덱스 : 119\t|\t이동 손실 : 0.7466387569904324\n",
      "배치 인덱스 : 120\t|\t이동 손실 : 0.7472431920776679\n",
      "배치 인덱스 : 121\t|\t이동 손실 : 0.7478667888485013\n",
      "배치 인덱스 : 122\t|\t이동 손실 : 0.748014960347152\n",
      "배치 인덱스 : 123\t|\t이동 손실 : 0.7481599248224685\n",
      "배치 인덱스 : 124\t|\t이동 손실 : 0.7483063263893124\n",
      "배치 인덱스 : 125\t|\t이동 손실 : 0.7481449336286572\n",
      "배치 인덱스 : 126\t|\t이동 손실 : 0.7485074964095285\n",
      "배치 인덱스 : 127\t|\t이동 손실 : 0.7484498275443908\n",
      "배치 인덱스 : 128\t|\t이동 손실 : 0.7486561656922329\n",
      "배치 인덱스 : 129\t|\t이동 손실 : 0.749062474415852\n",
      "배치 인덱스 : 130\t|\t이동 손실 : 0.749494885215322\n",
      "배치 인덱스 : 131\t|\t이동 손실 : 0.7499783242290666\n",
      "배치 인덱스 : 132\t|\t이동 손실 : 0.7500000847013369\n",
      "배치 인덱스 : 133\t|\t이동 손실 : 0.7505093652810619\n",
      "배치 인덱스 : 134\t|\t이동 손실 : 0.7511894142186196\n",
      "배치 인덱스 : 135\t|\t이동 손실 : 0.7515292829450435\n",
      "배치 인덱스 : 136\t|\t이동 손실 : 0.7515223848558686\n",
      "배치 인덱스 : 137\t|\t이동 손실 : 0.7515065734801081\n",
      "배치 인덱스 : 138\t|\t이동 손실 : 0.7519850812369967\n",
      "배치 인덱스 : 139\t|\t이동 손실 : 0.752261610116277\n",
      "배치 인덱스 : 140\t|\t이동 손실 : 0.7525585948998197\n",
      "배치 인덱스 : 141\t|\t이동 손실 : 0.7524007034133854\n",
      "배치 인덱스 : 142\t|\t이동 손실 : 0.7531481706179102\n",
      "배치 인덱스 : 143\t|\t이동 손실 : 0.7532423076530294\n",
      "배치 인덱스 : 144\t|\t이동 손실 : 0.7532359863149705\n",
      "배치 인덱스 : 145\t|\t이동 손실 : 0.7535184029846971\n",
      "배치 인덱스 : 146\t|\t이동 손실 : 0.7536336317354314\n",
      "배치 인덱스 : 147\t|\t이동 손실 : 0.7538007606525674\n",
      "배치 인덱스 : 148\t|\t이동 손실 : 0.7535049999320262\n",
      "배치 인덱스 : 149\t|\t이동 손실 : 0.7532068085670467\n",
      "배치 인덱스 : 150\t|\t이동 손실 : 0.752837706875327\n",
      "배치 인덱스 : 151\t|\t이동 손실 : 0.7530980345449946\n",
      "배치 인덱스 : 152\t|\t이동 손실 : 0.7539025303585074\n",
      "배치 인덱스 : 153\t|\t이동 손실 : 0.7541960590071489\n",
      "배치 인덱스 : 154\t|\t이동 손실 : 0.7541955686384628\n",
      "배치 인덱스 : 155\t|\t이동 손실 : 0.7543113395953787\n",
      "배치 인덱스 : 156\t|\t이동 손실 : 0.7544279364263933\n",
      "배치 인덱스 : 157\t|\t이동 손실 : 0.7546319176879107\n",
      "배치 인덱스 : 158\t|\t이동 손실 : 0.7543516777596381\n",
      "배치 인덱스 : 159\t|\t이동 손실 : 0.7550961799919602\n",
      "배치 인덱스 : 160\t|\t이동 손실 : 0.755651113409433\n",
      "배치 인덱스 : 161\t|\t이동 손실 : 0.7560320430331757\n",
      "배치 인덱스 : 162\t|\t이동 손실 : 0.7563974136955165\n",
      "배치 인덱스 : 163\t|\t이동 손실 : 0.7565357234419843\n",
      "배치 인덱스 : 164\t|\t이동 손실 : 0.7565769170269818\n",
      "배치 인덱스 : 165\t|\t이동 손실 : 0.756693329078605\n",
      "배치 인덱스 : 166\t|\t이동 손실 : 0.7571040616777839\n",
      "배치 인덱스 : 167\t|\t이동 손실 : 0.75685073045038\n",
      "배치 인덱스 : 168\t|\t이동 손실 : 0.7567853955827517\n",
      "배치 인덱스 : 169\t|\t이동 손실 : 0.7566639388308801\n",
      "배치 인덱스 : 170\t|\t이동 손실 : 0.7563759234913604\n",
      "배치 인덱스 : 171\t|\t이동 손실 : 0.7563594749500581\n",
      "배치 인덱스 : 172\t|\t이동 손실 : 0.7567208254268399\n",
      "배치 인덱스 : 173\t|\t이동 손실 : 0.7571538354473548\n",
      "배치 인덱스 : 174\t|\t이동 손실 : 0.7572465395927425\n",
      "배치 인덱스 : 175\t|\t이동 손실 : 0.7573402950709511\n",
      "배치 인덱스 : 176\t|\t이동 손실 : 0.7575987506720975\n",
      "배치 인덱스 : 177\t|\t이동 손실 : 0.7575274685795383\n",
      "배치 인덱스 : 178\t|\t이동 손실 : 0.7579542784717492\n",
      "배치 인덱스 : 179\t|\t이동 손실 : 0.7582516723208954\n",
      "배치 인덱스 : 180\t|\t이동 손실 : 0.758015380379903\n",
      "배치 인덱스 : 181\t|\t이동 손실 : 0.7580117219752004\n",
      "배치 인덱스 : 182\t|\t이동 손실 : 0.7576697204933788\n",
      "배치 인덱스 : 183\t|\t이동 손실 : 0.7579337513965105\n",
      "배치 인덱스 : 184\t|\t이동 손실 : 0.7578294116097524\n",
      "배치 인덱스 : 185\t|\t이동 손실 : 0.7580532284193138\n",
      "배치 인덱스 : 186\t|\t이동 손실 : 0.7585901844310247\n",
      "배치 인덱스 : 187\t|\t이동 손실 : 0.758976540349899\n",
      "배치 인덱스 : 188\t|\t이동 손실 : 0.7591108512626119\n",
      "배치 인덱스 : 189\t|\t이동 손실 : 0.7592340020756968\n",
      "배치 인덱스 : 190\t|\t이동 손실 : 0.7595872476462914\n",
      "배치 인덱스 : 191\t|\t이동 손실 : 0.7598425230632221\n",
      "배치 인덱스 : 192\t|\t이동 손실 : 0.7601649773553241\n",
      "배치 인덱스 : 193\t|\t이동 손실 : 0.7601435737511542\n",
      "배치 인덱스 : 194\t|\t이동 손실 : 0.7601378966600463\n",
      "배치 인덱스 : 195\t|\t이동 손실 : 0.760253543148235\n",
      "배치 인덱스 : 196\t|\t이동 손실 : 0.7605020887960633\n",
      "배치 인덱스 : 197\t|\t이동 손실 : 0.7605525210048208\n",
      "배치 인덱스 : 198\t|\t이동 손실 : 0.7608901441995818\n",
      "배치 인덱스 : 199\t|\t이동 손실 : 0.7609867978096004\n",
      "배치 인덱스 : 200\t|\t이동 손실 : 0.7610447374149337\n",
      "배치 인덱스 : 201\t|\t이동 손실 : 0.7613845576744265\n",
      "배치 인덱스 : 202\t|\t이동 손실 : 0.7616436504965342\n",
      "배치 인덱스 : 203\t|\t이동 손실 : 0.7620343209481704\n",
      "배치 인덱스 : 204\t|\t이동 손실 : 0.7618424904055708\n",
      "배치 인덱스 : 205\t|\t이동 손실 : 0.7623164688499225\n",
      "배치 인덱스 : 206\t|\t이동 손실 : 0.7625405707796987\n",
      "배치 인덱스 : 207\t|\t이동 손실 : 0.763081321922632\n",
      "배치 인덱스 : 208\t|\t이동 손실 : 0.7633441187548291\n",
      "배치 인덱스 : 209\t|\t이동 손실 : 0.7635900645028973\n",
      "배치 인덱스 : 210\t|\t이동 손실 : 0.7634628437706641\n",
      "배치 인덱스 : 211\t|\t이동 손실 : 0.7637772520758067\n",
      "배치 인덱스 : 212\t|\t이동 손실 : 0.7640419291778345\n",
      "배치 인덱스 : 213\t|\t이동 손실 : 0.7645556806960948\n",
      "배치 인덱스 : 214\t|\t이동 손실 : 0.7649220940678614\n",
      "배치 인덱스 : 215\t|\t이동 손실 : 0.7647916398666518\n",
      "배치 인덱스 : 216\t|\t이동 손실 : 0.7646581025167539\n",
      "배치 인덱스 : 217\t|\t이동 손실 : 0.7647622667868198\n",
      "배치 인덱스 : 218\t|\t이동 손실 : 0.7647855679194128\n",
      "배치 인덱스 : 219\t|\t이동 손실 : 0.7648622263561591\n",
      "배치 인덱스 : 220\t|\t이동 손실 : 0.7646596596251781\n",
      "배치 인덱스 : 221\t|\t이동 손실 : 0.7648607892496088\n",
      "배치 인덱스 : 222\t|\t이동 손실 : 0.7646457812176687\n",
      "배치 인덱스 : 223\t|\t이동 손실 : 0.7649342492222782\n",
      "배치 인덱스 : 224\t|\t이동 손실 : 0.7649020473162329\n",
      "배치 인덱스 : 225\t|\t이동 손실 : 0.7649969471766881\n",
      "배치 인덱스 : 226\t|\t이동 손실 : 0.7649025050553977\n",
      "Epoch: 10 | Time: 15m 31s\n",
      "\tTrain Loss: 0.765 | Train PPL: 2.149\n",
      "\tValidation Loss: 2.060 | Validation PPL: 7.843\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "import random\n",
    "\n",
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time() # 시작 시간 기록\n",
    "\n",
    "    print(f\"에폭 : {epoch}\")\n",
    "\n",
    "    train_loss = train(model, train_dataloader, optimizer, criterion, CLIP, device)\n",
    "    valid_loss = evaluate(model, valid_dataloader, criterion, device)\n",
    "\n",
    "    end_time = time.time() # 종료 시간 기록\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'transformer_german_to_english.pt')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):.3f}')\n",
    "    print(f'\\tValidation Loss: {valid_loss:.3f} | Validation PPL: {math.exp(valid_loss):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1cENwd0ik9C"
   },
   "source": [
    "### build_vocab_from_iterator에서 min_freq(최소 빈도)를 2로 설정했을 때 에폭 9, 10 결과  \n",
    "~~~\n",
    "Epoch: 09 | Time: 13m 20s\n",
    "\tTrain Loss: 1.055 | Train PPL: 2.871\n",
    "\tValidation Loss: 1.691 | Validation PPL: 5.424\n",
    "\n",
    "Epoch: 10 | Time: 13m 38s\n",
    "\tTrain Loss: 0.958 | Train PPL: 2.608\n",
    "\tValidation Loss: 1.732 | Validation PPL: 5.655\n",
    "~~~\n",
    "\n",
    "### build_vocab_from_iterator에서 min_freq(최소 빈도)를 1로 설정했을 때 에폭 8 ~ 10 결과  \n",
    "~~~\n",
    "Epoch: 08 | Time: 15m 4s\n",
    "\tTrain Loss: 1.012 | Train PPL: 2.750\n",
    "\tValidation Loss: 1.978 | Validation PPL: 7.225\n",
    "\n",
    "Epoch: 09 | Time: 15m 9s\n",
    "\tTrain Loss: 0.879 | Train PPL: 2.409\n",
    "\tValidation Loss: 2.011 | Validation PPL: 7.472\n",
    "\n",
    "Epoch: 10 | Time: 15m 31s\n",
    "\tTrain Loss: 0.765 | Train PPL: 2.149\n",
    "\tValidation Loss: 2.060 | Validation PPL: 7.843\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('transformer_german_to_english.pt'))\n",
    "\n",
    "#test_loss = evaluate(model, train_dataloader, criterion, device)\n",
    "\n",
    "#print(f'Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역(translation) 함수\n",
    "def translate_sentence(sentence, src_vocab, trg_vocab, model, device, max_len=50, logging=True):\n",
    "    model.eval() # 평가 모드\n",
    "\n",
    "    if isinstance(sentence, str):\n",
    "        nlp = spacy.load('de')\n",
    "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "\n",
    "    # 처음에  토큰, 마지막에  토큰 붙이기\n",
    "    tokens = ['<bos>'] + tokens + ['<eos>']\n",
    "    if logging:\n",
    "        print(f\"전체 소스 토큰: {tokens}\")\n",
    "\n",
    "    src_indexes = src_vocab.lookup_indices(tokens)\n",
    "    if logging:\n",
    "        print(f\"소스 문장 인덱스: {src_indexes}\")\n",
    "\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
    "\n",
    "    # 소스 문장에 따른 마스크 생성\n",
    "    src_mask = model.create_src_mask(src_tensor)\n",
    "\n",
    "    # 인코더(endocer)에 소스 문장을 넣어 출력 값 구하기\n",
    "    with torch.no_grad():\n",
    "        enc_src = model.encoder(src_tensor, src_mask)\n",
    "\n",
    "    # 처음에는  토큰 하나만 가지고 있도록 하기\n",
    "    trg_indexes = [2] #trg_vocab.lookup_indices(['<bos>'])\n",
    "\n",
    "    for i in range(max_len):\n",
    "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
    "\n",
    "        # 출력 문장에 따른 마스크 생성\n",
    "        trg_mask = model.create_tgt_mask(trg_tensor)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
    "\n",
    "        # 출력 문장에서 가장 마지막 단어만 사용\n",
    "        pred_token = output.argmax(2)[:,-1].item()\n",
    "        trg_indexes.append(pred_token) # 출력 문장에 더하기\n",
    "\n",
    "        # 를 만나는 순간 끝\n",
    "        if pred_token == trg_vocab.lookup_indices(['<eos>'])[0]:\n",
    "            break\n",
    "\n",
    "    # 각 출력 단어 인덱스를 실제 단어로 변환\n",
    "    trg_tokens = [trg_vocab.lookup_token(i) for i in trg_indexes]\n",
    "\n",
    "    # 첫 번째 는 제외하고 출력 문장 반환\n",
    "    return trg_tokens[1:], attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 소스 토큰: ['<bos>', 'ein', 'mädchen', 'in', 'einem', 'jeanskleid', 'läuft', 'über', 'einen', 'erhöhten', 'schwebebalken', '.', '<eos>']\n",
      "소스 문장 인덱스: [2, 15, 0, 7, 6, 0, 86, 43, 20, 3480, 0, 4, 3]\n",
      "['A', 'lone', 'worker', 'in', 'a', 'ski', 'suit', 'is', 'walking', 'across', 'an', 'elevated', 'roof', '.', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "#test_src_sentence = ['eine', 'mutter', 'und', 'ihr', 'kleiner', 'sohn', 'genießen', 'einen', 'schönen', 'tag', 'im', 'freien', '.']\n",
    "test_src_sentence = ['Ein', 'Mädchen', 'in', 'einem', 'Jeanskleid', 'läuft', 'über', 'einen', 'erhöhten', 'Schwebebalken', '.']\n",
    "translation, attention = translate_sentence(test_src_sentence, vocab_transform[SRC_LANG], vocab_transform[TGT_LANG], model, device, logging=True)\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 소스 토큰: ['<bos>', 'eine', 'frau', 'sitzt', 'an', 'einer', 'dunklen', 'bar', '.', '<eos>']\n",
      "소스 문장 인덱스: [2, 18, 0, 32, 23, 13, 389, 0, 4, 3]\n",
      "모델 출력 결과: A lone child is sitting by a dark ski lift . <eos>\n"
     ]
    }
   ],
   "source": [
    "test_src_sentence = ['Eine', 'Frau', 'sitzt', 'an', 'einer', 'dunklen', 'Bar','.']\n",
    "#A woman sits at a dark bar.\n",
    "translation, attention = translate_sentence(test_src_sentence, vocab_transform[SRC_LANG], vocab_transform[TGT_LANG], model, device, logging=True)\n",
    "print(\"모델 출력 결과:\", \" \".join(translation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 소스 토큰: ['<bos>', 'drei', 'alte', 'männer', 'sehen', 'einem', 'anderen', 'mann', 'zu', ',', 'wie', 'er', 'fisch', 'zubereitet', '.', '<eos>']\n",
      "소스 문장 인덱스: [2, 196, 418, 0, 147, 6, 99, 0, 29, 8, 170, 153, 0, 1624, 4, 3]\n",
      "모델 출력 결과: 3 old worker is watching another shooting frisbee . <eos>\n"
     ]
    }
   ],
   "source": [
    "test_src_sentence = ['Drei', 'alte', 'Männer', 'sehen', 'einem', 'anderen', 'Mann', 'zu', ',', 'wie', 'er', 'Fisch', 'zubereitet', '.']\n",
    "#Three old men are watching another man prepare fish.\n",
    "translation, attention = translate_sentence(test_src_sentence, vocab_transform[SRC_LANG], vocab_transform[TGT_LANG], model, device, logging=True)\n",
    "print(\"모델 출력 결과:\", \" \".join(translation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 소스 토큰: ['<bos>', 'eine', 'mutter', 'und', 'ihr', 'kleiner', 'sohn', 'genießen', 'einen', 'schönen', 'tag', 'im', 'freien', '.', '<eos>']\n",
      "소스 문장 인덱스: [2, 18, 0, 9, 138, 75, 0, 583, 20, 807, 0, 22, 2235, 4, 3]\n",
      "모델 출력 결과: A lone car and her small kite enjoy a nice leaf during the driveway . <eos>\n"
     ]
    }
   ],
   "source": [
    "test_src_sentence = ['Eine', 'Mutter', 'und', 'ihr', 'kleiner', 'Sohn', 'genießen', 'einen', 'schönen', 'Tag', 'im', 'Freien', '.']\n",
    "#A mother and her young song enjoying a beautiful day outside.\t\n",
    "translation, attention = translate_sentence(test_src_sentence, vocab_transform[SRC_LANG], vocab_transform[TGT_LANG], model, device, logging=True)\n",
    "print(\"모델 출력 결과:\", \" \".join(translation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vocab 빌드에 최소 빈도를 2로 지정했을 경우\n",
    "\n",
    "번역 테스트 1  \n",
    "~~~\n",
    "전체 소스 토큰: ['<bos>', 'ein', 'mädchen', 'in', 'einem', 'jeanskleid', 'läuft', 'über', 'einen', 'erhöhten', 'schwebebalken', '.', '<eos>']\n",
    "소스 문장 인덱스: [2, 15, 0, 7, 6, 0, 86, 43, 20, 3480, 0, 4, 3]\n",
    "['<unk>', '<unk>', 'in', 'a', '<unk>', \"'s\", 'and', 'running', 'over', 'an', 'elevated', 'platform', '.', '<eos>']\n",
    "~~~\n",
    "\n",
    "번역 테스트 2  \n",
    "~~~\n",
    "전체 소스 토큰: ['<bos>', 'eine', 'frau', 'sitzt', 'an', 'einer', 'dunklen', 'bar', '.', '<eos>']\n",
    "소스 문장 인덱스: [2, 18, 0, 32, 23, 13, 389, 0, 4, 3]\n",
    "모델 출력 결과: <unk> <unk> sitting at a dark plastic bar . <eos>\n",
    "~~~\n",
    "\n",
    "Out-of-Vocabulary(OoV) 문제가 발생했다.  \n",
    "~~~\n",
    "  vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n",
    "                                                  min_freq=2, \n",
    "                                                  specials=special_symbols,\n",
    "                                                  special_first=True)\n",
    "~~~\n",
    "min_freq를 2로 지정하여 최소 2번 이상 등장한 단어만을 선택하도록 해놨어서 어휘사전에 없는 단어가 많은 것 같다.  \n",
    "\n",
    "min_freq를 1로 지정하여 다시 실행해봤다.  \n",
    "\n",
    "### vocab 빌드에 최소 빈도를 1로 지정했을 경우\n",
    "\n",
    "번역 테스트 1  \n",
    "~~~\n",
    "전체 소스 토큰: ['<bos>', 'ein', 'mädchen', 'in', 'einem', 'jeanskleid', 'läuft', 'über', 'einen', 'erhöhten', 'schwebebalken', '.', '<eos>']\n",
    "소스 문장 인덱스: [2, 15, 0, 7, 6, 0, 86, 43, 20, 3480, 0, 4, 3]\n",
    "['A', 'lone', 'worker', 'in', 'a', 'ski', 'suit', 'is', 'walking', 'across', 'an', 'elevated', 'roof', '.', '<eos>']\n",
    "정답: \n",
    "~~~\n",
    "\n",
    "번역 테스트 2  \n",
    "~~~\n",
    "전체 소스 토큰: ['<bos>', 'eine', 'frau', 'sitzt', 'an', 'einer', 'dunklen', 'bar', '.', '<eos>']\n",
    "소스 문장 인덱스: [2, 18, 0, 32, 23, 13, 389, 0, 4, 3]\n",
    "모델 출력 결과: A lone child is sitting by a dark ski lift . <eos>\n",
    "정답: A woman sits at a dark bar.\n",
    "~~~\n",
    "\n",
    "번역 테스트 3  \n",
    "~~~\n",
    "전체 소스 토큰: ['<bos>', 'drei', 'alte', 'männer', 'sehen', 'einem', 'anderen', 'mann', 'zu', ',', 'wie', 'er', 'fisch', 'zubereitet', '.', '<eos>']\n",
    "소스 문장 인덱스: [2, 196, 418, 0, 147, 6, 99, 0, 29, 8, 170, 153, 0, 1624, 4, 3]\n",
    "모델 출력 결과: 3 old worker is watching another shooting frisbee . <eos>\n",
    "정답: Three old men are watching another man prepare fish.\n",
    "~~~\n",
    "\n",
    "UNK 토큰이 줄은 것처럼 보이지만 번역 결과가 이상하다. 원인이 뭘까...  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
