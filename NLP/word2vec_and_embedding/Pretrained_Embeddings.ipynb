{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pNflcE7Xnf4E",
    "outputId": "c37a5619-0baf-486d-ac5e-5390713dc5b2"
   },
   "outputs": [],
   "source": [
    "# annoy 패키지를 설치합니다.\n",
    "!pip install annoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wce9esK2nbQA"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from annoy import AnnoyIndex\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ilK5G46nbQB"
   },
   "outputs": [],
   "source": [
    "class PreTrainedEmbeddings(object):\n",
    "    \"\"\" 사전 훈련된 단어 벡터 사용을 위한 래퍼 클래스 \"\"\"\n",
    "    def __init__(self, word_to_index, word_vectors):\n",
    "        \"\"\"\n",
    "        매개변수:\n",
    "            word_to_index (dict): 단어에서 정수로 매핑\n",
    "            word_vectors (numpy 배열의 리스트)\n",
    "        \"\"\"\n",
    "        self.word_to_index = word_to_index\n",
    "        self.word_vectors = word_vectors\n",
    "        self.index_to_word = {v: k for k, v in self.word_to_index.items()}\n",
    "\n",
    "        self.index = AnnoyIndex(len(word_vectors[0]), metric='euclidean')\n",
    "        print(\"인덱스 만드는 중!\")\n",
    "        for _, i in self.word_to_index.items():\n",
    "            self.index.add_item(i, self.word_vectors[i])\n",
    "        self.index.build(50)\n",
    "        print(\"완료!\")\n",
    "        \n",
    "    @classmethod\n",
    "    def from_embeddings_file(cls, embedding_file):\n",
    "        \"\"\"사전 훈련된 벡터 파일에서 객체를 만듭니다.\n",
    "        \n",
    "        벡터 파일은 다음과 같은 포맷입니다:\n",
    "            word0 x0_0 x0_1 x0_2 x0_3 ... x0_N\n",
    "            word1 x1_0 x1_1 x1_2 x1_3 ... x1_N\n",
    "        \n",
    "        매개변수:\n",
    "            embedding_file (str): 파일 위치\n",
    "        반환값:\n",
    "            PretrainedEmbeddings의 인스턴스\n",
    "        \"\"\"\n",
    "        word_to_index = {}\n",
    "        word_vectors = []\n",
    "\n",
    "        with open(embedding_file) as fp:\n",
    "            for line in fp.readlines():\n",
    "                line = line.split(\" \")\n",
    "                word = line[0]\n",
    "                vec = np.array([float(x) for x in line[1:]])\n",
    "                \n",
    "                word_to_index[word] = len(word_to_index)\n",
    "                word_vectors.append(vec)\n",
    "                \n",
    "        return cls(word_to_index, word_vectors)\n",
    "    \n",
    "    def get_embedding(self, word):\n",
    "        \"\"\"\n",
    "        매개변수:\n",
    "            word (str)\n",
    "        반환값\n",
    "            임베딩 (numpy.ndarray)\n",
    "        \"\"\"\n",
    "        return self.word_vectors[self.word_to_index[word]]\n",
    "\n",
    "    def get_closest_to_vector(self, vector, n=1):\n",
    "        \"\"\"벡터가 주어지면 n 개의 최근접 이웃을 반환합니다\n",
    "        매개변수:\n",
    "            vector (np.ndarray): Annoy 인덱스에 있는 벡터의 크기와 같아야 합니다\n",
    "            n (int): 반환될 이웃의 개수\n",
    "        반환값:\n",
    "            [str, str, ...]: 주어진 벡터와 가장 가까운 단어\n",
    "                단어는 거리순으로 정렬되어 있지 않습니다.\n",
    "        \"\"\"\n",
    "        nn_indices = self.index.get_nns_by_vector(vector, n)\n",
    "        return [self.index_to_word[neighbor] for neighbor in nn_indices]\n",
    "    \n",
    "    def compute_and_print_analogy(self, word1, word2, word3):\n",
    "        \"\"\"단어 임베딩을 사용한 유추 결과를 출력합니다\n",
    "\n",
    "        word1이 word2일 때 word3은 __입니다.\n",
    "        이 메서드는 word1 : word2 :: word3 : word4를 출력합니다\n",
    "        \n",
    "        매개변수:\n",
    "            word1 (str)\n",
    "            word2 (str)\n",
    "            word3 (str)\n",
    "        \"\"\"\n",
    "        vec1 = self.get_embedding(word1)\n",
    "        vec2 = self.get_embedding(word2)\n",
    "        vec3 = self.get_embedding(word3)\n",
    "\n",
    "        # 네 번째 단어 임베딩을 계산합니다\n",
    "        spatial_relationship = vec2 - vec1\n",
    "        vec4 = vec3 + spatial_relationship\n",
    "\n",
    "        closest_words = self.get_closest_to_vector(vec4, n=4)\n",
    "        existing_words = set([word1, word2, word3])\n",
    "        closest_words = [word for word in closest_words \n",
    "                             if word not in existing_words] \n",
    "\n",
    "        if len(closest_words) == 0:\n",
    "            print(\"계산된 벡터와 가장 가까운 이웃을 찾을 수 없습니다!\")\n",
    "            return\n",
    "        \n",
    "        for word4 in closest_words:\n",
    "            print(\"{} : {} :: {} : {}\".format(word1, word2, word3, word4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wzI7893JnbQC",
    "outputId": "bac8fd67-678e-43c9-bd9d-52bc74b76e88"
   },
   "outputs": [],
   "source": [
    "# GloVe 데이터를 다운로드합니다.\n",
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip glove.6B.zip\n",
    "!mkdir -p data/glove\n",
    "!mv glove.6B.100d.txt data/glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jAjjduj4nbQC",
    "outputId": "5403f750-3482-4249-9a3d-3330652f4135",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embeddings = PreTrainedEmbeddings.from_embeddings_file('data/glove/glove.6B.100d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-vkPwR1WnbQD",
    "outputId": "3e7d5a07-d720-4154-b20a-988441ec3410"
   },
   "outputs": [],
   "source": [
    "embeddings.compute_and_print_analogy('man', 'he', 'woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qdW0ALNwnbQD",
    "outputId": "3dea466c-d8eb-474f-b54e-9c76c12ceb67"
   },
   "outputs": [],
   "source": [
    "embeddings.compute_and_print_analogy('fly', 'plane', 'sail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7BPECjEWnbQD",
    "outputId": "314544b9-04d1-45e2-8fdf-0d41072d57dd"
   },
   "outputs": [],
   "source": [
    "embeddings.compute_and_print_analogy('cat', 'kitten', 'dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GTePW8TUnbQD",
    "outputId": "ef4f7a42-5495-4917-bf19-5fa68251fb96"
   },
   "outputs": [],
   "source": [
    "embeddings.compute_and_print_analogy('blue', 'color', 'dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qS2ZTE2gnbQE",
    "outputId": "d618b2eb-7bbd-4d2d-e56a-cb3b6ef84619"
   },
   "outputs": [],
   "source": [
    "embeddings.compute_and_print_analogy('leg', 'legs', 'hand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BjoDo_0tnbQE",
    "outputId": "6d5c6696-e96c-420b-8c8f-d4c5a29bed1c"
   },
   "outputs": [],
   "source": [
    "embeddings.compute_and_print_analogy('toe', 'foot', 'finger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sf2Cg82nnbQE",
    "outputId": "19dcdd31-242b-411f-be32-69a38b83ff88"
   },
   "outputs": [],
   "source": [
    "embeddings.compute_and_print_analogy('talk', 'communicate', 'read')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cYyVG3c8nbQE",
    "outputId": "92e8f7a8-06b5-4885-ad5d-ef7c2354d5b1"
   },
   "outputs": [],
   "source": [
    "embeddings.compute_and_print_analogy('blue', 'democrat', 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "28L6Y98PnbQE",
    "outputId": "fefe074c-6c62-44cb-ea3e-8923432b0277"
   },
   "outputs": [],
   "source": [
    "embeddings.compute_and_print_analogy('man', 'king', 'woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gJVD1nyDnbQF",
    "outputId": "a7bd69f7-4435-4d8e-d139-cd4299932220"
   },
   "outputs": [],
   "source": [
    "embeddings.compute_and_print_analogy('man', 'doctor', 'woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PUnCxUdcnbQF",
    "outputId": "dac53761-2be2-446f-996e-040f3026665d"
   },
   "outputs": [],
   "source": [
    "embeddings.compute_and_print_analogy('fast', 'fastest', 'small')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "5_1_Pretrained_Embeddings.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
