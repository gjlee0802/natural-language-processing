{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9fadiGlp5EO"
   },
   "source": [
    "# Attention is All You Need (NIPS 2017) 실습\n",
    "\n",
    "트랜스포머 정리 노트: https://github.com/gjlee0802/natural-language-processing/blob/main/NLP/transformer/attention_is_all_you_need_summary.md\n",
    "\n",
    "\n",
    "독일어를 영어로 번역하는 Machine Translation 구현, 데이터셋은 Multi30k 이용."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fxcMGl0fs0Eq"
   },
   "source": [
    "# 데이터 전처리(Preprocessing)\n",
    "\n",
    "spacy 라이브러리: 문장의 토큰화, 태깅 등의 전처리 기능을 위한 라이브러리\n",
    "\n",
    "영어와 독일어 전처리 모듈 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1k_hv31Ip4eu"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!python -m spacy download en\n",
    "!python -m spacy download de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9JExj6Ytn1RP"
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NtS7D7ZYpXvs"
   },
   "outputs": [],
   "source": [
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "spacy_de = spacy.load('de_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eTRo5yXjphab",
    "outputId": "4585f69d-69ba-440e-a5e1-11e5628097dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인덱스 0 : I\n",
      "인덱스 1 : am\n",
      "인덱스 2 : a\n",
      "인덱스 3 : graduate\n",
      "인덱스 4 : student\n",
      "인덱스 5 : .\n"
     ]
    }
   ],
   "source": [
    "tokenized = spacy_en.tokenizer(\"I am a graduate student.\")\n",
    "\n",
    "for i, token in enumerate(tokenized):\n",
    "  print(f\"인덱스 {i} : {token.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WrbKUTTIsxLV"
   },
   "source": [
    "## 토큰화 함수 정의 (spacy의 토크나이저 이용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0TN6TdgBscdG"
   },
   "outputs": [],
   "source": [
    "# 독일어 문장을 토큰화 하는 함수\n",
    "def tokenize_de(text):\n",
    "  return [token.text for token in spacy_de.tokenizer(text)]\n",
    "\n",
    "# 영어 문장을 토큰화 하는 함수\n",
    "def tokenize_en(text):\n",
    "  return [token.text for token in spacy_en.tokenizer(text)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wZMobabcvtvo",
    "outputId": "03699952-d7bf-4a2d-d2d1-c723b28ee882"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0+cu121\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bzZUvITRujcF",
    "outputId": "76312ec5-49b1-49e6-a0a3-6f75377b3dd7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install torchtext==0.17.0\\n!pip install portalocker>=2.0.0\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "!pip install torchtext==0.17.0\n",
    "!pip install portalocker>=2.0.0\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9pg6vp1wGa_v"
   },
   "source": [
    "## 어휘집 Vocab 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "cPx1ryFGMbQ0"
   },
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.datasets import multi30k, Multi30k\n",
    "from typing import Iterable, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update URLs to point to data stored by user\n",
    "#multi30k.URL[\"train\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/training.tar.gz\"\n",
    "#multi30k.URL[\"valid\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/validation.tar.gz\"\n",
    "multi30k.URL[\"test\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/mmt16_task1_test.tar.gz\"\n",
    "\n",
    "# Update hash since there is a discrepancy between user hosted test split and that of the test split in the original dataset \n",
    "multi30k.MD5[\"test\"] = \"6d1ca1dba99e2c5dd54cae1226ff11c2551e6ce63527ebb072a1f70f72a5cd36\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "WXaA4kGG_Sfe"
   },
   "outputs": [],
   "source": [
    "SRC_LANG = 'de'\n",
    "TGT_LANG = 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0xwMHiw9DEsR"
   },
   "outputs": [],
   "source": [
    "tokenizer = {}\n",
    "tokenizer['en'] = tokenize_en\n",
    "tokenizer['de'] = tokenize_de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "uxzGsx_g_Png"
   },
   "outputs": [],
   "source": [
    "# 토큰 목록을 생성하기 위한 헬퍼(helper) 함수\n",
    "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
    "    language_index = {SRC_LANG: 0, TGT_LANG: 1}\n",
    "\n",
    "    for i, datasample_tuple in enumerate(train_iter):\n",
    "      yield tokenizer[language](datasample_tuple[language_index[language]])\n",
    "    '''\n",
    "    for data_sample in data_iter:\n",
    "        yield token_transform[language](data_sample[language_index[language]])\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ivS0lAYgMWZf"
   },
   "outputs": [],
   "source": [
    "# 특수 기호(symbol)와 인덱스를 정의합니다\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "# 토큰들이 어휘집(vocab)에 인덱스 순서대로 잘 삽입되어 있는지 확인합니다\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "\n",
    "vocab_transform = {} # 영어, 독일어에 대해서 torchtext의 Vocab 옵젝이 저장됨.\n",
    "\n",
    "for ln in [SRC_LANG, TGT_LANG]:\n",
    "  train_iter = Multi30k(split='train', language_pair=(SRC_LANG, TGT_LANG))\n",
    "  val_iter = Multi30k(split='valid', language_pair=(SRC_LANG, TGT_LANG))\n",
    "  test_iter = Multi30k(split='test', language_pair=(SRC_LANG, TGT_LANG))\n",
    "\n",
    "  vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n",
    "                                                  min_freq=2, # 최소 2번 이상 등장한 단어만을 선택\n",
    "                                                  specials=special_symbols,\n",
    "                                                  special_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f9K165Ma_MPg",
    "outputId": "6229d701-4c70-4164-d1d2-d106ff163c75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \n",
      "x:Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche. \n",
      "y:Two young, White males are outside near many bushes.\n",
      "[1] \n",
      "x:Mehrere Männer mit Schutzhelmen bedienen ein Antriebsradsystem. \n",
      "y:Several men in hard hats are operating a giant pulley system.\n",
      "[2] \n",
      "x:Ein kleines Mädchen klettert in ein Spielhaus aus Holz. \n",
      "y:A little girl climbing into a wooden playhouse.\n",
      "[3] \n",
      "x:Ein Mann in einem blauen Hemd steht auf einer Leiter und putzt ein Fenster. \n",
      "y:A man in a blue shirt is standing on a ladder cleaning a window.\n",
      "[4] \n",
      "x:Zwei Männer stehen am Herd und bereiten Essen zu. \n",
      "y:Two men are at the stove preparing food.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\이경주\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\combining.py:337: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
      "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
     ]
    }
   ],
   "source": [
    "for idx, (x, y) in enumerate(train_iter):\n",
    "  if idx == 5:\n",
    "    break\n",
    "\n",
    "  print(f'[{idx}] \\nx:{x} \\ny:{y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "aTp2GdU4BIN5"
   },
   "outputs": [],
   "source": [
    "# ``UNK_IDX`` 를 기본 인덱스로 설정합니다. 이 인덱스는 토큰을 찾지 못하는 경우에 반환됩니다.\n",
    "# 만약 기본 인덱스를 설정하지 않으면 어휘집(Vocabulary)에서 토큰을 찾지 못하는 경우\n",
    "# ``RuntimeError`` 가 발생합니다.\n",
    "for ln in [SRC_LANG, TGT_LANG]:\n",
    "    vocab_transform[ln].set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xNAwtyBLEqc6",
    "outputId": "8637ed2c-afb6-4f97-d21e-d935516ab241"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소스 언어의 Vocab(어휘집)\n",
      "[Vocab] index: 0 | token: <unk>\n",
      "[Vocab] index: 1 | token: <pad>\n",
      "[Vocab] index: 2 | token: <bos>\n",
      "[Vocab] index: 3 | token: <eos>\n",
      "[Vocab] index: 4 | token: .\n",
      "[Vocab] index: 5 | token: Ein\n",
      "[Vocab] index: 6 | token: einem\n",
      "[Vocab] index: 7 | token: in\n",
      "[Vocab] index: 8 | token: ,\n",
      "[Vocab] index: 9 | token: und\n",
      "[Vocab] index: 10 | token: mit\n",
      "[Vocab] index: 11 | token: auf\n",
      "[Vocab] index: 12 | token: Mann\n",
      "[Vocab] index: 13 | token: einer\n",
      "[Vocab] index: 14 | token: Eine\n",
      "[Vocab] index: 15 | token: ein\n",
      "[Vocab] index: 16 | token: der\n",
      "[Vocab] index: 17 | token: Frau\n",
      "[Vocab] index: 18 | token: eine\n",
      "[Vocab] index: 19 | token: die\n"
     ]
    }
   ],
   "source": [
    "print('소스 언어의 Vocab(어휘집)')\n",
    "for idx in range(20):\n",
    "  print(f'[Vocab] index: {idx} | token: {vocab_transform[SRC_LANG].lookup_token(idx)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h16VuyrcF7ae",
    "outputId": "684800c7-1e74-450c-a375-304963379f92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타겟 언어의 Vocab(어휘집)\n",
      "[Vocab] index: 0 | token: <unk>\n",
      "[Vocab] index: 1 | token: <pad>\n",
      "[Vocab] index: 2 | token: <bos>\n",
      "[Vocab] index: 3 | token: <eos>\n",
      "[Vocab] index: 4 | token: a\n",
      "[Vocab] index: 5 | token: .\n",
      "[Vocab] index: 6 | token: A\n",
      "[Vocab] index: 7 | token: in\n",
      "[Vocab] index: 8 | token: the\n",
      "[Vocab] index: 9 | token: on\n",
      "[Vocab] index: 10 | token: is\n",
      "[Vocab] index: 11 | token: and\n",
      "[Vocab] index: 12 | token: man\n",
      "[Vocab] index: 13 | token: of\n",
      "[Vocab] index: 14 | token: with\n",
      "[Vocab] index: 15 | token: ,\n",
      "[Vocab] index: 16 | token: woman\n",
      "[Vocab] index: 17 | token: are\n",
      "[Vocab] index: 18 | token: to\n",
      "[Vocab] index: 19 | token: Two\n"
     ]
    }
   ],
   "source": [
    "print('타겟 언어의 Vocab(어휘집)')\n",
    "for idx in range(20):\n",
    "  print(f'[Vocab] index: {idx} | token: {vocab_transform[TGT_LANG].lookup_token(idx)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y9Mzk1E-FAUs",
    "outputId": "b0b9851b-1976-4119-b77b-7ebf40fd4a1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]\n"
     ]
    }
   ],
   "source": [
    "print(vocab_transform[TGT_LANG].lookup_indices(['A']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MO_zPx6xLnsh",
    "outputId": "6fcebbf6-969e-4edb-b9ed-b9b5053e5d82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8014\n",
      "6191\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab_transform[SRC_LANG]))\n",
    "print(len(vocab_transform[TGT_LANG]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UZ7gFWM7dtRe"
   },
   "source": [
    "배치 크기, 문장 내 최대 단어 개수 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "q6Bu7xTaJPrO"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128  # 배치 크기\n",
    "MAX_LENGTH = 100  # 한 문장 내에 들어갈 수 있는 최대 단어 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9PPOjrn-SBMJ"
   },
   "source": [
    "배치 생성 전처리 코드 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "v24L26f-C4zi"
   },
   "outputs": [],
   "source": [
    "from torch.nn.functional import pad\n",
    "\n",
    "src_pipeline = lambda x: vocab_transform[SRC_LANG].lookup_indices(tokenizer[SRC_LANG](x))\n",
    "tgt_pipeline = lambda x: vocab_transform[TGT_LANG].lookup_indices(tokenizer[TGT_LANG](x))\n",
    "\n",
    "def collate_batch(batch):\n",
    "\n",
    "  bs_id = torch.tensor([BOS_IDX])\n",
    "  eos_id = torch.tensor([EOS_IDX])\n",
    "\n",
    "  src_list, tgt_list = [], []\n",
    "  for (_srctext, _tgttext) in batch:\n",
    "    processed_src = torch.cat(\n",
    "        [\n",
    "            bs_id,\n",
    "            torch.tensor(\n",
    "                src_pipeline(_srctext),\n",
    "                dtype=torch.int64\n",
    "            ),\n",
    "            eos_id,\n",
    "        ],\n",
    "        0,\n",
    "    )\n",
    "    processed_tgt = torch.cat(\n",
    "        [\n",
    "            bs_id,\n",
    "            torch.tensor(\n",
    "                tgt_pipeline(_tgttext),\n",
    "                dtype=torch.int64\n",
    "            ),\n",
    "            eos_id\n",
    "        ],\n",
    "        0,\n",
    "    )\n",
    "    src_list.append(\n",
    "            # warning - overwrites values for negative values of padding - len\n",
    "            pad(\n",
    "                processed_src,\n",
    "                (\n",
    "                    0,\n",
    "                    MAX_LENGTH - len(processed_src),\n",
    "                ),\n",
    "                value=PAD_IDX,\n",
    "            )\n",
    "    )\n",
    "    tgt_list.append(\n",
    "            # warning - overwrites values for negative values of padding - len\n",
    "            pad(\n",
    "                processed_tgt,\n",
    "                (\n",
    "                    0,\n",
    "                    MAX_LENGTH - len(processed_tgt),\n",
    "                ),\n",
    "                value=PAD_IDX,\n",
    "            )\n",
    "    )\n",
    "    #src_list.append(processed_src)\n",
    "    #tgt_list.append(processed_tgt)\n",
    "  '''\n",
    "  src_list = torch.cat(src_list)\n",
    "  tgt_list = torch.cat(tgt_list)\n",
    "\n",
    "  src_list = pad(\n",
    "    src_list,\n",
    "    (\n",
    "        0,\n",
    "        BATCH_SIZE - len(src_list),\n",
    "    ),\n",
    "    value=PAD_IDX,\n",
    "  )\n",
    "  tgt_list = pad(\n",
    "    tgt_list,\n",
    "    (\n",
    "        0,\n",
    "        BATCH_SIZE - len(tgt_list),\n",
    "    ),\n",
    "    value=PAD_IDX,\n",
    "  )\n",
    "  '''\n",
    "\n",
    "  src = torch.stack(src_list)\n",
    "  tgt = torch.stack(tgt_list)\n",
    "  return src, tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "j9QkUCNh5ouZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\이경주\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\combining.py:337: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
      "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def train_valid_split(train_iterator, split_ratio=0.8, seed=42):\n",
    "    train_count = int(split_ratio * len(train_iterator))\n",
    "    valid_count = len(train_iterator) - train_count\n",
    "    generator = torch.Generator().manual_seed(seed)\n",
    "    train_set, valid_set = random_split(\n",
    "        train_iterator, lengths=[train_count, valid_count], generator=generator)\n",
    "    return train_set, valid_set\n",
    "\n",
    "# iterable type에서 map style로 변환해야 length check 가능\n",
    "train_iter = to_map_style_dataset(train_iter)\n",
    "valid_iter = to_map_style_dataset(val_iter)\n",
    "#test_iter = to_map_style_dataset(test_iter)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_iter, batch_size=BATCH_SIZE, shuffle=True, collate_fn = collate_batch)\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_iter, batch_size=BATCH_SIZE, shuffle=True, collate_fn = collate_batch)\n",
    "#test_dataloader = DataLoader(\n",
    "#    test_iter, batch_size=BATCH_SIZE, shuffle=True, collate_fn = collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PJwkeOUoiY-y",
    "outputId": "7467fb8d-e831-428f-83bf-c3982bbc9ca4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29001\n"
     ]
    }
   ],
   "source": [
    "print(len(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K_WY977piby3",
    "outputId": "1d50b163-5820-46a8-d272-a707b52de735"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1015\n"
     ]
    }
   ],
   "source": [
    "print(len(valid_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iPiTz04K_asj"
   },
   "source": [
    "train_dataloader를 돌며 Source에 대한 배치 데이터 출력해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r86krVyZGiGa"
   },
   "source": [
    "# Transformer 활용 Seq2Seq 모델\n",
    "\n",
    "torch에서 제공하는 Transformer을 사용하지 않고, transformer을 구현하여 활용해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "Apd2N7M2GrSD"
   },
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "import math\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRVJ_C0XPNbG"
   },
   "source": [
    "## Multi Head Attention\n",
    "\n",
    "어텐션은 세가지 요소를 입력으로 받는다.\n",
    "- 쿼리(queries)\n",
    "- 키(keys)\n",
    "- 값(values)\n",
    "\n",
    "하이퍼 파라미터\n",
    "- hidden_dim: 하나의 단어에 대한 임베딩 차원\n",
    "- n_heads: 헤드의 개수(scaled dot-product attention 개수)\n",
    "- dropout_ratio: 드롭아웃 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "7A6B9TajPSvm"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MultiHeadAttentionLayer(nn.Module):\n",
    "  def __init__(self, hidden_dim, n_heads, dropout_ratio, device):\n",
    "    super().__init__()\n",
    "\n",
    "    # assert는 뒤의 조건이 True가 아니면 AssertError를 발생한다.\n",
    "    assert hidden_dim % n_heads == 0\n",
    "\n",
    "    self.hidden_dim = hidden_dim # 임베딩 차원\n",
    "    self.n_heads = n_heads # 헤드의 개수(서로 다른 어텐션 컨셉의 수)\n",
    "    self.head_dim = hidden_dim // n_heads # 각 헤드에서의 임베딩 차원 = 전체 임베딩 차원을 헤드의 수로 나눈 값\n",
    "\n",
    "    self.fc_q = nn.Linear(hidden_dim, hidden_dim) # Query 값에 적용될 FC 레이어\n",
    "    self.fc_k = nn.Linear(hidden_dim, hidden_dim) # Key 값에 적용될 FC 레이어\n",
    "    self.fc_v = nn.Linear(hidden_dim, hidden_dim) # Value 값에 적용될 FC 레이어\n",
    "\n",
    "    self.fc_o = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "    self.dropout = nn.Dropout(dropout_ratio)\n",
    "\n",
    "    self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
    "\n",
    "  def forward(self, query, key, value, mask = None):\n",
    "    batch_size = query.shape[0]\n",
    "\n",
    "    # query: [batch_size, query_len, hidden_dim]\n",
    "    # key: [batch_size, key_len, hidden_dim]\n",
    "    # value: [batch_size, value_len, hidden_dim]\n",
    "\n",
    "    # 각각 FC 레이어에 입력\n",
    "    Q = self.fc_q(query)\n",
    "    K = self.fc_k(key)\n",
    "    V = self.fc_v(value)\n",
    "\n",
    "    # Q: [batch_size, query_len, hidden_dim]\n",
    "    # K: [batch_size, key_len, hidden_dim]\n",
    "    # V: [batch_size, value_len, hidden_dim]\n",
    "\n",
    "    # hidden_dim -> n_heads X head_dim 형태로 변형\n",
    "    # after permute\n",
    "    # Q: [batch_size, query_len, n_heads, head_dim] -> [batch_size, n_heads, query_len, head_dim]\n",
    "    # K: [batch_size, key_len, n_heads, head_dim] -> [batch_size, n_heads, key_len, head_dim]\n",
    "    # V: [batch_size, value_len, n_heads, head_dim] -> [batch_size, n_heads, value_len, head_dim]\n",
    "    Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0,2,1,3)\n",
    "    K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0,2,1,3)\n",
    "    V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0,2,1,3)\n",
    "\n",
    "    # Q: [batch_size, n_heads, query_len, head_dim]\n",
    "    # K: [batch_size, n_heads, key_len, head_dim]\n",
    "    # V: [batch_size, n_heads, value_len, head_dim]\n",
    "\n",
    "    # Attention Energy 계산 (유사도 계산)\n",
    "    energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
    "\n",
    "    # 마스크를 사용할 경우\n",
    "    if mask is not None:\n",
    "      energy = energy.masked_fill(mask==0, -1e10) # 마스크 값이 0인 부분에 상당이 작은 값으로 채워준다.\n",
    "\n",
    "    # 어텐션 스코어 계산: 각 단어에 대한 확률 값\n",
    "    attention = torch.softmax(energy, dim=-1) # 소프트맥스로 정규화\n",
    "\n",
    "    # attention: [batch_size, n_heads, query_len, key_len]\n",
    "\n",
    "    # Scaled Dot-Product Attention을 계산\n",
    "    x = torch.matmul(self.dropout(attention), V)\n",
    "\n",
    "    # x: [batch_size, n_heads, query_len, head_dim]\n",
    "\n",
    "    x = x.permute(0,2,1,3).contiguous()\n",
    "\n",
    "    # x: [batch_size, query_len, n_heads, head_dim]\n",
    "\n",
    "    # n_heads X head_dim -> hidden_dim 변형\n",
    "    x = x.view(batch_size, -1, self.hidden_dim)\n",
    "\n",
    "    # x: [batch_size, query_len, hidden_dim]\n",
    "\n",
    "    x = self.fc_o(x)\n",
    "\n",
    "    return x, attention\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WrHqPNDD1ib3"
   },
   "source": [
    "## Position-wise Feedforward\n",
    "입력과 출력의 차원이 동일함.  \n",
    "- encoder와 decoder의 각각의 layer는 fully connected feed-forward network를 포함하고 있음.  \n",
    "- position 마다, 즉 개별 단어마다 적용되기 때문에 position-wise.  \n",
    "- network는 두 번의 linear transformation과 activation function ReLU로 이루어져 있음(fc1 -> relu -> fc2).  \n",
    "\n",
    "하이퍼 파라미터\n",
    "- hidden_dim: 하나의 단어에 대한 임베딩 차원\n",
    "- pf_dim: Feedforward 레이어에서의 내부 임베딩 차원\n",
    "- dropout_ratio: 드롭아웃 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "RM2bCgO-1IDQ"
   },
   "outputs": [],
   "source": [
    "class PositionwiseFeedforwardLayer(nn.Module):\n",
    "  def __init__(self, hidden_dim, pf_dim, dropout_ratio):\n",
    "      super().__init__()\n",
    "\n",
    "      self.fc_1 = nn.Linear(hidden_dim, pf_dim)\n",
    "      self.fc_2 = nn.Linear(pf_dim, hidden_dim)\n",
    "\n",
    "      self.dropout = nn.Dropout(dropout_ratio)\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "    # x: [batch_size, seq_len, hidden_dim]\n",
    "\n",
    "    x = self.dropout(torch.relu(self.fc_1(x)))\n",
    "\n",
    "    # x: [batch_size, seq_len, pf_dim]\n",
    "\n",
    "    x = self.fc_2(x)\n",
    "\n",
    "    # x: [batch_size, seq_len, hidden_dim]\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpCBRc9A4DO5"
   },
   "source": [
    "## Encoder 레이어\n",
    "인코더는 아래의 인코더 레이어를 여러번 중첩하여 사용함.  \n",
    "인코더 레이어의 입력과 출력의 차원이 같음.  \n",
    "\n",
    "\n",
    "하이퍼 파라미터\n",
    "- hidden_dim: 하나의 단어에 대한 임베딩 차원\n",
    "- n_heads: 헤드의 개수\n",
    "- pf_dim: Feedforward 레이어(PositionwiseFeedforward)에서의 내부 임베딩 차원\n",
    "- dropout_ratio: 드롭아웃 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "0_NDqu9B4IEJ"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "  def __init__(self, hidden_dim, n_heads, pf_dim, dropout_ratio, device):\n",
    "    super().__init__()\n",
    "\n",
    "    self.self_attn_layer_norm = nn.LayerNorm(hidden_dim)\n",
    "    self.ff_layer_norm = nn.LayerNorm(hidden_dim)\n",
    "    self.self_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio, device)\n",
    "    self.positionwise_feedforward = PositionwiseFeedforwardLayer(hidden_dim, pf_dim, dropout_ratio)\n",
    "    self.dropout = nn.Dropout(dropout_ratio)\n",
    "\n",
    "  def forward(self, src, src_mask):\n",
    "    # src: [batch_size, src_len, hidden_dim]\n",
    "    # src_mask: [batch_size, src_len]\n",
    "\n",
    "    # Self Attention\n",
    "    # 필요한 경우 마스크 행렬을 이용하여 어텐션할 단어 조절 가능\n",
    "    _src, _ = self.self_attention.forward(src, src, src, src_mask) # params : query, key, value, mask\n",
    "\n",
    "    # dropout, residual connection and layer norm\n",
    "    # residual connection : feedforward를 거치기 전 입력 x를 feedforward를 거친 결과값에 더해주어 입력하는 것\n",
    "    src = self.self_attn_layer_norm.forward(src + self.dropout(_src))\n",
    "\n",
    "    # src: [batch_size, src_len, hidden_dim]\n",
    "\n",
    "    # Position-wisd feedforward\n",
    "    _src = self.positionwise_feedforward.forward(src)\n",
    "\n",
    "    # dropout, residual and layer norm\n",
    "    src = self.ff_layer_norm(src + self.dropout(_src))\n",
    "\n",
    "    # src: [batch_size, src_len, hidden_dim]\n",
    "\n",
    "    return src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxkzEBsYxNaW"
   },
   "source": [
    "## Encoder\n",
    "\n",
    "하이퍼 파라미터\n",
    "- input_dim: 하나의 단어에 대한 원-핫 인코딩 차원\n",
    "- hidden_dim: 하나의 단어에 대한 임베딩 차원\n",
    "- n_layers: 내부적으로 사용할 인코더 레이어의 개수\n",
    "- n_heads: 헤드의 개수\n",
    "- pf_dim: Feedforward 레이어에서의 내부 임베딩 차원\n",
    "- dropout_ratio: 드롭아웃 비율\n",
    "- max_length: 문장 내 최대 단어 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "75t0GSZ793lU"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "  def __init__(self, input_dim, hidden_dim, n_layers, n_heads, pf_dim, dropout_ratio, device, max_length=100):\n",
    "    super().__init__()\n",
    "\n",
    "    self.device = device\n",
    "\n",
    "    self.tok_embedding = nn.Embedding(input_dim, hidden_dim)\n",
    "    self.pos_embedding = nn.Embedding(max_length, hidden_dim)\n",
    "\n",
    "    self.encoder_layers = nn.ModuleList([EncoderLayer(hidden_dim, n_heads, pf_dim, dropout_ratio, device) for _ in range(n_layers)])\n",
    "\n",
    "    self.dropout = nn.Dropout(dropout_ratio)\n",
    "\n",
    "    self.scale = torch.sqrt(torch.FloatTensor([hidden_dim])).to(device)\n",
    "\n",
    "  def forward(self, src, src_mask):\n",
    "    # src: [batch_size, src_len]\n",
    "    # src_mask: [batch_size, src_len]\n",
    "\n",
    "    src = src.to(self.device)\n",
    "    src_mask = src_mask.to(self.device)\n",
    "\n",
    "    batch_size = src.shape[0]\n",
    "    src_len = src.shape[1]\n",
    "\n",
    "    # unsqueeze는 특정 위치에 1인 차원을 추가함.\n",
    "    # unsqueeze(0)는 첫번째 차원에 1인 차원을 추가함. [1 X src_len]\n",
    "    # repeat 함수는 텐서를 반복 확장시켜줌.\n",
    "    # repeat(batch_size, 1)은 [1 X src_len] 형태를 [batch_size, src_len] 차원으로 만들어줌.\n",
    "    pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
    "\n",
    "    # pos: [batch_size, src_len]\n",
    "\n",
    "    # 소스 문장의 임베딩과 위치 임베딩을 더함. (Positional Encoding)\n",
    "    src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos)).to(device)\n",
    "\n",
    "    # src: [batch_size, src_len, hidden_dim]\n",
    "\n",
    "    # 모든 인코더 레이어를 차례대로 거치며 순전파 수행\n",
    "    for layer in self.encoder_layers:\n",
    "      src = layer(src, src_mask)\n",
    "\n",
    "    # src: [batch_size, src_len, hidden_dim]\n",
    "\n",
    "    # 마지막 레이어의 출력 반환\n",
    "    return src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qic-2XOFMPJV"
   },
   "source": [
    "## Decoder 레이어\n",
    "\n",
    "하이퍼 파라미터\n",
    "- hidden_dim: 하나의 단어에 대한 임베딩 차원\n",
    "- n_heads: 헤드의 개수\n",
    "- pf_dim: Feedforward 레이어(PositionwiseFeedforward)에서의 내부 임베딩 차원\n",
    "- dropout_ratio: 드롭아웃 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "YX1nh8YWMOFl"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "  def __init__(self, hidden_dim, n_heads, pf_dim, dropout_ratio, device):\n",
    "    super().__init__()\n",
    "\n",
    "    self.self_attn_layer_norm = nn.LayerNorm(hidden_dim)\n",
    "    self.enc_attn_layer_norm = nn.LayerNorm(hidden_dim)\n",
    "    self.ff_layer_norm = nn.LayerNorm(hidden_dim)\n",
    "    self.self_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio, device)\n",
    "    self.encoder_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio, device)\n",
    "    self.positionwise_feedforward = PositionwiseFeedforwardLayer(hidden_dim, pf_dim, dropout_ratio)\n",
    "    self.dropout = nn.Dropout(dropout_ratio)\n",
    "\n",
    "  # 인코더의 출력 값(enc_src)를 어텐션하는 구조\n",
    "  def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "    # trg: [batch_size, trg_len, hidden_dim]\n",
    "    # enc_src: [batch_size, src_len, hidden_dim]\n",
    "    # trg_mask: [batch_size, trg_len, hidden_dim]\n",
    "    # src_mask: [batch_size, src_len, hidden_dim]\n",
    "\n",
    "    _trg, _ = self.self_attention.forward(trg, trg, trg, trg_mask) # params : query, key, value, mask\n",
    "\n",
    "    trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
    "\n",
    "    # trg: [batch_size, trg_len, hidden_dim]\n",
    "\n",
    "    # Encoder Attention\n",
    "    # 디코더의 쿼리(Query)를 이용하여 인코더를 어텐션\n",
    "    _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
    "\n",
    "    # dropout, residual connection and layer norm\n",
    "    trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
    "\n",
    "    # trg: [batch_size, trg_len, hidden_dim]\n",
    "    # attention: [batch_size, n_heads, trg_len, src_len]\n",
    "\n",
    "    # positionwise feedforward\n",
    "    _trg = self.positionwise_feedforward(trg)\n",
    "\n",
    "    # dropout, residual and layer norm\n",
    "    # residual connection : feedforward를 거치기 전 입력 x를 feedforward를 거친 결과값에 더해주어 입력하는 것\n",
    "    trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
    "\n",
    "    # trg: [batch_size, trg_len, hidden_dim]\n",
    "    # attention: [batch_size, n_heads, trg_len, src_len]\n",
    "\n",
    "    return trg, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "seOLTrmBR7eA"
   },
   "source": [
    "## Decoder\n",
    "원본 논문과 다르게 위치 임베딩(positional embedding)을 학습하는 형태(BERT와 같은 모던 트랜스포머 모델에서 사용되는 방식)로 구현함.  \n",
    "  \n",
    "소스 문장의 'pad' 토큰에 대해 마스크(MASK) 값을 0으로 설정함.  \n",
    "  \n",
    "Masked Decoder Self-Attention: 타겟 문장에서 각 단어는 다음 단어가 무엇인지 알 수 없도록(이전 단어만 보도록) 만들기 위해 마스크(MASK)를 사용함.\n",
    "~~~\n",
    "Masked Decoder Self-Attention : 디코더 파트에서 셀프 어텐션을 사용할 때는 각각의 출력 단어가 다른 모든 출력 단어를 참고하도록 하지는 않고, 앞쪽의 단어들만 참고하도록 함.\n",
    "~~~\n",
    "\n",
    "하이퍼 파라미터\n",
    "- output_dim: 하나의 단어에 대한 원-핫 인코딩 차원\n",
    "- hidden_dim: 하나의 단어에 대한 임베딩 차원\n",
    "- n_layers: 내부적으로 사용할 인코더 레이어의 개수\n",
    "- n_heads: 헤드의 개수\n",
    "- pf_dim: Feedforward 레이어에서의 내부 임베딩 차원\n",
    "- dropout_ratio: 드롭아웃 비율\n",
    "- max_length: 문장 내 최대 단어 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "fQ48w4KqSoei"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "  def __init__(self, output_dim, hidden_dim, n_layers, n_heads, pf_dim, dropout_ratio, device, max_length=100):\n",
    "    super().__init__()\n",
    "\n",
    "    self.device = device\n",
    "\n",
    "    self.tok_embedding = nn.Embedding(output_dim, hidden_dim)\n",
    "    self.pos_embedding = nn.Embedding(max_length, hidden_dim)\n",
    "\n",
    "    self.decoder_layers = nn.ModuleList([DecoderLayer(hidden_dim, n_heads, pf_dim, dropout_ratio, device) for _ in range(n_layers)])\n",
    "\n",
    "    self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    self.dropout = nn.Dropout(dropout_ratio)\n",
    "\n",
    "    self.scale = torch.sqrt(torch.FloatTensor([hidden_dim])).to(device)\n",
    "\n",
    "  def forward(self, trg, enc_src, trg_mask, src_mask):\n",
    "    # trg: [batch_size, trg_len]\n",
    "    # enc_src: [batch_size, src_len, hidden_dim]\n",
    "    # trg_mask: [batch_size, trg_len]\n",
    "    # src_mask: [batch_size, src_len]\n",
    "\n",
    "    batch_size = trg.shape[0]\n",
    "    trg_len = trg.shape[1]\n",
    "\n",
    "    # unsqueeze는 특정 위치에 1인 차원을 추가함.\n",
    "    # unsqueeze(0)는 첫번째 차원에 1인 차원을 추가함. [1 X trg_len]\n",
    "    # repeat 함수는 텐서를 반복 확장시켜줌.\n",
    "    # repeat(batch_size, 1)은 [1 X trg_len] 형태를 [batch_size, trg_len] 차원으로 만들어줌.\n",
    "    pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
    "\n",
    "    # pos : [batch_size, trg_len]\n",
    "\n",
    "    # 타겟 문장의 임베딩과 위치 임베딩을 더함. (Positional Encoding)\n",
    "    trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
    "\n",
    "    # trg: [batch_size, trg_len, hidden_dim]\n",
    "\n",
    "    # 모든 디코더 레이어를 거치며 순전파 수행\n",
    "    for layer in self.decoder_layers:\n",
    "      trg, attention = layer(trg, enc_src, trg_mask, src_mask) # 소스 마스크와 타겟 마스크 모두 사용\n",
    "\n",
    "    # trg: [batch_size, trg_len, hidden_dim]\n",
    "    # attention: [batch_size, n_heads, trg_len, src_len]\n",
    "\n",
    "    output = self.fc_out(trg)\n",
    "\n",
    "    # output: [batch_size, trg_len, output_dim]\n",
    "\n",
    "    return output, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1BSe_vRZZIY"
   },
   "source": [
    "## Transformer Model\n",
    "입력이 들어왔을 때 앞서 정의한 Encoder와 Decoder을 거쳐 출력 문장을 생성함.\n",
    "\n",
    "파라미터\n",
    "- encoder: encoder 객체\n",
    "- decoder: decoder 객체\n",
    "- src_pad_idx: 소스 문장의 패딩 문자 인덱스\n",
    "- trg_pad_idx: 타겟 문장의 패딩 문자 인덱스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "m5rahb6AZhok"
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "  def __init__(self, encoder, decoder, src_pad_idx, trg_pad_idx, device):\n",
    "    super().__init__()\n",
    "\n",
    "    self.encoder = encoder\n",
    "    self.decoder = decoder\n",
    "    #self.src_pad_idx = src_pad_idx\n",
    "    #self.trg_pad_idx = trg_pad_idx\n",
    "    self.padding_idx = src_pad_idx\n",
    "\n",
    "    self.device = device\n",
    "    '''\n",
    "      def make_padding_mask(self, q, k):\n",
    "        # q,k의 size = (batch_size, seq_len)\n",
    "        _, q_seq_len = q.size()\n",
    "        _, k_seq_len = k.size()\n",
    "    \n",
    "        q = q.ne(self.padding_idx)  # padding token을 0, 나머지를 1로 만들어줌\n",
    "        q = q.unsqueeze(1).unsqueeze(3) # (batch_size, 1, q_seq_len, 1)\n",
    "        q = q.repeat(1,1,1,k_seq_len)   # (batch_size, 1, q_seq_len, k_seq_len)\n",
    "    \n",
    "        k = k.ne(self.padding_idx)\n",
    "        k = k.unsqueeze(1).unsqueeze(2) # (batch_size, 1, 1, k_seq_len)\n",
    "        k = k.repeat(1,1,q_seq_len,1)   # (batch_size, 1, q_seq_len, k_seq_len)\n",
    "    \n",
    "        # and 연산\n",
    "        # (batch_size, 1, q_seq_len, k_seq_len)\n",
    "        mask = q & k\n",
    "    \n",
    "        return mask\n",
    "          \n",
    "      def make_look_ahead_mask(self, tgt):\n",
    "        _, seq_len = tgt.size()\n",
    "    \n",
    "        # torch.tril 함수를 사용하여 한칸씩 밀려나며 마스킹을 해줌\n",
    "        # (seq_len, seq_len)\n",
    "        mask = torch.tril(torch.ones(seq_len,seq_len)).type(torch.BoolTensor).to(self.device)\n",
    "    \n",
    "        return mask\n",
    "    '''\n",
    "  # 소스 문장의  토큰에 대하여 마스크(mask) 값을 0으로 설정\n",
    "  def create_src_mask(self, src):\n",
    "    #주어진 src에서 패딩 인덱스와 같지 않은 요소를 찾는다.\n",
    "    src_mask = torch.ne(src, self.padding_idx).unsqueeze(1).unsqueeze(2)\n",
    "    # src shape: (batch_size, seq_length)\n",
    "    # src_mask shape: (batch_size, 1, 1, seq_length)\n",
    "    return src_mask\n",
    "\n",
    "  # 타겟 문장에서 각 단어는 다음 단어가 무엇인지 알 수 없도록(이전 단어만 보도록) 만들기 위해 마스크를 사용\n",
    "  def create_tgt_mask(self, tgt):\n",
    "    \"\"\"\n",
    "    Pad Mask example\n",
    "        1 0 0 0 0\n",
    "        1 1 0 0 0\n",
    "        1 1 1 0 0\n",
    "        1 1 1 0 0\n",
    "        1 1 1 0 0\n",
    "    \"\"\"\n",
    "    tgt_pad_mask = torch.ne(tgt, self.padding_idx).unsqueeze(1).unsqueeze(3)\n",
    "    # tgt_pad_mask shape: (batch_size, 1, seq_length, 1)\n",
    "        \n",
    "    tgt_len = tgt.shape[1]\n",
    "    # torch.tril 함수는 주어진 텐서의 하삼각부분만을 유지하고 나머지를 0으로 만드는 함수입니다. \n",
    "    # 이를 이용하여 각 위치에서 자신과 이전 토큰만 \"볼 수 있는\" 마스크를 생성합니다. \n",
    "    \"\"\"\n",
    "    Sub Mask example\n",
    "        1 0 0 0 0\n",
    "        1 1 0 0 0\n",
    "        1 1 1 0 0\n",
    "        1 1 1 1 0\n",
    "        1 1 1 1 1\n",
    "        \"\"\"\n",
    "    tgt_sub_mask = torch.tril(torch.ones((tgt_len, tgt_len))).bool()\n",
    "    # tgt_sub_mask shape: (seq_length, seq_length)\n",
    "        \n",
    "    # 이 두 마스크를 합치면, 패딩 토큰과 미래 토큰 모두에 대한 마스크를 생성할 수 있습니다.\n",
    "    tgt_mask = tgt_pad_mask & tgt_sub_mask\n",
    "    # tgt_mask shape: (batch_size, 1, seq_length, seq_length)\n",
    "    return tgt_mask\n",
    "\n",
    "  def forward(self, src, trg):\n",
    "    # src: [batch_size, src_len]\n",
    "    # trg: [batch_size, trg_len]\n",
    "\n",
    "    src_mask = self.create_src_mask(src)\n",
    "    tgt_mask = self.create_tgt_mask(trg)\n",
    "\n",
    "    enc_src = self.encoder(src, src_mask)\n",
    "    # enc_src: [batch_size, src_len, hidden_dim]\n",
    "\n",
    "    output, attention = self.decoder(trg, enc_src, tgt_mask, src_mask)\n",
    "\n",
    "    # output: [batch_size, trg_len, otuput_dim]\n",
    "    # attention: [batch_size, n_heads, trg_len, src_len]\n",
    "\n",
    "    return output, attention\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RbKLabhmgErU"
   },
   "source": [
    "## Training (학습)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5p-kCLmmspl"
   },
   "source": [
    "### 하이퍼 파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "A9dXwLSDZj4p"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(vocab_transform[SRC_LANG])\n",
    "OUTPUT_DIM = len(vocab_transform[TGT_LANG])\n",
    "HIDDEN_DIM = 256\n",
    "ENC_LAYERS = 3\n",
    "DEC_LAYERS = 3\n",
    "ENC_HEADS = 8\n",
    "DEC_HEADS = 8\n",
    "ENC_PF_DIM = 512\n",
    "DEC_PF_DIM = 512\n",
    "ENC_DROPOUT = 0.1\n",
    "DEC_DROPOUT = 0.1\n",
    "\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xqGYQMamnjK"
   },
   "source": [
    "### 모델 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BAJbQwfsiM8I",
    "outputId": "8eddb74e-5d7f-462b-dbc2-5df7006aa9bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# 패딩 인덱스를 확인하기 위해 출력해본다.\n",
    "print(vocab_transform[SRC_LANG].lookup_indices(['<pad>']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "gpuMMWv1h7Q2"
   },
   "outputs": [],
   "source": [
    "SRC_PAD_IDX = vocab_transform[SRC_LANG].lookup_indices(['<pad>'])[0]\n",
    "TGT_PAD_IDX = vocab_transform[TGT_LANG].lookup_indices(['<pad>'])[0]\n",
    "\n",
    "# 인코더와 디코더 객체 선언\n",
    "enc = Encoder(INPUT_DIM, HIDDEN_DIM, ENC_LAYERS, ENC_HEADS, ENC_PF_DIM, ENC_DROPOUT, device)\n",
    "dec = Decoder(OUTPUT_DIM, HIDDEN_DIM, DEC_LAYERS, DEC_HEADS, DEC_PF_DIM, DEC_DROPOUT, device)\n",
    "\n",
    "# Transformer 객체 선언\n",
    "model = Transformer(enc, dec, SRC_PAD_IDX, TGT_PAD_IDX, device).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SH6p7N-FnGS3"
   },
   "source": [
    "### 모델 가중치 파라미터 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dLXaoHqsjp1k",
    "outputId": "1c87c0d2-679f-453a-d703-93da83d7ce61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 9,232,431 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rqcMJz4UnyXk",
    "outputId": "fe78fa99-48db-4ca5-d37d-2f3ab9134c56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): Encoder(\n",
       "    (tok_embedding): Embedding(8014, 256)\n",
       "    (pos_embedding): Embedding(100, 256)\n",
       "    (encoder_layers): ModuleList(\n",
       "      (0-2): 3 x EncoderLayer(\n",
       "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
       "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (tok_embedding): Embedding(6191, 256)\n",
       "    (pos_embedding): Embedding(100, 256)\n",
       "    (decoder_layers): ModuleList(\n",
       "      (0-2): 3 x DecoderLayer(\n",
       "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
       "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (fc_out): Linear(in_features=256, out_features=6191, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def initialize_weights(m):\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "        nn.init.xavier_uniform_(m.weight.data) # 가중치를 Xavier 값으로 초기화\n",
    "\n",
    "model.apply(initialize_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ih-oGnXtn8qg"
   },
   "source": [
    "### 학습 및 평가 함수 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PGuSujTzpTvh"
   },
   "source": [
    "optimizer는 Adam optimizer 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "P_1PEe_PpLWy"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "lr = 0.0005\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# 뒷 부분의 패딩에 대해서는 값 무시\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TGT_PAD_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDKQoU_lpoLe"
   },
   "source": [
    "모델 학습 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QEK93Pq_YX9Q",
    "outputId": "bef27e06-18b1-4be1-e136-5b7326617707"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "gW-VkN2jKTRz"
   },
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion, clip, device):\n",
    "  model.train()\n",
    "  epoch_loss = 0\n",
    "  running_loss = 0\n",
    "\n",
    "  for index, batch in enumerate(dataloader):\n",
    "    src = batch[0]\n",
    "    tgt = batch[1]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 출력 단어의 마지막 인덱스()는 제외\n",
    "    # 입력을 할 때는 부터 시작하도록 처리\n",
    "    output, _ = model(src, tgt[:,:-1])\n",
    "\n",
    "    # output: [배치 크기, tgt_len - 1, output_dim]\n",
    "    # trg: [배치 크기, tgt_len]\n",
    "\n",
    "    output_dim = output.shape[-1]\n",
    "\n",
    "    output = output.contiguous().view(-1, output_dim)\n",
    "    # 출력 단어의 인덱스 0()은 제외\n",
    "    tgt = tgt[:,1:].contiguous().view(-1)\n",
    "\n",
    "    # output: [배치 크기 * tgt_len - 1, output_dim]\n",
    "    # tgt: [배치 크기 * tgt_len - 1]\n",
    "\n",
    "    # 모델의 출력 결과와 타겟 문장을 비교하여 손실 계산\n",
    "    loss = criterion(output, tgt)\n",
    "    loss.backward() # 기울기(gradient) 계산\n",
    "\n",
    "    # 기울기(gradient) clipping 진행\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "    # 파라미터 업데이트\n",
    "    optimizer.step()\n",
    "\n",
    "    # 전체 손실 값 계산\n",
    "    epoch_loss += loss.item()\n",
    "\n",
    "    running_loss += (loss.item() - running_loss) / (index + 1)\n",
    "\n",
    "\n",
    "    print(f\"배치 인덱스 : {index}\\t|\\t이동 손실 : {running_loss}\")\n",
    "\n",
    "  return epoch_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "_9lXdn2eYgTK"
   },
   "outputs": [],
   "source": [
    "# 모델 평가(evaluate) 함수\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval() # 평가 모드\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # 전체 평가 데이터를 확인하며\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            src = batch[0].to(device)\n",
    "            tgt = batch[1].to(device)\n",
    "\n",
    "            # 출력 단어의 마지막 인덱스()는 제외\n",
    "            # 입력을 할 때는 부터 시작하도록 처리\n",
    "            output, _ = model(src, tgt[:,:-1])\n",
    "\n",
    "            # output: [배치 크기, trg_len - 1, output_dim]\n",
    "            # tgt: [배치 크기, tgt_len]\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "\n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            # 출력 단어의 인덱스 0()은 제외\n",
    "            tgt = tgt[:,1:].contiguous().view(-1)\n",
    "\n",
    "            # output: [배치 크기 * trg_len - 1, output_dim]\n",
    "            # tgt: [배치 크기 * tgt_len - 1]\n",
    "\n",
    "            # 모델의 출력 결과와 타겟 문장을 비교하여 손실 계산\n",
    "            loss = criterion(output, tgt)\n",
    "\n",
    "            # 전체 손실 값 계산\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "ckMu93wrYp-W"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uWP6bMABYryG",
    "outputId": "9ea5e144-853d-4785-e055-cd9d4b370951"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에폭 : 0\n",
      "배치 인덱스 : 0\t|\t이동 손실 : 8.757208824157715\n",
      "배치 인덱스 : 1\t|\t이동 손실 : 8.559910774230957\n",
      "배치 인덱스 : 2\t|\t이동 손실 : 8.422504742940268\n",
      "배치 인덱스 : 3\t|\t이동 손실 : 8.313313245773315\n",
      "배치 인덱스 : 4\t|\t이동 손실 : 8.2179612159729\n",
      "배치 인덱스 : 5\t|\t이동 손실 : 8.134968201319378\n",
      "배치 인덱스 : 6\t|\t이동 손실 : 8.05678462982178\n",
      "배치 인덱스 : 7\t|\t이동 손실 : 7.981208503246309\n",
      "배치 인덱스 : 8\t|\t이동 손실 : 7.909010940127904\n",
      "배치 인덱스 : 9\t|\t이동 손실 : 7.836860847473146\n",
      "배치 인덱스 : 10\t|\t이동 손실 : 7.765327843752775\n",
      "배치 인덱스 : 11\t|\t이동 손실 : 7.696515123049419\n",
      "배치 인덱스 : 12\t|\t이동 손실 : 7.629416979276218\n",
      "배치 인덱스 : 13\t|\t이동 손실 : 7.561516250882831\n",
      "배치 인덱스 : 14\t|\t이동 손실 : 7.498679892222087\n",
      "배치 인덱스 : 15\t|\t이동 손실 : 7.4339580833911905\n",
      "배치 인덱스 : 16\t|\t이동 손실 : 7.37362783095416\n",
      "배치 인덱스 : 17\t|\t이동 손실 : 7.313304901123048\n",
      "배치 인덱스 : 18\t|\t이동 손실 : 7.25213552776136\n",
      "배치 인덱스 : 19\t|\t이동 손실 : 7.193245291709901\n",
      "배치 인덱스 : 20\t|\t이동 손실 : 7.1344207127889\n",
      "배치 인덱스 : 21\t|\t이동 손실 : 7.079521244222468\n",
      "배치 인덱스 : 22\t|\t이동 손실 : 7.025757209114406\n",
      "배치 인덱스 : 23\t|\t이동 손실 : 6.970311721165975\n",
      "배치 인덱스 : 24\t|\t이동 손실 : 6.91860065460205\n",
      "배치 인덱스 : 25\t|\t이동 손실 : 6.868741879096397\n",
      "배치 인덱스 : 26\t|\t이동 손실 : 6.818129610132288\n",
      "배치 인덱스 : 27\t|\t이동 손실 : 6.769056490489414\n",
      "배치 인덱스 : 28\t|\t이동 손실 : 6.723252904826197\n",
      "배치 인덱스 : 29\t|\t이동 손실 : 6.677586936950683\n",
      "배치 인덱스 : 30\t|\t이동 손실 : 6.632101935725058\n",
      "배치 인덱스 : 31\t|\t이동 손실 : 6.590454533696175\n",
      "배치 인덱스 : 32\t|\t이동 손실 : 6.549859393726695\n",
      "배치 인덱스 : 33\t|\t이동 손실 : 6.51117309402017\n",
      "배치 인덱스 : 34\t|\t이동 손실 : 6.475533839634486\n",
      "배치 인덱스 : 35\t|\t이동 손실 : 6.438925796084933\n",
      "배치 인덱스 : 36\t|\t이동 손실 : 6.402928751868171\n",
      "배치 인덱스 : 37\t|\t이동 손실 : 6.369174743953504\n",
      "배치 인덱스 : 38\t|\t이동 손실 : 6.33599721468412\n",
      "배치 인덱스 : 39\t|\t이동 손실 : 6.299136173725128\n",
      "배치 인덱스 : 40\t|\t이동 손실 : 6.268527647344078\n",
      "배치 인덱스 : 41\t|\t이동 손실 : 6.237617560795376\n",
      "배치 인덱스 : 42\t|\t이동 손실 : 6.204553581947504\n",
      "배치 인덱스 : 43\t|\t이동 손실 : 6.174659252166748\n",
      "배치 인덱스 : 44\t|\t이동 손실 : 6.145900514390734\n",
      "배치 인덱스 : 45\t|\t이동 손실 : 6.117025696712991\n",
      "배치 인덱스 : 46\t|\t이동 손실 : 6.087019230457062\n",
      "배치 인덱스 : 47\t|\t이동 손실 : 6.060409039258957\n",
      "배치 인덱스 : 48\t|\t이동 손실 : 6.033058156772536\n",
      "배치 인덱스 : 49\t|\t이동 손실 : 6.006426162719727\n",
      "배치 인덱스 : 50\t|\t이동 손실 : 5.980080754149194\n",
      "배치 인덱스 : 51\t|\t이동 손실 : 5.953632565645071\n",
      "배치 인덱스 : 52\t|\t이동 손실 : 5.928016410683686\n",
      "배치 인덱스 : 53\t|\t이동 손실 : 5.903168907871953\n",
      "배치 인덱스 : 54\t|\t이동 손실 : 5.879427094893022\n",
      "배치 인덱스 : 55\t|\t이동 손실 : 5.856682002544403\n",
      "배치 인덱스 : 56\t|\t이동 손실 : 5.833398300304747\n",
      "배치 인덱스 : 57\t|\t이동 손실 : 5.811489475184473\n",
      "배치 인덱스 : 58\t|\t이동 손실 : 5.788132433163917\n",
      "배치 인덱스 : 59\t|\t이동 손실 : 5.765891122817993\n",
      "배치 인덱스 : 60\t|\t이동 손실 : 5.74335811177238\n",
      "배치 인덱스 : 61\t|\t이동 손실 : 5.721467271927864\n",
      "배치 인덱스 : 62\t|\t이동 손실 : 5.701539206126379\n",
      "배치 인덱스 : 63\t|\t이동 손실 : 5.680166468024254\n",
      "배치 인덱스 : 64\t|\t이동 손실 : 5.658579378861647\n",
      "배치 인덱스 : 65\t|\t이동 손실 : 5.640174092668476\n",
      "배치 인덱스 : 66\t|\t이동 손실 : 5.621199977931692\n",
      "배치 인덱스 : 67\t|\t이동 손실 : 5.600636924014372\n",
      "배치 인덱스 : 68\t|\t이동 손실 : 5.583326477935349\n",
      "배치 인덱스 : 69\t|\t이동 손실 : 5.565446063450405\n",
      "배치 인덱스 : 70\t|\t이동 손실 : 5.547408896432796\n",
      "배치 인덱스 : 71\t|\t이동 손실 : 5.5292033486896095\n",
      "배치 인덱스 : 72\t|\t이동 손실 : 5.5110665282158005\n",
      "배치 인덱스 : 73\t|\t이동 손실 : 5.4930555240528\n",
      "배치 인덱스 : 74\t|\t이동 손실 : 5.475079046885172\n",
      "배치 인덱스 : 75\t|\t이동 손실 : 5.458190165067974\n",
      "배치 인덱스 : 76\t|\t이동 손실 : 5.443028258038805\n",
      "배치 인덱스 : 77\t|\t이동 손실 : 5.424992469640879\n",
      "배치 인덱스 : 78\t|\t이동 손실 : 5.408168635790862\n",
      "배치 인덱스 : 79\t|\t이동 손실 : 5.39273533821106\n",
      "배치 인덱스 : 80\t|\t이동 손실 : 5.376122586521102\n",
      "배치 인덱스 : 81\t|\t이동 손실 : 5.361341557851652\n",
      "배치 인덱스 : 82\t|\t이동 손실 : 5.344988719526544\n",
      "배치 인덱스 : 83\t|\t이동 손실 : 5.329703461556208\n",
      "배치 인덱스 : 84\t|\t이동 손실 : 5.3150587867288035\n",
      "배치 인덱스 : 85\t|\t이동 손실 : 5.299249269241511\n",
      "배치 인덱스 : 86\t|\t이동 손실 : 5.2846683661143\n",
      "배치 인덱스 : 87\t|\t이동 손실 : 5.270195318893954\n",
      "배치 인덱스 : 88\t|\t이동 손실 : 5.256703443741531\n",
      "배치 인덱스 : 89\t|\t이동 손실 : 5.241612346967062\n",
      "배치 인덱스 : 90\t|\t이동 손실 : 5.227514966503605\n",
      "배치 인덱스 : 91\t|\t이동 손실 : 5.21434790932614\n",
      "배치 인덱스 : 92\t|\t이동 손실 : 5.202933344789732\n",
      "배치 인덱스 : 93\t|\t이동 손실 : 5.191832407991938\n",
      "배치 인덱스 : 94\t|\t이동 손실 : 5.177872979013545\n",
      "배치 인덱스 : 95\t|\t이동 손실 : 5.166598906119666\n",
      "배치 인덱스 : 96\t|\t이동 손실 : 5.154142070062383\n",
      "배치 인덱스 : 97\t|\t이동 손실 : 5.1401425721694025\n",
      "배치 인덱스 : 98\t|\t이동 손실 : 5.127667887042269\n",
      "배치 인덱스 : 99\t|\t이동 손실 : 5.114530622959139\n",
      "배치 인덱스 : 100\t|\t이동 손실 : 5.101545022265747\n",
      "배치 인덱스 : 101\t|\t이동 손실 : 5.08987904997433\n",
      "배치 인덱스 : 102\t|\t이동 손실 : 5.078569301123759\n",
      "배치 인덱스 : 103\t|\t이동 손실 : 5.067176050864734\n",
      "배치 인덱스 : 104\t|\t이동 손실 : 5.0565061773572655\n",
      "배치 인덱스 : 105\t|\t이동 손실 : 5.045514815258531\n",
      "배치 인덱스 : 106\t|\t이동 손실 : 5.03546717233747\n",
      "배치 인덱스 : 107\t|\t이동 손실 : 5.023893060507598\n",
      "배치 인덱스 : 108\t|\t이동 손실 : 5.01290687727272\n",
      "배치 인덱스 : 109\t|\t이동 손실 : 5.002389779957858\n",
      "배치 인덱스 : 110\t|\t이동 손실 : 4.991302142272125\n",
      "배치 인덱스 : 111\t|\t이동 손실 : 4.981828834329333\n",
      "배치 인덱스 : 112\t|\t이동 손실 : 4.971319553071419\n",
      "배치 인덱스 : 113\t|\t이동 손실 : 4.961144725481669\n",
      "배치 인덱스 : 114\t|\t이동 손실 : 4.951188821377962\n",
      "배치 인덱스 : 115\t|\t이동 손실 : 4.94171487668465\n",
      "배치 인덱스 : 116\t|\t이동 손실 : 4.932018361539924\n",
      "배치 인덱스 : 117\t|\t이동 손실 : 4.922219706793964\n",
      "배치 인덱스 : 118\t|\t이동 손실 : 4.913418511382673\n",
      "배치 인덱스 : 119\t|\t이동 손실 : 4.903315263986589\n",
      "배치 인덱스 : 120\t|\t이동 손실 : 4.893578911615799\n",
      "배치 인덱스 : 121\t|\t이동 손실 : 4.883895760676901\n",
      "배치 인덱스 : 122\t|\t이동 손실 : 4.8743087974021115\n",
      "배치 인덱스 : 123\t|\t이동 손실 : 4.864492041449394\n",
      "배치 인덱스 : 124\t|\t이동 손실 : 4.8551408882141125\n",
      "배치 인덱스 : 125\t|\t이동 손실 : 4.846851532421416\n",
      "배치 인덱스 : 126\t|\t이동 손실 : 4.838023232662773\n",
      "배치 인덱스 : 127\t|\t이동 손실 : 4.829625422134997\n",
      "배치 인덱스 : 128\t|\t이동 손실 : 4.821051732514258\n",
      "배치 인덱스 : 129\t|\t이동 손실 : 4.811862672292271\n",
      "배치 인덱스 : 130\t|\t이동 손실 : 4.802843321370717\n",
      "배치 인덱스 : 131\t|\t이동 손실 : 4.794444004694623\n",
      "배치 인덱스 : 132\t|\t이동 손실 : 4.785505870231114\n",
      "배치 인덱스 : 133\t|\t이동 손실 : 4.776956100962058\n",
      "배치 인덱스 : 134\t|\t이동 손실 : 4.769304220764727\n",
      "배치 인덱스 : 135\t|\t이동 손실 : 4.760369921431824\n",
      "배치 인덱스 : 136\t|\t이동 손실 : 4.751966076175664\n",
      "배치 인덱스 : 137\t|\t이동 손실 : 4.745089422101563\n",
      "배치 인덱스 : 138\t|\t이동 손실 : 4.736836158971995\n",
      "배치 인덱스 : 139\t|\t이동 손실 : 4.729591098853523\n",
      "배치 인덱스 : 140\t|\t이동 손실 : 4.72221870625273\n",
      "배치 인덱스 : 141\t|\t이동 손실 : 4.715247436308528\n",
      "배치 인덱스 : 142\t|\t이동 손실 : 4.708705566979791\n",
      "배치 인덱스 : 143\t|\t이동 손실 : 4.701400104496217\n",
      "배치 인덱스 : 144\t|\t이동 손실 : 4.692987846506055\n",
      "배치 인덱스 : 145\t|\t이동 손실 : 4.684957257688864\n",
      "배치 인덱스 : 146\t|\t이동 손실 : 4.6780739560419216\n",
      "배치 인덱스 : 147\t|\t이동 손실 : 4.6704812259287465\n",
      "배치 인덱스 : 148\t|\t이동 손실 : 4.662694766217432\n",
      "배치 인덱스 : 149\t|\t이동 손실 : 4.655814727147422\n",
      "배치 인덱스 : 150\t|\t이동 손실 : 4.647835562560734\n",
      "배치 인덱스 : 151\t|\t이동 손실 : 4.641083160513327\n",
      "배치 인덱스 : 152\t|\t이동 손실 : 4.634980932559844\n",
      "배치 인덱스 : 153\t|\t이동 손실 : 4.628327937869284\n",
      "배치 인덱스 : 154\t|\t이동 손실 : 4.621828283802157\n",
      "배치 인덱스 : 155\t|\t이동 손실 : 4.615055417403198\n",
      "배치 인덱스 : 156\t|\t이동 손실 : 4.608199851528096\n",
      "배치 인덱스 : 157\t|\t이동 손실 : 4.6025001021880145\n",
      "배치 인덱스 : 158\t|\t이동 손실 : 4.596146745501825\n",
      "배치 인덱스 : 159\t|\t이동 손실 : 4.589537715911866\n",
      "배치 인덱스 : 160\t|\t이동 손실 : 4.5826672308193235\n",
      "배치 인덱스 : 161\t|\t이동 손실 : 4.576750955463928\n",
      "배치 인덱스 : 162\t|\t이동 손실 : 4.570110313731469\n",
      "배치 인덱스 : 163\t|\t이동 손실 : 4.563685347394246\n",
      "배치 인덱스 : 164\t|\t이동 손실 : 4.557274133508857\n",
      "배치 인덱스 : 165\t|\t이동 손실 : 4.550201061260271\n",
      "배치 인덱스 : 166\t|\t이동 손실 : 4.5433306165798\n",
      "배치 인덱스 : 167\t|\t이동 손실 : 4.536891393718267\n",
      "배치 인덱스 : 168\t|\t이동 손실 : 4.5303708815715735\n",
      "배치 인덱스 : 169\t|\t이동 손실 : 4.524114953770359\n",
      "배치 인덱스 : 170\t|\t이동 손실 : 4.517802803139939\n",
      "배치 인덱스 : 171\t|\t이동 손실 : 4.511599683484367\n",
      "배치 인덱스 : 172\t|\t이동 손실 : 4.505266565807983\n",
      "배치 인덱스 : 173\t|\t이동 손실 : 4.500581069924367\n",
      "배치 인덱스 : 174\t|\t이동 손실 : 4.494075790132797\n",
      "배치 인덱스 : 175\t|\t이동 손실 : 4.488547479564495\n",
      "배치 인덱스 : 176\t|\t이동 손실 : 4.482523871006941\n",
      "배치 인덱스 : 177\t|\t이동 손실 : 4.476983607485056\n",
      "배치 인덱스 : 178\t|\t이동 손실 : 4.471177725818572\n",
      "배치 인덱스 : 179\t|\t이동 손실 : 4.465219132105512\n",
      "배치 인덱스 : 180\t|\t이동 손실 : 4.459539521464988\n",
      "배치 인덱스 : 181\t|\t이동 손실 : 4.453666930670269\n",
      "배치 인덱스 : 182\t|\t이동 손실 : 4.4480356935594925\n",
      "배치 인덱스 : 183\t|\t이동 손실 : 4.442538743433747\n",
      "배치 인덱스 : 184\t|\t이동 손실 : 4.436659472697492\n",
      "배치 인덱스 : 185\t|\t이동 손실 : 4.430892022707131\n",
      "배치 인덱스 : 186\t|\t이동 손실 : 4.4253184591385155\n",
      "배치 인덱스 : 187\t|\t이동 손실 : 4.419415230446676\n",
      "배치 인덱스 : 188\t|\t이동 손실 : 4.414617265973774\n",
      "배치 인덱스 : 189\t|\t이동 손실 : 4.410005785289566\n",
      "배치 인덱스 : 190\t|\t이동 손실 : 4.405558075580299\n",
      "배치 인덱스 : 191\t|\t이동 손실 : 4.400152628620468\n",
      "배치 인덱스 : 192\t|\t이동 손실 : 4.395155680611964\n",
      "배치 인덱스 : 193\t|\t이동 손실 : 4.39033981082366\n",
      "배치 인덱스 : 194\t|\t이동 손실 : 4.384677941982566\n",
      "배치 인덱스 : 195\t|\t이동 손실 : 4.379315035683771\n",
      "배치 인덱스 : 196\t|\t이동 손실 : 4.3744991600210925\n",
      "배치 인덱스 : 197\t|\t이동 손실 : 4.368680934713347\n",
      "배치 인덱스 : 198\t|\t이동 손실 : 4.363535597096738\n",
      "배치 인덱스 : 199\t|\t이동 손실 : 4.358578554391864\n",
      "배치 인덱스 : 200\t|\t이동 손실 : 4.353380723972228\n",
      "배치 인덱스 : 201\t|\t이동 손실 : 4.348207766466804\n",
      "배치 인덱스 : 202\t|\t이동 손실 : 4.343286964106444\n",
      "배치 인덱스 : 203\t|\t이동 손실 : 4.338163821136252\n",
      "배치 인덱스 : 204\t|\t이동 손실 : 4.333003754732087\n",
      "배치 인덱스 : 205\t|\t이동 손실 : 4.328410718047505\n",
      "배치 인덱스 : 206\t|\t이동 손실 : 4.323415273629527\n",
      "배치 인덱스 : 207\t|\t이동 손실 : 4.3188324123621005\n",
      "배치 인덱스 : 208\t|\t이동 손실 : 4.313711103640107\n",
      "배치 인덱스 : 209\t|\t이동 손실 : 4.309410729862397\n",
      "배치 인덱스 : 210\t|\t이동 손실 : 4.304201717060327\n",
      "배치 인덱스 : 211\t|\t이동 손실 : 4.299667397759998\n",
      "배치 인덱스 : 212\t|\t이동 손실 : 4.294701211329359\n",
      "배치 인덱스 : 213\t|\t이동 손실 : 4.289409985052093\n",
      "배치 인덱스 : 214\t|\t이동 손실 : 4.2850504420524445\n",
      "배치 인덱스 : 215\t|\t이동 손실 : 4.280108901085679\n",
      "배치 인덱스 : 216\t|\t이동 손실 : 4.27567153702134\n",
      "배치 인덱스 : 217\t|\t이동 손실 : 4.271183906345194\n",
      "배치 인덱스 : 218\t|\t이동 손실 : 4.266678032809742\n",
      "배치 인덱스 : 219\t|\t이동 손실 : 4.261975931037558\n",
      "배치 인덱스 : 220\t|\t이동 손실 : 4.257588541885308\n",
      "배치 인덱스 : 221\t|\t이동 손실 : 4.252037811923673\n",
      "배치 인덱스 : 222\t|\t이동 손실 : 4.247566079879557\n",
      "배치 인덱스 : 223\t|\t이동 손실 : 4.243622603160996\n",
      "배치 인덱스 : 224\t|\t이동 손실 : 4.239916569391888\n",
      "배치 인덱스 : 225\t|\t이동 손실 : 4.235579214264863\n",
      "배치 인덱스 : 226\t|\t이동 손실 : 4.2306537208053\n",
      "Epoch: 01 | Time: 14m 6s\n",
      "\tTrain Loss: 4.231 | Train PPL: 68.762\n",
      "\tValidation Loss: 3.050 | Validation PPL: 21.112\n",
      "에폭 : 1\n",
      "배치 인덱스 : 0\t|\t이동 손실 : 3.1395015716552734\n",
      "배치 인덱스 : 1\t|\t이동 손실 : 3.135301351547241\n",
      "배치 인덱스 : 2\t|\t이동 손실 : 3.165741523106893\n",
      "배치 인덱스 : 3\t|\t이동 손실 : 3.1383156776428223\n",
      "배치 인덱스 : 4\t|\t이동 손실 : 3.1104337692260744\n",
      "배치 인덱스 : 5\t|\t이동 손실 : 3.118652900060018\n",
      "배치 인덱스 : 6\t|\t이동 손실 : 3.108156476702009\n",
      "배치 인덱스 : 7\t|\t이동 손실 : 3.1075123250484467\n",
      "배치 인덱스 : 8\t|\t이동 손실 : 3.102196349038018\n",
      "배치 인덱스 : 9\t|\t이동 손실 : 3.1023850202560426\n",
      "배치 인덱스 : 10\t|\t이동 손실 : 3.1075122356414795\n",
      "배치 인덱스 : 11\t|\t이동 손실 : 3.0940375328063965\n",
      "배치 인덱스 : 12\t|\t이동 손실 : 3.0878447202535777\n",
      "배치 인덱스 : 13\t|\t이동 손실 : 3.0755074535097395\n",
      "배치 인덱스 : 14\t|\t이동 손실 : 3.066862456003825\n",
      "배치 인덱스 : 15\t|\t이동 손실 : 3.0714669227600098\n",
      "배치 인덱스 : 16\t|\t이동 손실 : 3.078823776806102\n",
      "배치 인덱스 : 17\t|\t이동 손실 : 3.083923776944478\n",
      "배치 인덱스 : 18\t|\t이동 손실 : 3.080990954449302\n",
      "배치 인덱스 : 19\t|\t이동 손실 : 3.078847336769104\n",
      "배치 인덱스 : 20\t|\t이동 손실 : 3.0707092058090937\n",
      "배치 인덱스 : 21\t|\t이동 손실 : 3.066976384683089\n",
      "배치 인덱스 : 22\t|\t이동 손실 : 3.0601606265358305\n",
      "배치 인덱스 : 23\t|\t이동 손실 : 3.0596618751684828\n",
      "배치 인덱스 : 24\t|\t이동 손실 : 3.0580821609497075\n",
      "배치 인덱스 : 25\t|\t이동 손실 : 3.0547315432475166\n",
      "배치 인덱스 : 26\t|\t이동 손실 : 3.056079740877505\n",
      "배치 인덱스 : 27\t|\t이동 손실 : 3.0567138195037846\n",
      "배치 인덱스 : 28\t|\t이동 손실 : 3.0549102980515057\n",
      "배치 인덱스 : 29\t|\t이동 손실 : 3.0551116943359378\n",
      "배치 인덱스 : 30\t|\t이동 손실 : 3.0511541828032467\n",
      "배치 인덱스 : 31\t|\t이동 손실 : 3.0525747761130337\n",
      "배치 인덱스 : 32\t|\t이동 손실 : 3.0527592861291137\n",
      "배치 인덱스 : 33\t|\t이동 손실 : 3.047330316375284\n",
      "배치 인덱스 : 34\t|\t이동 손실 : 3.0412650585174563\n",
      "배치 인덱스 : 35\t|\t이동 손실 : 3.0370195706685386\n",
      "배치 인덱스 : 36\t|\t이동 손실 : 3.033350944519043\n",
      "배치 인덱스 : 37\t|\t이동 손실 : 3.0345691191522697\n",
      "배치 인덱스 : 38\t|\t이동 손실 : 3.0361344202970844\n",
      "배치 인덱스 : 39\t|\t이동 손실 : 3.034727621078491\n",
      "배치 인덱스 : 40\t|\t이동 손실 : 3.0315904210253457\n",
      "배치 인덱스 : 41\t|\t이동 손실 : 3.032550147601536\n",
      "배치 인덱스 : 42\t|\t이동 손실 : 3.031440052875252\n",
      "배치 인덱스 : 43\t|\t이동 손실 : 3.028379256075078\n",
      "배치 인덱스 : 44\t|\t이동 손실 : 3.0286937342749694\n",
      "배치 인덱스 : 45\t|\t이동 손실 : 3.0265654169994844\n",
      "배치 인덱스 : 46\t|\t이동 손실 : 3.022358021837599\n",
      "배치 인덱스 : 47\t|\t이동 손실 : 3.0183027237653723\n",
      "배치 인덱스 : 48\t|\t이동 손실 : 3.0199535476918116\n",
      "배치 인덱스 : 49\t|\t이동 손실 : 3.0172309827804558\n",
      "배치 인덱스 : 50\t|\t이동 손실 : 3.0144649206423284\n",
      "배치 인덱스 : 51\t|\t이동 손실 : 3.016555075462047\n",
      "배치 인덱스 : 52\t|\t이동 손실 : 3.013945907916662\n",
      "배치 인덱스 : 53\t|\t이동 손실 : 3.015936100924456\n",
      "배치 인덱스 : 54\t|\t이동 손실 : 3.0174778504805126\n",
      "배치 인덱스 : 55\t|\t이동 손실 : 3.0164985912186753\n",
      "배치 인덱스 : 56\t|\t이동 손실 : 3.016011944988317\n",
      "배치 인덱스 : 57\t|\t이동 손실 : 3.0158841239994967\n",
      "배치 인덱스 : 58\t|\t이동 손실 : 3.0140039193428168\n",
      "배치 인덱스 : 59\t|\t이동 손실 : 3.013378548622131\n",
      "배치 인덱스 : 60\t|\t이동 손실 : 3.012022549988793\n",
      "배치 인덱스 : 61\t|\t이동 손실 : 3.0095961939903995\n",
      "배치 인덱스 : 62\t|\t이동 손실 : 3.0084917356097507\n",
      "배치 인덱스 : 63\t|\t이동 손실 : 3.0070439279079437\n",
      "배치 인덱스 : 64\t|\t이동 손실 : 3.0019038200378416\n",
      "배치 인덱스 : 65\t|\t이동 손실 : 2.998840834155227\n",
      "배치 인덱스 : 66\t|\t이동 손실 : 2.9977157329445454\n",
      "배치 인덱스 : 67\t|\t이동 손실 : 2.9938421109143425\n",
      "배치 인덱스 : 68\t|\t이동 손실 : 2.9934752263884614\n",
      "배치 인덱스 : 69\t|\t이동 손실 : 2.990950850078038\n",
      "배치 인덱스 : 70\t|\t이동 손실 : 2.989838052803362\n",
      "배치 인덱스 : 71\t|\t이동 손실 : 2.991161379549238\n",
      "배치 인덱스 : 72\t|\t이동 손실 : 2.988981844627694\n",
      "배치 인덱스 : 73\t|\t이동 손실 : 2.9871568808684477\n",
      "배치 인덱스 : 74\t|\t이동 손실 : 2.9865198389689125\n",
      "배치 인덱스 : 75\t|\t이동 손실 : 2.985594476524152\n",
      "배치 인덱스 : 76\t|\t이동 손실 : 2.9832723450351066\n",
      "배치 인덱스 : 77\t|\t이동 손실 : 2.9811553588280306\n",
      "배치 인덱스 : 78\t|\t이동 손실 : 2.9790794004367873\n",
      "배치 인덱스 : 79\t|\t이동 손실 : 2.978500413894653\n",
      "배치 인덱스 : 80\t|\t이동 손실 : 2.977636334336834\n",
      "배치 인덱스 : 81\t|\t이동 손실 : 2.976393667663016\n",
      "배치 인덱스 : 82\t|\t이동 손실 : 2.9734776336026476\n",
      "배치 인덱스 : 83\t|\t이동 손실 : 2.970753261021205\n",
      "배치 인덱스 : 84\t|\t이동 손실 : 2.968221557841581\n",
      "배치 인덱스 : 85\t|\t이동 손실 : 2.9667176507240116\n",
      "배치 인덱스 : 86\t|\t이동 손실 : 2.9662406745998338\n",
      "배치 인덱스 : 87\t|\t이동 손실 : 2.965651972727342\n",
      "배치 인덱스 : 88\t|\t이동 손실 : 2.9637859751669207\n",
      "배치 인덱스 : 89\t|\t이동 손실 : 2.962154494391547\n",
      "배치 인덱스 : 90\t|\t이동 손실 : 2.9617351123264855\n",
      "배치 인덱스 : 91\t|\t이동 손실 : 2.9602489030879475\n",
      "배치 인덱스 : 92\t|\t이동 손실 : 2.9586131085631666\n",
      "배치 인덱스 : 93\t|\t이동 손실 : 2.9574299061552005\n",
      "배치 인덱스 : 94\t|\t이동 손실 : 2.9562643201727616\n",
      "배치 인덱스 : 95\t|\t이동 손실 : 2.955055591960748\n",
      "배치 인덱스 : 96\t|\t이동 손실 : 2.952219722197228\n",
      "배치 인덱스 : 97\t|\t이동 손실 : 2.95110090168155\n",
      "배치 인덱스 : 98\t|\t이동 손실 : 2.9496928706313628\n",
      "배치 인덱스 : 99\t|\t이동 손실 : 2.9479765176773074\n",
      "배치 인덱스 : 100\t|\t이동 손실 : 2.9462818178800076\n",
      "배치 인덱스 : 101\t|\t이동 손실 : 2.9458426564347513\n",
      "배치 인덱스 : 102\t|\t이동 손실 : 2.9445152815105846\n",
      "배치 인덱스 : 103\t|\t이동 손실 : 2.9431461783555837\n",
      "배치 인덱스 : 104\t|\t이동 손실 : 2.9407009601593015\n",
      "배치 인덱스 : 105\t|\t이동 손실 : 2.9385997461822795\n",
      "배치 인덱스 : 106\t|\t이동 손실 : 2.9368122760380535\n",
      "배치 인덱스 : 107\t|\t이동 손실 : 2.9344477366518085\n",
      "배치 인덱스 : 108\t|\t이동 손실 : 2.932670466396786\n",
      "배치 인덱스 : 109\t|\t이동 손실 : 2.9292214697057544\n",
      "배치 인덱스 : 110\t|\t이동 손실 : 2.9267074374465247\n",
      "배치 인덱스 : 111\t|\t이동 손실 : 2.9257530889340804\n",
      "배치 인덱스 : 112\t|\t이동 손실 : 2.924964662146779\n",
      "배치 인덱스 : 113\t|\t이동 손실 : 2.9239738447624335\n",
      "배치 인덱스 : 114\t|\t이동 손실 : 2.9218699911366333\n",
      "배치 인덱스 : 115\t|\t이동 손실 : 2.920666725471101\n",
      "배치 인덱스 : 116\t|\t이동 손실 : 2.919607007605397\n",
      "배치 인덱스 : 117\t|\t이동 손실 : 2.9177960076574543\n",
      "배치 인덱스 : 118\t|\t이동 손실 : 2.9169023597941672\n",
      "배치 인덱스 : 119\t|\t이동 손실 : 2.916820746660232\n",
      "배치 인덱스 : 120\t|\t이동 손실 : 2.914965156681281\n",
      "배치 인덱스 : 121\t|\t이동 손실 : 2.9129050833279964\n",
      "배치 인덱스 : 122\t|\t이동 손실 : 2.910876812973642\n",
      "배치 인덱스 : 123\t|\t이동 손실 : 2.90966696316196\n",
      "배치 인덱스 : 124\t|\t이동 손실 : 2.908806324005126\n",
      "배치 인덱스 : 125\t|\t이동 손실 : 2.9070041066124315\n",
      "배치 인덱스 : 126\t|\t이동 손실 : 2.9042366283146404\n",
      "배치 인덱스 : 127\t|\t이동 손실 : 2.901804348453878\n",
      "배치 인덱스 : 128\t|\t이동 손실 : 2.9002763559651914\n",
      "배치 인덱스 : 129\t|\t이동 손실 : 2.8978667479294984\n",
      "배치 인덱스 : 130\t|\t이동 손실 : 2.897182142461528\n",
      "배치 인덱스 : 131\t|\t이동 손실 : 2.89589902487668\n",
      "배치 인덱스 : 132\t|\t이동 손실 : 2.8940924719760277\n",
      "배치 인덱스 : 133\t|\t이동 손실 : 2.8921621593076776\n",
      "배치 인덱스 : 134\t|\t이동 손실 : 2.890320581860011\n",
      "배치 인덱스 : 135\t|\t이동 손실 : 2.8888398356297422\n",
      "배치 인덱스 : 136\t|\t이동 손실 : 2.887613068531898\n",
      "배치 인덱스 : 137\t|\t이동 손실 : 2.887088552765223\n",
      "배치 인덱스 : 138\t|\t이동 손실 : 2.884891681533922\n",
      "배치 인덱스 : 139\t|\t이동 손실 : 2.883215360982076\n",
      "배치 인덱스 : 140\t|\t이동 손실 : 2.8832945958942373\n",
      "배치 인덱스 : 141\t|\t이동 손실 : 2.882016193698828\n",
      "배치 인덱스 : 142\t|\t이동 손실 : 2.881129499915595\n",
      "배치 인덱스 : 143\t|\t이동 손실 : 2.8810090935892516\n",
      "배치 인덱스 : 144\t|\t이동 손실 : 2.87947397889762\n",
      "배치 인덱스 : 145\t|\t이동 손실 : 2.8787432664061234\n",
      "배치 인덱스 : 146\t|\t이동 손실 : 2.876318396354207\n",
      "배치 인덱스 : 147\t|\t이동 손실 : 2.875434799774272\n",
      "배치 인덱스 : 148\t|\t이동 손실 : 2.87484774493531\n",
      "배치 인덱스 : 149\t|\t이동 손실 : 2.8735927248001087\n",
      "배치 인덱스 : 150\t|\t이동 손실 : 2.8717526584271553\n",
      "배치 인덱스 : 151\t|\t이동 손실 : 2.8697307611766605\n",
      "배치 인덱스 : 152\t|\t이동 손실 : 2.8680024411943212\n",
      "배치 인덱스 : 153\t|\t이동 손실 : 2.866622779276463\n",
      "배치 인덱스 : 154\t|\t이동 손실 : 2.8658221783176536\n",
      "배치 인덱스 : 155\t|\t이동 손실 : 2.8645433936363602\n",
      "배치 인덱스 : 156\t|\t이동 손실 : 2.863961471873483\n",
      "배치 인덱스 : 157\t|\t이동 손실 : 2.862493299230744\n",
      "배치 인덱스 : 158\t|\t이동 손실 : 2.8610904276745868\n",
      "배치 인덱스 : 159\t|\t이동 손실 : 2.8599150970578187\n",
      "배치 인덱스 : 160\t|\t이동 손실 : 2.85935298108166\n",
      "배치 인덱스 : 161\t|\t이동 손실 : 2.8576609426074553\n",
      "배치 인덱스 : 162\t|\t이동 손실 : 2.857151502480536\n",
      "배치 인덱스 : 163\t|\t이동 손실 : 2.8551694430956025\n",
      "배치 인덱스 : 164\t|\t이동 손실 : 2.853848512244947\n",
      "배치 인덱스 : 165\t|\t이동 손실 : 2.8518213062401276\n",
      "배치 인덱스 : 166\t|\t이동 손실 : 2.85007026523887\n",
      "배치 인덱스 : 167\t|\t이동 손실 : 2.8486576662177128\n",
      "배치 인덱스 : 168\t|\t이동 손실 : 2.847665719026644\n",
      "배치 인덱스 : 169\t|\t이동 손실 : 2.8465656042098995\n",
      "배치 인덱스 : 170\t|\t이동 손실 : 2.8453957588351955\n",
      "배치 인덱스 : 171\t|\t이동 손실 : 2.843082422433897\n",
      "배치 인덱스 : 172\t|\t이동 손실 : 2.8418579060218234\n",
      "배치 인덱스 : 173\t|\t이동 손실 : 2.840401345285876\n",
      "배치 인덱스 : 174\t|\t이동 손실 : 2.8390380137307303\n",
      "배치 인덱스 : 175\t|\t이동 손실 : 2.838136773217808\n",
      "배치 인덱스 : 176\t|\t이동 손실 : 2.8367632863211765\n",
      "배치 인덱스 : 177\t|\t이동 손실 : 2.834642352682821\n",
      "배치 인덱스 : 178\t|\t이동 손실 : 2.8325166542436824\n",
      "배치 인덱스 : 179\t|\t이동 손실 : 2.8313723338974848\n",
      "배치 인덱스 : 180\t|\t이동 손실 : 2.8305509406558715\n",
      "배치 인덱스 : 181\t|\t이동 손실 : 2.82983621267172\n",
      "배치 인덱스 : 182\t|\t이동 손실 : 2.8284988572688703\n",
      "배치 인덱스 : 183\t|\t이동 손실 : 2.8278421435667123\n",
      "배치 인덱스 : 184\t|\t이동 손실 : 2.827339269019462\n",
      "배치 인덱스 : 185\t|\t이동 손실 : 2.82532633760924\n",
      "배치 인덱스 : 186\t|\t이동 손실 : 2.8243529120868542\n",
      "배치 인덱스 : 187\t|\t이동 손실 : 2.8228737331451255\n",
      "배치 인덱스 : 188\t|\t이동 손실 : 2.821891908292417\n",
      "배치 인덱스 : 189\t|\t이동 손실 : 2.8209187582919473\n",
      "배치 인덱스 : 190\t|\t이동 손실 : 2.8197482243882424\n",
      "배치 인덱스 : 191\t|\t이동 손실 : 2.818567874530951\n",
      "배치 인덱스 : 192\t|\t이동 손실 : 2.8165863017344104\n",
      "배치 인덱스 : 193\t|\t이동 손실 : 2.8159283743691197\n",
      "배치 인덱스 : 194\t|\t이동 손실 : 2.8154243872715874\n",
      "배치 인덱스 : 195\t|\t이동 손실 : 2.814122144056826\n",
      "배치 인덱스 : 196\t|\t이동 손실 : 2.8128087665828954\n",
      "배치 인덱스 : 197\t|\t이동 손실 : 2.8114389337674535\n",
      "배치 인덱스 : 198\t|\t이동 손실 : 2.8097226380103795\n",
      "배치 인덱스 : 199\t|\t이동 손실 : 2.8080989789962767\n",
      "배치 인덱스 : 200\t|\t이동 손실 : 2.806333892974094\n",
      "배치 인덱스 : 201\t|\t이동 손실 : 2.804354374951655\n",
      "배치 인덱스 : 202\t|\t이동 손실 : 2.803337421323278\n",
      "배치 인덱스 : 203\t|\t이동 손실 : 2.8014769542450995\n",
      "배치 인덱스 : 204\t|\t이동 손실 : 2.8001627177726927\n",
      "배치 인덱스 : 205\t|\t이동 손실 : 2.7995377941039\n",
      "배치 인덱스 : 206\t|\t이동 손실 : 2.798102722075826\n",
      "배치 인덱스 : 207\t|\t이동 손실 : 2.797661879887947\n",
      "배치 인덱스 : 208\t|\t이동 손실 : 2.7965316612754707\n",
      "배치 인덱스 : 209\t|\t이동 손실 : 2.7950532243365327\n",
      "배치 인덱스 : 210\t|\t이동 손실 : 2.7936041208240088\n",
      "배치 인덱스 : 211\t|\t이동 손실 : 2.79266774204542\n",
      "배치 인덱스 : 212\t|\t이동 손실 : 2.7912095958638075\n",
      "배치 인덱스 : 213\t|\t이동 손실 : 2.789769282964902\n",
      "배치 인덱스 : 214\t|\t이동 손실 : 2.788555541149405\n",
      "배치 인덱스 : 215\t|\t이동 손실 : 2.7878443532519865\n",
      "배치 인덱스 : 216\t|\t이동 손실 : 2.7860891478402268\n",
      "배치 인덱스 : 217\t|\t이동 손실 : 2.784521573180452\n",
      "배치 인덱스 : 218\t|\t이동 손실 : 2.782957265366157\n",
      "배치 인덱스 : 219\t|\t이동 손실 : 2.7817293546416533\n",
      "배치 인덱스 : 220\t|\t이동 손실 : 2.780906528369333\n",
      "배치 인덱스 : 221\t|\t이동 손실 : 2.7801660557050956\n",
      "배치 인덱스 : 222\t|\t이동 손실 : 2.779135031550454\n",
      "배치 인덱스 : 223\t|\t이동 손실 : 2.7773521574480187\n",
      "배치 인덱스 : 224\t|\t이동 손실 : 2.7755543486277254\n",
      "배치 인덱스 : 225\t|\t이동 손실 : 2.7745975614648994\n",
      "배치 인덱스 : 226\t|\t이동 손실 : 2.7731187207058126\n",
      "Epoch: 02 | Time: 14m 11s\n",
      "\tTrain Loss: 2.773 | Train PPL: 16.008\n",
      "\tValidation Loss: 2.339 | Validation PPL: 10.375\n",
      "에폭 : 2\n",
      "배치 인덱스 : 0\t|\t이동 손실 : 2.237395763397217\n",
      "배치 인덱스 : 1\t|\t이동 손실 : 2.307295799255371\n",
      "배치 인덱스 : 2\t|\t이동 손실 : 2.327468236287435\n",
      "배치 인덱스 : 3\t|\t이동 손실 : 2.308566927909851\n",
      "배치 인덱스 : 4\t|\t이동 손실 : 2.31748046875\n",
      "배치 인덱스 : 5\t|\t이동 손실 : 2.30618417263031\n",
      "배치 인덱스 : 6\t|\t이동 손실 : 2.3225280216761996\n",
      "배치 인덱스 : 7\t|\t이동 손실 : 2.33717942237854\n",
      "배치 인덱스 : 8\t|\t이동 손실 : 2.3268528514438205\n",
      "배치 인덱스 : 9\t|\t이동 손실 : 2.341371250152588\n",
      "배치 인덱스 : 10\t|\t이동 손실 : 2.338909756053578\n",
      "배치 인덱스 : 11\t|\t이동 손실 : 2.3305525382359824\n",
      "배치 인덱스 : 12\t|\t이동 손실 : 2.3273096084594727\n",
      "배치 인덱스 : 13\t|\t이동 손실 : 2.3231743574142456\n",
      "배치 인덱스 : 14\t|\t이동 손실 : 2.3230313142140706\n",
      "배치 인덱스 : 15\t|\t이동 손실 : 2.3207904547452927\n",
      "배치 인덱스 : 16\t|\t이동 손실 : 2.3179961793562947\n",
      "배치 인덱스 : 17\t|\t이동 손실 : 2.315595759285821\n",
      "배치 인덱스 : 18\t|\t이동 손실 : 2.3212926387786865\n",
      "배치 인덱스 : 19\t|\t이동 손실 : 2.3262426018714906\n",
      "배치 인덱스 : 20\t|\t이동 손실 : 2.331275463104248\n",
      "배치 인덱스 : 21\t|\t이동 손실 : 2.3330272978002373\n",
      "배치 인덱스 : 22\t|\t이동 손실 : 2.3285755178202754\n",
      "배치 인덱스 : 23\t|\t이동 손실 : 2.3269241650899253\n",
      "배치 인덱스 : 24\t|\t이동 손실 : 2.327856140136719\n",
      "배치 인덱스 : 25\t|\t이동 손실 : 2.3263237934846144\n",
      "배치 인덱스 : 26\t|\t이동 손실 : 2.3285091011612504\n",
      "배치 인덱스 : 27\t|\t이동 손실 : 2.3262918506349837\n",
      "배치 인덱스 : 28\t|\t이동 손실 : 2.3280553817749023\n",
      "배치 인덱스 : 29\t|\t이동 손실 : 2.324905037879944\n",
      "배치 인덱스 : 30\t|\t이동 손실 : 2.325913344660113\n",
      "배치 인덱스 : 31\t|\t이동 손실 : 2.323588475584984\n",
      "배치 인덱스 : 32\t|\t이동 손실 : 2.3217337998476895\n",
      "배치 인덱스 : 33\t|\t이동 손실 : 2.3186329743441414\n",
      "배치 인덱스 : 34\t|\t이동 손실 : 2.3182285717555455\n",
      "배치 인덱스 : 35\t|\t이동 손실 : 2.320583383242289\n",
      "배치 인덱스 : 36\t|\t이동 손실 : 2.3170684543815816\n",
      "배치 인덱스 : 37\t|\t이동 손실 : 2.3188070874465136\n",
      "배치 인덱스 : 38\t|\t이동 손실 : 2.3199012707441278\n",
      "배치 인덱스 : 39\t|\t이동 손실 : 2.318192321062088\n",
      "배치 인덱스 : 40\t|\t이동 손실 : 2.316347209418692\n",
      "배치 인덱스 : 41\t|\t이동 손실 : 2.319137595948719\n",
      "배치 인덱스 : 42\t|\t이동 손실 : 2.316531220147776\n",
      "배치 인덱스 : 43\t|\t이동 손실 : 2.3151263269511135\n",
      "배치 인덱스 : 44\t|\t이동 손실 : 2.3114819314744737\n",
      "배치 인덱스 : 45\t|\t이동 손실 : 2.312514709389728\n",
      "배치 인덱스 : 46\t|\t이동 손실 : 2.3136749622669623\n",
      "배치 인덱스 : 47\t|\t이동 손실 : 2.3149033536513643\n",
      "배치 인덱스 : 48\t|\t이동 손실 : 2.314892768859863\n",
      "배치 인덱스 : 49\t|\t이동 손실 : 2.3140896987915034\n",
      "배치 인덱스 : 50\t|\t이동 손실 : 2.3118438533708154\n",
      "배치 인덱스 : 51\t|\t이동 손실 : 2.3116791431720434\n",
      "배치 인덱스 : 52\t|\t이동 손실 : 2.3095235509692493\n",
      "배치 인덱스 : 53\t|\t이동 손실 : 2.306533809061403\n",
      "배치 인덱스 : 54\t|\t이동 손실 : 2.306133686412464\n",
      "배치 인덱스 : 55\t|\t이동 손실 : 2.3039161988667076\n",
      "배치 인덱스 : 56\t|\t이동 손실 : 2.301818078024345\n",
      "배치 인덱스 : 57\t|\t이동 손실 : 2.2996753865274884\n",
      "배치 인덱스 : 58\t|\t이동 손실 : 2.2977196564108633\n",
      "배치 인덱스 : 59\t|\t이동 손실 : 2.297942996025085\n",
      "배치 인덱스 : 60\t|\t이동 손실 : 2.2954339785654034\n",
      "배치 인덱스 : 61\t|\t이동 손실 : 2.2959328351482267\n",
      "배치 인덱스 : 62\t|\t이동 손실 : 2.29199224805075\n",
      "배치 인덱스 : 63\t|\t이동 손실 : 2.29128110781312\n",
      "배치 인덱스 : 64\t|\t이동 손실 : 2.290896489070012\n",
      "배치 인덱스 : 65\t|\t이동 손실 : 2.289390437530749\n",
      "배치 인덱스 : 66\t|\t이동 손실 : 2.2860122118423236\n",
      "배치 인덱스 : 67\t|\t이동 손실 : 2.286910029018627\n",
      "배치 인덱스 : 68\t|\t이동 손실 : 2.285933729531109\n",
      "배치 인덱스 : 69\t|\t이동 손실 : 2.2852214234215875\n",
      "배치 인덱스 : 70\t|\t이동 손실 : 2.283274486031331\n",
      "배치 인덱스 : 71\t|\t이동 손실 : 2.2837257915072975\n",
      "배치 인덱스 : 72\t|\t이동 손실 : 2.285168399549511\n",
      "배치 인덱스 : 73\t|\t이동 손실 : 2.283379197120667\n",
      "배치 인덱스 : 74\t|\t이동 손실 : 2.282470938364665\n",
      "배치 인덱스 : 75\t|\t이동 손실 : 2.2819350487307504\n",
      "배치 인덱스 : 76\t|\t이동 손실 : 2.2819826726789603\n",
      "배치 인덱스 : 77\t|\t이동 손실 : 2.2817224294711385\n",
      "배치 인덱스 : 78\t|\t이동 손실 : 2.2804307937622075\n",
      "배치 인덱스 : 79\t|\t이동 손실 : 2.279563865065575\n",
      "배치 인덱스 : 80\t|\t이동 손실 : 2.277293196430913\n",
      "배치 인덱스 : 81\t|\t이동 손실 : 2.2771801279812327\n",
      "배치 인덱스 : 82\t|\t이동 손실 : 2.275162153933422\n",
      "배치 인덱스 : 83\t|\t이동 손실 : 2.2761608333814713\n",
      "배치 인덱스 : 84\t|\t이동 손실 : 2.276822132222793\n",
      "배치 인덱스 : 85\t|\t이동 손실 : 2.2731227736140407\n",
      "배치 인덱스 : 86\t|\t이동 손실 : 2.272752690589291\n",
      "배치 인덱스 : 87\t|\t이동 손실 : 2.271659834818407\n",
      "배치 인덱스 : 88\t|\t이동 손실 : 2.2709021059314862\n",
      "배치 인덱스 : 89\t|\t이동 손실 : 2.270629106627571\n",
      "배치 인덱스 : 90\t|\t이동 손실 : 2.269248336226076\n",
      "배치 인덱스 : 91\t|\t이동 손실 : 2.2686497439508857\n",
      "배치 인덱스 : 92\t|\t이동 손실 : 2.2689500213951197\n",
      "배치 인덱스 : 93\t|\t이동 손실 : 2.2695426281462328\n",
      "배치 인덱스 : 94\t|\t이동 손실 : 2.2679525099302595\n",
      "배치 인덱스 : 95\t|\t이동 손실 : 2.2687043795983\n",
      "배치 인덱스 : 96\t|\t이동 손실 : 2.268766688317368\n",
      "배치 인덱스 : 97\t|\t이동 손실 : 2.2678948932764484\n",
      "배치 인덱스 : 98\t|\t이동 손실 : 2.267003447118432\n",
      "배치 인덱스 : 99\t|\t이동 손실 : 2.2674288558959965\n",
      "배치 인덱스 : 100\t|\t이동 손실 : 2.267040018988128\n",
      "배치 인덱스 : 101\t|\t이동 손실 : 2.267286436230529\n",
      "배치 인덱스 : 102\t|\t이동 손실 : 2.266418160744084\n",
      "배치 인덱스 : 103\t|\t이동 손실 : 2.2665595801977014\n",
      "배치 인덱스 : 104\t|\t이동 손실 : 2.2658141613006597\n",
      "배치 인덱스 : 105\t|\t이동 손실 : 2.265817473519524\n",
      "배치 인덱스 : 106\t|\t이동 손실 : 2.2653961582718614\n",
      "배치 인덱스 : 107\t|\t이동 손실 : 2.2644119969120737\n",
      "배치 인덱스 : 108\t|\t이동 손실 : 2.2622382312739666\n",
      "배치 인덱스 : 109\t|\t이동 손실 : 2.261976493488659\n",
      "배치 인덱스 : 110\t|\t이동 손실 : 2.261681015427049\n",
      "배치 인덱스 : 111\t|\t이동 손실 : 2.261099002190999\n",
      "배치 인덱스 : 112\t|\t이동 손실 : 2.2611810148289777\n",
      "배치 인덱스 : 113\t|\t이동 손실 : 2.261542441552146\n",
      "배치 인덱스 : 114\t|\t이동 손실 : 2.2631448144498085\n",
      "배치 인덱스 : 115\t|\t이동 손실 : 2.2607645536291194\n",
      "배치 인덱스 : 116\t|\t이동 손실 : 2.2608615699996304\n",
      "배치 인덱스 : 117\t|\t이동 손실 : 2.2600950002670297\n",
      "배치 인덱스 : 118\t|\t이동 손실 : 2.2595205186795795\n",
      "배치 인덱스 : 119\t|\t이동 손실 : 2.2594742476940164\n",
      "배치 인덱스 : 120\t|\t이동 손실 : 2.2573528802099316\n",
      "배치 인덱스 : 121\t|\t이동 손실 : 2.2575079202651986\n",
      "배치 인덱스 : 122\t|\t이동 손실 : 2.2573376147727666\n",
      "배치 인덱스 : 123\t|\t이동 손실 : 2.257248226673373\n",
      "배치 인덱스 : 124\t|\t이동 손실 : 2.2562346878051764\n",
      "배치 인덱스 : 125\t|\t이동 손실 : 2.255830496076554\n",
      "배치 인덱스 : 126\t|\t이동 손실 : 2.2550882692412135\n",
      "배치 인덱스 : 127\t|\t이동 손실 : 2.254812797531486\n",
      "배치 인덱스 : 128\t|\t이동 손실 : 2.253847776457321\n",
      "배치 인덱스 : 129\t|\t이동 손실 : 2.2519184754445005\n",
      "배치 인덱스 : 130\t|\t이동 손실 : 2.2503945827484135\n",
      "배치 인덱스 : 131\t|\t이동 손실 : 2.250459224888773\n",
      "배치 인덱스 : 132\t|\t이동 손실 : 2.250204421523819\n",
      "배치 인덱스 : 133\t|\t이동 손실 : 2.2507119125394683\n",
      "배치 인덱스 : 134\t|\t이동 손실 : 2.2497474635088888\n",
      "배치 인덱스 : 135\t|\t이동 손실 : 2.2489878938478585\n",
      "배치 인덱스 : 136\t|\t이동 손실 : 2.248433372400103\n",
      "배치 인덱스 : 137\t|\t이동 손실 : 2.2489313751027207\n",
      "배치 인덱스 : 138\t|\t이동 손실 : 2.2481614033952892\n",
      "배치 인덱스 : 139\t|\t이동 손실 : 2.2479452865464347\n",
      "배치 인덱스 : 140\t|\t이동 손실 : 2.246679277284771\n",
      "배치 인덱스 : 141\t|\t이동 손실 : 2.2468256900008297\n",
      "배치 인덱스 : 142\t|\t이동 손실 : 2.2459257599357128\n",
      "배치 인덱스 : 143\t|\t이동 손실 : 2.245117964016067\n",
      "배치 인덱스 : 144\t|\t이동 손실 : 2.2441370865394332\n",
      "배치 인덱스 : 145\t|\t이동 손실 : 2.244684740288617\n",
      "배치 인덱스 : 146\t|\t이동 손실 : 2.2442605754956095\n",
      "배치 인덱스 : 147\t|\t이동 손실 : 2.2443999696422265\n",
      "배치 인덱스 : 148\t|\t이동 손실 : 2.244430751608522\n",
      "배치 인덱스 : 149\t|\t이동 손실 : 2.244394205411275\n",
      "배치 인덱스 : 150\t|\t이동 손실 : 2.2430596367412843\n",
      "배치 인덱스 : 151\t|\t이동 손실 : 2.2425220514598645\n",
      "배치 인덱스 : 152\t|\t이동 손실 : 2.242649781158547\n",
      "배치 인덱스 : 153\t|\t이동 손실 : 2.2428530253373182\n",
      "배치 인덱스 : 154\t|\t이동 손실 : 2.242944583585185\n",
      "배치 인덱스 : 155\t|\t이동 손실 : 2.242657609474964\n",
      "배치 인덱스 : 156\t|\t이동 손실 : 2.2418395744007857\n",
      "배치 인덱스 : 157\t|\t이동 손실 : 2.2422788112978385\n",
      "배치 인덱스 : 158\t|\t이동 손실 : 2.242443107209115\n",
      "배치 인덱스 : 159\t|\t이동 손실 : 2.2417286276817316\n",
      "배치 인덱스 : 160\t|\t이동 손실 : 2.24204341076916\n",
      "배치 인덱스 : 161\t|\t이동 손실 : 2.2416834448590683\n",
      "배치 인덱스 : 162\t|\t이동 손실 : 2.241658456486426\n",
      "배치 인덱스 : 163\t|\t이동 손실 : 2.2405633272194274\n",
      "배치 인덱스 : 164\t|\t이동 손실 : 2.239986945643569\n",
      "배치 인덱스 : 165\t|\t이동 손실 : 2.239469984927809\n",
      "배치 인덱스 : 166\t|\t이동 손실 : 2.2388703851642715\n",
      "배치 인덱스 : 167\t|\t이동 손실 : 2.2392204162620355\n",
      "배치 인덱스 : 168\t|\t이동 손실 : 2.239066710838904\n",
      "배치 인덱스 : 169\t|\t이동 손실 : 2.239143727807437\n",
      "배치 인덱스 : 170\t|\t이동 손실 : 2.239213108319287\n",
      "배치 인덱스 : 171\t|\t이동 손실 : 2.2392705110616453\n",
      "배치 인덱스 : 172\t|\t이동 손실 : 2.239176832871629\n",
      "배치 인덱스 : 173\t|\t이동 손실 : 2.2384589800889456\n",
      "배치 인덱스 : 174\t|\t이동 손실 : 2.2374572263445165\n",
      "배치 인덱스 : 175\t|\t이동 손실 : 2.2375047748739063\n",
      "배치 인덱스 : 176\t|\t이동 손실 : 2.2367843732995496\n",
      "배치 인덱스 : 177\t|\t이동 손실 : 2.2369519806979743\n",
      "배치 인덱스 : 178\t|\t이동 손실 : 2.2364382117820183\n",
      "배치 인덱스 : 179\t|\t이동 손실 : 2.236238086223602\n",
      "배치 인덱스 : 180\t|\t이동 손실 : 2.2354170736028345\n",
      "배치 인덱스 : 181\t|\t이동 손실 : 2.2355745480610776\n",
      "배치 인덱스 : 182\t|\t이동 손실 : 2.2352334827673244\n",
      "배치 인덱스 : 183\t|\t이동 손실 : 2.234996329183164\n",
      "배치 인덱스 : 184\t|\t이동 손실 : 2.2340261755762874\n",
      "배치 인덱스 : 185\t|\t이동 손실 : 2.233016125617489\n",
      "배치 인덱스 : 186\t|\t이동 손실 : 2.232270732920438\n",
      "배치 인덱스 : 187\t|\t이동 손실 : 2.232635286260159\n",
      "배치 인덱스 : 188\t|\t이동 손실 : 2.232486761436261\n",
      "배치 인덱스 : 189\t|\t이동 손실 : 2.2318932671295975\n",
      "배치 인덱스 : 190\t|\t이동 손실 : 2.2316278737252926\n",
      "배치 인덱스 : 191\t|\t이동 손실 : 2.2305187135934834\n",
      "배치 인덱스 : 192\t|\t이동 손실 : 2.229156381107983\n",
      "배치 인덱스 : 193\t|\t이동 손실 : 2.228033865235516\n",
      "배치 인덱스 : 194\t|\t이동 손실 : 2.22805002347017\n",
      "배치 인덱스 : 195\t|\t이동 손실 : 2.2271642386913304\n",
      "배치 인덱스 : 196\t|\t이동 손실 : 2.2270426247930772\n",
      "배치 인덱스 : 197\t|\t이동 손실 : 2.2260108662374094\n",
      "배치 인덱스 : 198\t|\t이동 손실 : 2.226248376333534\n",
      "배치 인덱스 : 199\t|\t이동 손실 : 2.225753378272057\n",
      "배치 인덱스 : 200\t|\t이동 손실 : 2.224852763005157\n",
      "배치 인덱스 : 201\t|\t이동 손실 : 2.224245627917866\n",
      "배치 인덱스 : 202\t|\t이동 손실 : 2.2245964587028393\n",
      "배치 인덱스 : 203\t|\t이동 손실 : 2.2251300969544583\n",
      "배치 인덱스 : 204\t|\t이동 손실 : 2.2242725354869197\n",
      "배치 인덱스 : 205\t|\t이동 손실 : 2.223436717269491\n",
      "배치 인덱스 : 206\t|\t이동 손실 : 2.2230111061086983\n",
      "배치 인덱스 : 207\t|\t이동 손실 : 2.2226558310481224\n",
      "배치 인덱스 : 208\t|\t이동 손실 : 2.2218247366864152\n",
      "배치 인덱스 : 209\t|\t이동 손실 : 2.220933045092084\n",
      "배치 인덱스 : 210\t|\t이동 손실 : 2.2205513614048895\n",
      "배치 인덱스 : 211\t|\t이동 손실 : 2.220011989463051\n",
      "배치 인덱스 : 212\t|\t이동 손실 : 2.2186903942358893\n",
      "배치 인덱스 : 213\t|\t이동 손실 : 2.2178299137365047\n",
      "배치 인덱스 : 214\t|\t이동 손실 : 2.21761187841726\n",
      "배치 인덱스 : 215\t|\t이동 손실 : 2.2164986928304047\n",
      "배치 인덱스 : 216\t|\t이동 손실 : 2.2156431960620098\n",
      "배치 인덱스 : 217\t|\t이동 손실 : 2.2150769255576885\n",
      "배치 인덱스 : 218\t|\t이동 손실 : 2.2145582813106177\n",
      "배치 인덱스 : 219\t|\t이동 손실 : 2.2145430597392\n",
      "배치 인덱스 : 220\t|\t이동 손실 : 2.2145097892208883\n",
      "배치 인덱스 : 221\t|\t이동 손실 : 2.213857140626994\n",
      "배치 인덱스 : 222\t|\t이동 손실 : 2.2139361898995307\n",
      "배치 인덱스 : 223\t|\t이동 손실 : 2.2136019766330723\n",
      "배치 인덱스 : 224\t|\t이동 손실 : 2.2131423430972634\n",
      "배치 인덱스 : 225\t|\t이동 손실 : 2.2129496251587324\n",
      "배치 인덱스 : 226\t|\t이동 손실 : 2.2121889517695896\n",
      "Epoch: 03 | Time: 14m 25s\n",
      "\tTrain Loss: 2.212 | Train PPL: 9.136\n",
      "\tValidation Loss: 2.022 | Validation PPL: 7.550\n",
      "에폭 : 3\n",
      "배치 인덱스 : 0\t|\t이동 손실 : 1.8997366428375244\n",
      "배치 인덱스 : 1\t|\t이동 손실 : 1.8497707843780518\n",
      "배치 인덱스 : 2\t|\t이동 손실 : 1.8500664234161377\n",
      "배치 인덱스 : 3\t|\t이동 손실 : 1.8828740417957306\n",
      "배치 인덱스 : 4\t|\t이동 손실 : 1.8821055173873902\n",
      "배치 인덱스 : 5\t|\t이동 손실 : 1.8987760941187541\n",
      "배치 인덱스 : 6\t|\t이동 손실 : 1.8959809030805317\n",
      "배치 인덱스 : 7\t|\t이동 손실 : 1.9050845652818682\n",
      "배치 인덱스 : 8\t|\t이동 손실 : 1.9055636458926732\n",
      "배치 인덱스 : 9\t|\t이동 손실 : 1.9085599303245546\n",
      "배치 인덱스 : 10\t|\t이동 손실 : 1.9065901366147129\n",
      "배치 인덱스 : 11\t|\t이동 손실 : 1.8982504506905875\n",
      "배치 인덱스 : 12\t|\t이동 손실 : 1.8887680768966677\n",
      "배치 인덱스 : 13\t|\t이동 손실 : 1.8863817197935924\n",
      "배치 인덱스 : 14\t|\t이동 손실 : 1.8904109557469688\n",
      "배치 인덱스 : 15\t|\t이동 손실 : 1.888656944036484\n",
      "배치 인덱스 : 16\t|\t이동 손실 : 1.891004884944243\n",
      "배치 인덱스 : 17\t|\t이동 손실 : 1.8922729094823205\n",
      "배치 인덱스 : 18\t|\t이동 손실 : 1.8901317684273975\n",
      "배치 인덱스 : 19\t|\t이동 손실 : 1.8974524557590489\n",
      "배치 인덱스 : 20\t|\t이동 손실 : 1.896882948421297\n",
      "배치 인덱스 : 21\t|\t이동 손실 : 1.902634290131656\n",
      "배치 인덱스 : 22\t|\t이동 손실 : 1.911780714988709\n",
      "배치 인덱스 : 23\t|\t이동 손실 : 1.9125143289566044\n",
      "배치 인덱스 : 24\t|\t이동 손실 : 1.9057878780364994\n",
      "배치 인덱스 : 25\t|\t이동 손실 : 1.9031788156582763\n",
      "배치 인덱스 : 26\t|\t이동 손실 : 1.9051990244123675\n",
      "배치 인덱스 : 27\t|\t이동 손실 : 1.903632474797113\n",
      "배치 인덱스 : 28\t|\t이동 손실 : 1.9070046729054948\n",
      "배치 인덱스 : 29\t|\t이동 손실 : 1.8999855955441796\n",
      "배치 인덱스 : 30\t|\t이동 손실 : 1.8980336727634555\n",
      "배치 인덱스 : 31\t|\t이동 손실 : 1.9000071957707407\n",
      "배치 인덱스 : 32\t|\t이동 손실 : 1.898541204857104\n",
      "배치 인덱스 : 33\t|\t이동 손실 : 1.8978309771593882\n",
      "배치 인덱스 : 34\t|\t이동 손실 : 1.9001140049525673\n",
      "배치 인덱스 : 35\t|\t이동 손실 : 1.9015934367974603\n",
      "배치 인덱스 : 36\t|\t이동 손실 : 1.9030868137204973\n",
      "배치 인덱스 : 37\t|\t이동 손실 : 1.901277607993076\n",
      "배치 인덱스 : 38\t|\t이동 손실 : 1.9013479061615775\n",
      "배치 인덱스 : 39\t|\t이동 손실 : 1.899404537677765\n",
      "배치 인덱스 : 40\t|\t이동 손실 : 1.9000761421715342\n",
      "배치 인덱스 : 41\t|\t이동 손실 : 1.8988297808737984\n",
      "배치 인덱스 : 42\t|\t이동 손실 : 1.8988186620002572\n",
      "배치 인덱스 : 43\t|\t이동 손실 : 1.8978317759253764\n",
      "배치 인덱스 : 44\t|\t이동 손실 : 1.895446594556173\n",
      "배치 인덱스 : 45\t|\t이동 손실 : 1.893441358338232\n",
      "배치 인덱스 : 46\t|\t이동 손실 : 1.8922240987737131\n",
      "배치 인덱스 : 47\t|\t이동 손실 : 1.892517353097598\n",
      "배치 인덱스 : 48\t|\t이동 손실 : 1.8920514461945517\n",
      "배치 인덱스 : 49\t|\t이동 손실 : 1.893510036468506\n",
      "배치 인덱스 : 50\t|\t이동 손실 : 1.8961898672814463\n",
      "배치 인덱스 : 51\t|\t이동 손실 : 1.8972515716002538\n",
      "배치 인덱스 : 52\t|\t이동 손실 : 1.8988765658072706\n",
      "배치 인덱스 : 53\t|\t이동 손실 : 1.9004373108899153\n",
      "배치 인덱스 : 54\t|\t이동 손실 : 1.8995075485923074\n",
      "배치 인덱스 : 55\t|\t이동 손실 : 1.8998421047415053\n",
      "배치 인덱스 : 56\t|\t이동 손실 : 1.899172109470033\n",
      "배치 인덱스 : 57\t|\t이동 손실 : 1.8982403997717234\n",
      "배치 인덱스 : 58\t|\t이동 손실 : 1.896210205757012\n",
      "배치 인덱스 : 59\t|\t이동 손실 : 1.8963776846726739\n",
      "배치 인덱스 : 60\t|\t이동 손실 : 1.8977668109487318\n",
      "배치 인덱스 : 61\t|\t이동 손실 : 1.8996327942417517\n",
      "배치 인덱스 : 62\t|\t이동 손실 : 1.901526108620659\n",
      "배치 인덱스 : 63\t|\t이동 손실 : 1.8992641028016808\n",
      "배치 인덱스 : 64\t|\t이동 손실 : 1.9004075783949634\n",
      "배치 인덱스 : 65\t|\t이동 손실 : 1.900252598704714\n",
      "배치 인덱스 : 66\t|\t이동 손실 : 1.9000855506356087\n",
      "배치 인덱스 : 67\t|\t이동 손실 : 1.8999994397163396\n",
      "배치 인덱스 : 68\t|\t이동 손실 : 1.8988250476726591\n",
      "배치 인덱스 : 69\t|\t이동 손실 : 1.8978256293705535\n",
      "배치 인덱스 : 70\t|\t이동 손실 : 1.8977842834633845\n",
      "배치 인덱스 : 71\t|\t이동 손실 : 1.8993192646238544\n",
      "배치 인덱스 : 72\t|\t이동 손실 : 1.8997563368653603\n",
      "배치 인덱스 : 73\t|\t이동 손실 : 1.8993592101174437\n",
      "배치 인덱스 : 74\t|\t이동 손실 : 1.898346950213115\n",
      "배치 인덱스 : 75\t|\t이동 손실 : 1.899184311691084\n",
      "배치 인덱스 : 76\t|\t이동 손실 : 1.9000043652274399\n",
      "배치 인덱스 : 77\t|\t이동 손실 : 1.900717926331056\n",
      "배치 인덱스 : 78\t|\t이동 손실 : 1.9005989424790015\n",
      "배치 인덱스 : 79\t|\t이동 손실 : 1.9001768603920943\n",
      "배치 인덱스 : 80\t|\t이동 손실 : 1.8995280766192784\n",
      "배치 인덱스 : 81\t|\t이동 손실 : 1.9004780097705567\n",
      "배치 인덱스 : 82\t|\t이동 손실 : 1.900314569473267\n",
      "배치 인덱스 : 83\t|\t이동 손실 : 1.899606205168225\n",
      "배치 인덱스 : 84\t|\t이동 손실 : 1.8979261440389301\n",
      "배치 인덱스 : 85\t|\t이동 손실 : 1.8976551335911422\n",
      "배치 인덱스 : 86\t|\t이동 손실 : 1.8970149906202298\n",
      "배치 인덱스 : 87\t|\t이동 손실 : 1.898346527056261\n",
      "배치 인덱스 : 88\t|\t이동 손실 : 1.8976194898733936\n",
      "배치 인덱스 : 89\t|\t이동 손실 : 1.8974956817097137\n",
      "배치 인덱스 : 90\t|\t이동 손실 : 1.8981062226243075\n",
      "배치 인덱스 : 91\t|\t이동 손실 : 1.897374519835348\n",
      "배치 인덱스 : 92\t|\t이동 손실 : 1.8960638507719965\n",
      "배치 인덱스 : 93\t|\t이동 손실 : 1.8957536157141341\n",
      "배치 인덱스 : 94\t|\t이동 손실 : 1.8954918484938772\n",
      "배치 인덱스 : 95\t|\t이동 손실 : 1.8947525521119435\n",
      "배치 인덱스 : 96\t|\t이동 손실 : 1.8947653622971368\n",
      "배치 인덱스 : 97\t|\t이동 손실 : 1.8936772030227038\n",
      "배치 인덱스 : 98\t|\t이동 손실 : 1.892883757148126\n",
      "배치 인덱스 : 99\t|\t이동 손실 : 1.8928410971164702\n",
      "배치 인덱스 : 100\t|\t이동 손실 : 1.8932003018879653\n",
      "배치 인덱스 : 101\t|\t이동 손실 : 1.8936917816891388\n",
      "배치 인덱스 : 102\t|\t이동 손실 : 1.8944253377544067\n",
      "배치 인덱스 : 103\t|\t이동 손실 : 1.8945846202281802\n",
      "배치 인덱스 : 104\t|\t이동 손실 : 1.8944434824443996\n",
      "배치 인덱스 : 105\t|\t이동 손실 : 1.8931737654613996\n",
      "배치 인덱스 : 106\t|\t이동 손실 : 1.8934863805770872\n",
      "배치 인덱스 : 107\t|\t이동 손실 : 1.8923132783836787\n",
      "배치 인덱스 : 108\t|\t이동 손실 : 1.8919227976317798\n",
      "배치 인덱스 : 109\t|\t이동 손실 : 1.8917534416372124\n",
      "배치 인덱스 : 110\t|\t이동 손실 : 1.891103807870332\n",
      "배치 인덱스 : 111\t|\t이동 손실 : 1.8904884180852342\n",
      "배치 인덱스 : 112\t|\t이동 손실 : 1.890320859124175\n",
      "배치 인덱스 : 113\t|\t이동 손실 : 1.8904742096599776\n",
      "배치 인덱스 : 114\t|\t이동 손실 : 1.890263528409211\n",
      "배치 인덱스 : 115\t|\t이동 손실 : 1.8902806547181354\n",
      "배치 인덱스 : 116\t|\t이동 손실 : 1.8913800604323032\n",
      "배치 인덱스 : 117\t|\t이동 손실 : 1.8917879906751338\n",
      "배치 인덱스 : 118\t|\t이동 손실 : 1.8916221877106094\n",
      "배치 인덱스 : 119\t|\t이동 손실 : 1.8909177800019579\n",
      "배치 인덱스 : 120\t|\t이동 손실 : 1.8897008797353947\n",
      "배치 인덱스 : 121\t|\t이동 손실 : 1.8889122673722563\n",
      "배치 인덱스 : 122\t|\t이동 손실 : 1.887986286868894\n",
      "배치 인덱스 : 123\t|\t이동 손실 : 1.8883787970389088\n",
      "배치 인덱스 : 124\t|\t이동 손실 : 1.8872113914489745\n",
      "배치 인덱스 : 125\t|\t이동 손실 : 1.8876546772699507\n",
      "배치 인덱스 : 126\t|\t이동 손실 : 1.8877844660300909\n",
      "배치 인덱스 : 127\t|\t이동 손실 : 1.888764588162303\n",
      "배치 인덱스 : 128\t|\t이동 손실 : 1.88832603868588\n",
      "배치 인덱스 : 129\t|\t이동 손실 : 1.8880997410187355\n",
      "배치 인덱스 : 130\t|\t이동 손실 : 1.8876897542531255\n",
      "배치 인덱스 : 131\t|\t이동 손실 : 1.8877023675224998\n",
      "배치 인덱스 : 132\t|\t이동 손실 : 1.8875726362816374\n",
      "배치 인덱스 : 133\t|\t이동 손실 : 1.8878302511884206\n",
      "배치 인덱스 : 134\t|\t이동 손실 : 1.8873430622948542\n",
      "배치 인덱스 : 135\t|\t이동 손실 : 1.8877639060511309\n",
      "배치 인덱스 : 136\t|\t이동 손실 : 1.8875280897112658\n",
      "배치 인덱스 : 137\t|\t이동 손실 : 1.8875406315361245\n",
      "배치 인덱스 : 138\t|\t이동 손실 : 1.8876158127681815\n",
      "배치 인덱스 : 139\t|\t이동 손실 : 1.8867476991244725\n",
      "배치 인덱스 : 140\t|\t이동 손실 : 1.886017456122324\n",
      "배치 인덱스 : 141\t|\t이동 손실 : 1.8865524563990848\n",
      "배치 인덱스 : 142\t|\t이동 손실 : 1.8857713037437491\n",
      "배치 인덱스 : 143\t|\t이동 손실 : 1.8852271975742445\n",
      "배치 인덱스 : 144\t|\t이동 손실 : 1.8844845566256292\n",
      "배치 인덱스 : 145\t|\t이동 손실 : 1.8844808895293979\n",
      "배치 인덱스 : 146\t|\t이동 손실 : 1.8839991400841951\n",
      "배치 인덱스 : 147\t|\t이동 손실 : 1.884694470747097\n",
      "배치 인덱스 : 148\t|\t이동 손실 : 1.8848025870803218\n",
      "배치 인덱스 : 149\t|\t이동 손실 : 1.8844009288152057\n",
      "배치 인덱스 : 150\t|\t이동 손실 : 1.8841316699981687\n",
      "배치 인덱스 : 151\t|\t이동 손실 : 1.8842469555766956\n",
      "배치 인덱스 : 152\t|\t이동 손실 : 1.8832892405441382\n",
      "배치 인덱스 : 153\t|\t이동 손실 : 1.8836026958056857\n",
      "배치 인덱스 : 154\t|\t이동 손실 : 1.8830050522281276\n",
      "배치 인덱스 : 155\t|\t이동 손실 : 1.8826496562896629\n",
      "배치 인덱스 : 156\t|\t이동 손실 : 1.8821941507849722\n",
      "배치 인덱스 : 157\t|\t이동 손실 : 1.882973365391357\n",
      "배치 인덱스 : 158\t|\t이동 손실 : 1.8828994770469905\n",
      "배치 인덱스 : 159\t|\t이동 손실 : 1.8823493823409079\n",
      "배치 인덱스 : 160\t|\t이동 손실 : 1.8823999603342565\n",
      "배치 인덱스 : 161\t|\t이동 손실 : 1.8822103856522359\n",
      "배치 인덱스 : 162\t|\t이동 손실 : 1.8820845020329293\n",
      "배치 인덱스 : 163\t|\t이동 손실 : 1.8823364515130112\n",
      "배치 인덱스 : 164\t|\t이동 손실 : 1.8822137507525356\n",
      "배치 인덱스 : 165\t|\t이동 손실 : 1.882406872439097\n",
      "배치 인덱스 : 166\t|\t이동 손실 : 1.8820053317589671\n",
      "배치 인덱스 : 167\t|\t이동 손실 : 1.8810113902602874\n",
      "배치 인덱스 : 168\t|\t이동 손실 : 1.8810681584318711\n",
      "배치 인덱스 : 169\t|\t이동 손실 : 1.8808483846047344\n",
      "배치 인덱스 : 170\t|\t이동 손실 : 1.8810120960425214\n",
      "배치 인덱스 : 171\t|\t이동 손실 : 1.8810886865438416\n",
      "배치 인덱스 : 172\t|\t이동 손실 : 1.8818410958857894\n",
      "배치 인덱스 : 173\t|\t이동 손실 : 1.8820524914511318\n",
      "배치 인덱스 : 174\t|\t이동 손실 : 1.8824461732591902\n",
      "배치 인덱스 : 175\t|\t이동 손실 : 1.882193301211704\n",
      "배치 인덱스 : 176\t|\t이동 손실 : 1.8818865138932137\n",
      "배치 인덱스 : 177\t|\t이동 손실 : 1.8819080745236259\n",
      "배치 인덱스 : 178\t|\t이동 손실 : 1.8821037654770154\n",
      "배치 인덱스 : 179\t|\t이동 손실 : 1.882682608233558\n",
      "배치 인덱스 : 180\t|\t이동 손실 : 1.882194106750067\n",
      "배치 인덱스 : 181\t|\t이동 손실 : 1.881357197578137\n",
      "배치 인덱스 : 182\t|\t이동 손실 : 1.8813666958626505\n",
      "배치 인덱스 : 183\t|\t이동 손실 : 1.8809085941833001\n",
      "배치 인덱스 : 184\t|\t이동 손실 : 1.8796961803694032\n",
      "배치 인덱스 : 185\t|\t이동 손실 : 1.8797569627402935\n",
      "배치 인덱스 : 186\t|\t이동 손실 : 1.8793505723463664\n",
      "배치 인덱스 : 187\t|\t이동 손실 : 1.8787560450269825\n",
      "배치 인덱스 : 188\t|\t이동 손실 : 1.8781487424537622\n",
      "배치 인덱스 : 189\t|\t이동 손실 : 1.877482522788801\n",
      "배치 인덱스 : 190\t|\t이동 손실 : 1.877605628592806\n",
      "배치 인덱스 : 191\t|\t이동 손실 : 1.8768843983610475\n",
      "배치 인덱스 : 192\t|\t이동 손실 : 1.8774085829295029\n",
      "배치 인덱스 : 193\t|\t이동 손실 : 1.8771448749856854\n",
      "배치 인덱스 : 194\t|\t이동 손실 : 1.8768590517533135\n",
      "배치 인덱스 : 195\t|\t이동 손실 : 1.876887104949173\n",
      "배치 인덱스 : 196\t|\t이동 손실 : 1.8766149094867226\n",
      "배치 인덱스 : 197\t|\t이동 손실 : 1.8760481043295432\n",
      "배치 인덱스 : 198\t|\t이동 손실 : 1.8759371371724503\n",
      "배치 인덱스 : 199\t|\t이동 손실 : 1.875350648760796\n",
      "배치 인덱스 : 200\t|\t이동 손실 : 1.8752287199248134\n",
      "배치 인덱스 : 201\t|\t이동 손실 : 1.8750570021053357\n",
      "배치 인덱스 : 202\t|\t이동 손실 : 1.8739699101800407\n",
      "배치 인덱스 : 203\t|\t이동 손실 : 1.8734376734378295\n",
      "배치 인덱스 : 204\t|\t이동 손실 : 1.8732401301221153\n",
      "배치 인덱스 : 205\t|\t이동 손실 : 1.872538335693693\n",
      "배치 인덱스 : 206\t|\t이동 손실 : 1.87255338827769\n",
      "배치 인덱스 : 207\t|\t이동 손실 : 1.8725762052031667\n",
      "배치 인덱스 : 208\t|\t이동 손실 : 1.8725096335251368\n",
      "배치 인덱스 : 209\t|\t이동 손실 : 1.8732996066411338\n",
      "배치 인덱스 : 210\t|\t이동 손실 : 1.8732133612248572\n",
      "배치 인덱스 : 211\t|\t이동 손실 : 1.8729828753561346\n",
      "배치 인덱스 : 212\t|\t이동 손실 : 1.8728425301296612\n",
      "배치 인덱스 : 213\t|\t이동 손실 : 1.8730650995379299\n",
      "배치 인덱스 : 214\t|\t이동 손실 : 1.8732866481293082\n",
      "배치 인덱스 : 215\t|\t이동 손실 : 1.8731982994962624\n",
      "배치 인덱스 : 216\t|\t이동 손실 : 1.8728301470180813\n",
      "배치 인덱스 : 217\t|\t이동 손실 : 1.872463618943451\n",
      "배치 인덱스 : 218\t|\t이동 손실 : 1.8727721422230275\n",
      "배치 인덱스 : 219\t|\t이동 손실 : 1.872540598565882\n",
      "배치 인덱스 : 220\t|\t이동 손실 : 1.8723012732164894\n",
      "배치 인덱스 : 221\t|\t이동 손실 : 1.872169326017569\n",
      "배치 인덱스 : 222\t|\t이동 손실 : 1.872844380648147\n",
      "배치 인덱스 : 223\t|\t이동 손실 : 1.8731307999363969\n",
      "배치 인덱스 : 224\t|\t이동 손실 : 1.8728361882103814\n",
      "배치 인덱스 : 225\t|\t이동 손실 : 1.8726626154595771\n",
      "배치 인덱스 : 226\t|\t이동 손실 : 1.872140837135819\n",
      "Epoch: 04 | Time: 14m 12s\n",
      "\tTrain Loss: 1.872 | Train PPL: 6.502\n",
      "\tValidation Loss: 1.865 | Validation PPL: 6.456\n",
      "에폭 : 4\n",
      "배치 인덱스 : 0\t|\t이동 손실 : 1.7100690603256226\n",
      "배치 인덱스 : 1\t|\t이동 손실 : 1.6738075613975525\n",
      "배치 인덱스 : 2\t|\t이동 손실 : 1.634250322977702\n",
      "배치 인덱스 : 3\t|\t이동 손실 : 1.6005754172801971\n",
      "배치 인덱스 : 4\t|\t이동 손실 : 1.6151999950408935\n",
      "배치 인덱스 : 5\t|\t이동 손실 : 1.606169601281484\n",
      "배치 인덱스 : 6\t|\t이동 손실 : 1.599292857306344\n",
      "배치 인덱스 : 7\t|\t이동 손실 : 1.6209018379449844\n",
      "배치 인덱스 : 8\t|\t이동 손실 : 1.6199943489498563\n",
      "배치 인덱스 : 9\t|\t이동 손실 : 1.6124628067016602\n",
      "배치 인덱스 : 10\t|\t이동 손실 : 1.6126086495139382\n",
      "배치 인덱스 : 11\t|\t이동 손실 : 1.6136230031649272\n",
      "배치 인덱스 : 12\t|\t이동 손실 : 1.623115530380836\n",
      "배치 인덱스 : 13\t|\t이동 손실 : 1.6212385381971088\n",
      "배치 인덱스 : 14\t|\t이동 손실 : 1.6321558952331545\n",
      "배치 인덱스 : 15\t|\t이동 손실 : 1.6320034489035609\n",
      "배치 인덱스 : 16\t|\t이동 손실 : 1.6293755208744725\n",
      "배치 인덱스 : 17\t|\t이동 손실 : 1.6296760638554892\n",
      "배치 인덱스 : 18\t|\t이동 손실 : 1.6291316810407137\n",
      "배치 인덱스 : 19\t|\t이동 손실 : 1.6299237072467805\n",
      "배치 인덱스 : 20\t|\t이동 손실 : 1.6290147361301242\n",
      "배치 인덱스 : 21\t|\t이동 손실 : 1.6319356127218767\n",
      "배치 인덱스 : 22\t|\t이동 손실 : 1.6361616435258286\n",
      "배치 인덱스 : 23\t|\t이동 손실 : 1.6327762206395469\n",
      "배치 인덱스 : 24\t|\t이동 손실 : 1.6365441608428957\n",
      "배치 인덱스 : 25\t|\t이동 손실 : 1.631999685214116\n",
      "배치 인덱스 : 26\t|\t이동 손실 : 1.6329193689205028\n",
      "배치 인덱스 : 27\t|\t이동 손실 : 1.631522761923926\n",
      "배치 인덱스 : 28\t|\t이동 손실 : 1.6361610272835039\n",
      "배치 인덱스 : 29\t|\t이동 손실 : 1.6403962771097818\n",
      "배치 인덱스 : 30\t|\t이동 손실 : 1.6407951731835642\n",
      "배치 인덱스 : 31\t|\t이동 손실 : 1.637797500938177\n",
      "배치 인덱스 : 32\t|\t이동 손실 : 1.6350718881144668\n",
      "배치 인덱스 : 33\t|\t이동 손실 : 1.6368594765663147\n",
      "배치 인덱스 : 34\t|\t이동 손실 : 1.638201185635158\n",
      "배치 인덱스 : 35\t|\t이동 손실 : 1.6403379440307617\n",
      "배치 인덱스 : 36\t|\t이동 손실 : 1.6398294133109015\n",
      "배치 인덱스 : 37\t|\t이동 손실 : 1.6401039707033258\n",
      "배치 인덱스 : 38\t|\t이동 손실 : 1.6378634648445325\n",
      "배치 인덱스 : 39\t|\t이동 손실 : 1.6372630774974823\n",
      "배치 인덱스 : 40\t|\t이동 손실 : 1.6365624346384189\n",
      "배치 인덱스 : 41\t|\t이동 손실 : 1.6343630807740348\n",
      "배치 인덱스 : 42\t|\t이동 손실 : 1.633326347484145\n",
      "배치 인덱스 : 43\t|\t이동 손실 : 1.6313756731423465\n",
      "배치 인덱스 : 44\t|\t이동 손실 : 1.633381043540107\n",
      "배치 인덱스 : 45\t|\t이동 손실 : 1.6313024837037793\n",
      "배치 인덱스 : 46\t|\t이동 손실 : 1.6317084292148023\n",
      "배치 인덱스 : 47\t|\t이동 손실 : 1.632333184281985\n",
      "배치 인덱스 : 48\t|\t이동 손실 : 1.6307688513580634\n",
      "배치 인덱스 : 49\t|\t이동 손실 : 1.6332075595855713\n",
      "배치 인덱스 : 50\t|\t이동 손실 : 1.637025187997257\n",
      "배치 인덱스 : 51\t|\t이동 손실 : 1.6380577041552618\n",
      "배치 인덱스 : 52\t|\t이동 손실 : 1.6386329273007951\n",
      "배치 인덱스 : 53\t|\t이동 손실 : 1.6377202250339367\n",
      "배치 인덱스 : 54\t|\t이동 손실 : 1.6369301449168812\n",
      "배치 인덱스 : 55\t|\t이동 손실 : 1.6365687421389987\n",
      "배치 인덱스 : 56\t|\t이동 손실 : 1.6352273581320778\n",
      "배치 인덱스 : 57\t|\t이동 손실 : 1.6347048632029828\n",
      "배치 인덱스 : 58\t|\t이동 손실 : 1.6343878830893563\n",
      "배치 인덱스 : 59\t|\t이동 손실 : 1.6356466551621753\n",
      "배치 인덱스 : 60\t|\t이동 손실 : 1.6351960115745419\n",
      "배치 인덱스 : 61\t|\t이동 손실 : 1.6366939563905039\n",
      "배치 인덱스 : 62\t|\t이동 손실 : 1.6341162938920277\n",
      "배치 인덱스 : 63\t|\t이동 손실 : 1.6333488933742046\n",
      "배치 인덱스 : 64\t|\t이동 손실 : 1.6320874837728647\n",
      "배치 인덱스 : 65\t|\t이동 손실 : 1.6332071405468565\n",
      "배치 인덱스 : 66\t|\t이동 손실 : 1.633090086837313\n",
      "배치 인덱스 : 67\t|\t이동 손실 : 1.633055313545115\n",
      "배치 인덱스 : 68\t|\t이동 손실 : 1.6341309098229893\n",
      "배치 인덱스 : 69\t|\t이동 손실 : 1.632531554358346\n",
      "배치 인덱스 : 70\t|\t이동 손실 : 1.633874324006094\n",
      "배치 인덱스 : 71\t|\t이동 손실 : 1.6334975974427328\n",
      "배치 인덱스 : 72\t|\t이동 손실 : 1.6345011224485422\n",
      "배치 인덱스 : 73\t|\t이동 손실 : 1.6336406050501642\n",
      "배치 인덱스 : 74\t|\t이동 손실 : 1.6344726308186848\n",
      "배치 인덱스 : 75\t|\t이동 손실 : 1.6338878964122971\n",
      "배치 인덱스 : 76\t|\t이동 손실 : 1.6338956866945538\n",
      "배치 인덱스 : 77\t|\t이동 손실 : 1.6331880979048898\n",
      "배치 인덱스 : 78\t|\t이동 손실 : 1.6325581254838386\n",
      "배치 인덱스 : 79\t|\t이동 손실 : 1.6340807259082792\n",
      "배치 인덱스 : 80\t|\t이동 손실 : 1.634713702731662\n",
      "배치 인덱스 : 81\t|\t이동 손실 : 1.6343501021222369\n",
      "배치 인덱스 : 82\t|\t이동 손실 : 1.6350051351340418\n",
      "배치 인덱스 : 83\t|\t이동 손실 : 1.6357654035091398\n",
      "배치 인덱스 : 84\t|\t이동 손실 : 1.6364452670602234\n",
      "배치 인덱스 : 85\t|\t이동 손실 : 1.6365894411885458\n",
      "배치 인덱스 : 86\t|\t이동 손실 : 1.6378357204897647\n",
      "배치 인덱스 : 87\t|\t이동 손실 : 1.636487168344584\n",
      "배치 인덱스 : 88\t|\t이동 손실 : 1.6368549579984684\n",
      "배치 인덱스 : 89\t|\t이동 손실 : 1.6374742931789819\n",
      "배치 인덱스 : 90\t|\t이동 손실 : 1.6384878734965898\n",
      "배치 인덱스 : 91\t|\t이동 손실 : 1.639176767805348\n",
      "배치 인덱스 : 92\t|\t이동 손실 : 1.6383762000709448\n",
      "배치 인덱스 : 93\t|\t이동 손실 : 1.6388042011159527\n",
      "배치 인덱스 : 94\t|\t이동 손실 : 1.6376039994390383\n",
      "배치 인덱스 : 95\t|\t이동 손실 : 1.6361960656940933\n",
      "배치 인덱스 : 96\t|\t이동 손실 : 1.6355230550176085\n",
      "배치 인덱스 : 97\t|\t이동 손실 : 1.635050233529538\n",
      "배치 인덱스 : 98\t|\t이동 손실 : 1.6349132723278466\n",
      "배치 인덱스 : 99\t|\t이동 손실 : 1.634508086442947\n",
      "배치 인덱스 : 100\t|\t이동 손실 : 1.6336129490691833\n",
      "배치 인덱스 : 101\t|\t이동 손실 : 1.6345429373722447\n",
      "배치 인덱스 : 102\t|\t이동 손실 : 1.6343679694296083\n",
      "배치 인덱스 : 103\t|\t이동 손실 : 1.6352177078907302\n",
      "배치 인덱스 : 104\t|\t이동 손실 : 1.6348596334457393\n",
      "배치 인덱스 : 105\t|\t이동 손실 : 1.6359752798980132\n",
      "배치 인덱스 : 106\t|\t이동 손실 : 1.6363566645952023\n",
      "배치 인덱스 : 107\t|\t이동 손실 : 1.6360280259891788\n",
      "배치 인덱스 : 108\t|\t이동 손실 : 1.6359011536344472\n",
      "배치 인덱스 : 109\t|\t이동 손실 : 1.6358346494761378\n",
      "배치 인덱스 : 110\t|\t이동 손실 : 1.6360047937513469\n",
      "배치 인덱스 : 111\t|\t이동 손실 : 1.635539213461535\n",
      "배치 인덱스 : 112\t|\t이동 손실 : 1.6356045503531933\n",
      "배치 인덱스 : 113\t|\t이동 손실 : 1.6345875566465808\n",
      "배치 인덱스 : 114\t|\t이동 손실 : 1.6346031437749444\n",
      "배치 인덱스 : 115\t|\t이동 손실 : 1.6343134096984202\n",
      "배치 인덱스 : 116\t|\t이동 손실 : 1.6343097839599998\n",
      "배치 인덱스 : 117\t|\t이동 손실 : 1.633890563148563\n",
      "배치 인덱스 : 118\t|\t이동 손실 : 1.634466880509833\n",
      "배치 인덱스 : 119\t|\t이동 손실 : 1.6354666312535602\n",
      "배치 인덱스 : 120\t|\t이동 손실 : 1.6347141364389213\n",
      "배치 인덱스 : 121\t|\t이동 손실 : 1.635795709539632\n",
      "배치 인덱스 : 122\t|\t이동 손실 : 1.6354578151935482\n",
      "배치 인덱스 : 123\t|\t이동 손실 : 1.63378398072335\n",
      "배치 인덱스 : 124\t|\t이동 손실 : 1.6343961915969847\n",
      "배치 인덱스 : 125\t|\t이동 손실 : 1.6336715675535654\n",
      "배치 인덱스 : 126\t|\t이동 손실 : 1.6336596565922412\n",
      "배치 인덱스 : 127\t|\t이동 손실 : 1.633519331924617\n",
      "배치 인덱스 : 128\t|\t이동 손실 : 1.6337344701900036\n",
      "배치 인덱스 : 129\t|\t이동 손실 : 1.6337209683198193\n",
      "배치 인덱스 : 130\t|\t이동 손실 : 1.6339888791091568\n",
      "배치 인덱스 : 131\t|\t이동 손실 : 1.6336897196191729\n",
      "배치 인덱스 : 132\t|\t이동 손실 : 1.6336652623083356\n",
      "배치 인덱스 : 133\t|\t이동 손실 : 1.633157613562114\n",
      "배치 인덱스 : 134\t|\t이동 손실 : 1.6333401079531067\n",
      "배치 인덱스 : 135\t|\t이동 손실 : 1.6330473440534925\n",
      "배치 인덱스 : 136\t|\t이동 손실 : 1.6329368814064635\n",
      "배치 인덱스 : 137\t|\t이동 손실 : 1.633325542228809\n",
      "배치 인덱스 : 138\t|\t이동 손실 : 1.6331438143476307\n",
      "배치 인덱스 : 139\t|\t이동 손실 : 1.6336027187960487\n",
      "배치 인덱스 : 140\t|\t이동 손실 : 1.6343309033847022\n",
      "배치 인덱스 : 141\t|\t이동 손실 : 1.6346316471905773\n",
      "배치 인덱스 : 142\t|\t이동 손실 : 1.6345115808340216\n",
      "배치 인덱스 : 143\t|\t이동 손실 : 1.6340967168410616\n",
      "배치 인덱스 : 144\t|\t이동 손실 : 1.6341054924603162\n",
      "배치 인덱스 : 145\t|\t이동 손실 : 1.634683006430325\n",
      "배치 인덱스 : 146\t|\t이동 손실 : 1.6352109284628\n",
      "배치 인덱스 : 147\t|\t이동 손실 : 1.6354763137327653\n",
      "배치 인덱스 : 148\t|\t이동 손실 : 1.635326227885764\n",
      "배치 인덱스 : 149\t|\t이동 손실 : 1.634771695931752\n",
      "배치 인덱스 : 150\t|\t이동 손실 : 1.6349064261708033\n",
      "배치 인덱스 : 151\t|\t이동 손실 : 1.6348218290429362\n",
      "배치 인덱스 : 152\t|\t이동 손실 : 1.6342494659174498\n",
      "배치 인덱스 : 153\t|\t이동 손실 : 1.635183050260915\n",
      "배치 인덱스 : 154\t|\t이동 손실 : 1.6347010766306227\n",
      "배치 인덱스 : 155\t|\t이동 손실 : 1.6347107933117788\n",
      "배치 인덱스 : 156\t|\t이동 손실 : 1.6343794939624272\n",
      "배치 인덱스 : 157\t|\t이동 손실 : 1.6342885041538668\n",
      "배치 인덱스 : 158\t|\t이동 손실 : 1.6339489851357798\n",
      "배치 인덱스 : 159\t|\t이동 손실 : 1.6341736063361163\n",
      "배치 인덱스 : 160\t|\t이동 손실 : 1.6331045294400324\n",
      "배치 인덱스 : 161\t|\t이동 손실 : 1.632710774739583\n",
      "배치 인덱스 : 162\t|\t이동 손실 : 1.6327801891631142\n",
      "배치 인덱스 : 163\t|\t이동 손실 : 1.6329171832014873\n",
      "배치 인덱스 : 164\t|\t이동 손실 : 1.6327115225069448\n",
      "배치 인덱스 : 165\t|\t이동 손실 : 1.6335342512073285\n",
      "배치 인덱스 : 166\t|\t이동 손실 : 1.6326691433341203\n",
      "배치 인덱스 : 167\t|\t이동 손실 : 1.6334829663946515\n",
      "배치 인덱스 : 168\t|\t이동 손실 : 1.6338805707954092\n",
      "배치 인덱스 : 169\t|\t이동 손실 : 1.6334798511336832\n",
      "배치 인덱스 : 170\t|\t이동 손실 : 1.6328277762173213\n",
      "배치 인덱스 : 171\t|\t이동 손실 : 1.6321997469247775\n",
      "배치 인덱스 : 172\t|\t이동 손실 : 1.6321664435326022\n",
      "배치 인덱스 : 173\t|\t이동 손실 : 1.632385777330947\n",
      "배치 인덱스 : 174\t|\t이동 손실 : 1.6322688409260344\n",
      "배치 인덱스 : 175\t|\t이동 손실 : 1.6321687705137515\n",
      "배치 인덱스 : 176\t|\t이동 손실 : 1.631330069849047\n",
      "배치 인덱스 : 177\t|\t이동 손실 : 1.631676213125165\n",
      "배치 인덱스 : 178\t|\t이동 손실 : 1.6306007740883857\n",
      "배치 인덱스 : 179\t|\t이동 손실 : 1.6308302839597069\n",
      "배치 인덱스 : 180\t|\t이동 손실 : 1.6309865680188766\n",
      "배치 인덱스 : 181\t|\t이동 손실 : 1.6312445474194959\n",
      "배치 인덱스 : 182\t|\t이동 손실 : 1.6305673975762125\n",
      "배치 인덱스 : 183\t|\t이동 손실 : 1.6309044399987098\n",
      "배치 인덱스 : 184\t|\t이동 손실 : 1.6309177218256772\n",
      "배치 인덱스 : 185\t|\t이동 손실 : 1.6306371528615236\n",
      "배치 인덱스 : 186\t|\t이동 손실 : 1.630325808882076\n",
      "배치 인덱스 : 187\t|\t이동 손실 : 1.6300108489838054\n",
      "배치 인덱스 : 188\t|\t이동 손실 : 1.6295429379851731\n",
      "배치 인덱스 : 189\t|\t이동 손실 : 1.6302150738866708\n",
      "배치 인덱스 : 190\t|\t이동 손실 : 1.6302743401202857\n",
      "배치 인덱스 : 191\t|\t이동 손실 : 1.6302460599690678\n",
      "배치 인덱스 : 192\t|\t이동 손실 : 1.6300225041690888\n",
      "배치 인덱스 : 193\t|\t이동 손실 : 1.6299785129802746\n",
      "배치 인덱스 : 194\t|\t이동 손실 : 1.6295535478836454\n",
      "배치 인덱스 : 195\t|\t이동 손실 : 1.6300431118935959\n",
      "배치 인덱스 : 196\t|\t이동 손실 : 1.6298815459769393\n",
      "배치 인덱스 : 197\t|\t이동 손실 : 1.6299332133447286\n",
      "배치 인덱스 : 198\t|\t이동 손실 : 1.6302092285012486\n",
      "배치 인덱스 : 199\t|\t이동 손실 : 1.6300035125017172\n",
      "배치 인덱스 : 200\t|\t이동 손실 : 1.6299063779821448\n",
      "배치 인덱스 : 201\t|\t이동 손실 : 1.6303286009495805\n",
      "배치 인덱스 : 202\t|\t이동 손실 : 1.6297729449906377\n",
      "배치 인덱스 : 203\t|\t이동 손실 : 1.6297283762810282\n",
      "배치 인덱스 : 204\t|\t이동 손실 : 1.6301764243986554\n",
      "배치 인덱스 : 205\t|\t이동 손실 : 1.629435976732125\n",
      "배치 인덱스 : 206\t|\t이동 손실 : 1.6303588434118008\n",
      "배치 인덱스 : 207\t|\t이동 손실 : 1.6307510332419326\n",
      "배치 인덱스 : 208\t|\t이동 손실 : 1.6309397174981226\n",
      "배치 인덱스 : 209\t|\t이동 손실 : 1.6309727975300383\n",
      "배치 인덱스 : 210\t|\t이동 손실 : 1.6312483294880225\n",
      "배치 인덱스 : 211\t|\t이동 손실 : 1.6304329897997518\n",
      "배치 인덱스 : 212\t|\t이동 손실 : 1.6301875668512267\n",
      "배치 인덱스 : 213\t|\t이동 손실 : 1.6302541026445196\n",
      "배치 인덱스 : 214\t|\t이동 손실 : 1.6299379476281104\n",
      "배치 인덱스 : 215\t|\t이동 손실 : 1.6292739869267856\n",
      "배치 인덱스 : 216\t|\t이동 손실 : 1.6290576177808\n",
      "배치 인덱스 : 217\t|\t이동 손실 : 1.6284894669821506\n",
      "배치 인덱스 : 218\t|\t이동 손실 : 1.6281319470166074\n",
      "배치 인덱스 : 219\t|\t이동 손실 : 1.627829187566584\n",
      "배치 인덱스 : 220\t|\t이동 손실 : 1.6275377014643468\n",
      "배치 인덱스 : 221\t|\t이동 손실 : 1.6274129920177633\n",
      "배치 인덱스 : 222\t|\t이동 손실 : 1.6275776218405755\n",
      "배치 인덱스 : 223\t|\t이동 손실 : 1.6272918315870424\n",
      "배치 인덱스 : 224\t|\t이동 손실 : 1.6273468923568728\n",
      "배치 인덱스 : 225\t|\t이동 손실 : 1.6275885131506795\n",
      "배치 인덱스 : 226\t|\t이동 손실 : 1.6279577689023796\n",
      "Epoch: 05 | Time: 13m 24s\n",
      "\tTrain Loss: 1.628 | Train PPL: 5.093\n",
      "\tValidation Loss: 1.768 | Validation PPL: 5.858\n",
      "에폭 : 5\n",
      "배치 인덱스 : 0\t|\t이동 손실 : 1.575289011001587\n",
      "배치 인덱스 : 1\t|\t이동 손실 : 1.5346501469612122\n",
      "배치 인덱스 : 2\t|\t이동 손실 : 1.5030938784281414\n",
      "배치 인덱스 : 3\t|\t이동 손실 : 1.4795733392238617\n",
      "배치 인덱스 : 4\t|\t이동 손실 : 1.460462760925293\n",
      "배치 인덱스 : 5\t|\t이동 손실 : 1.4476855198542276\n",
      "배치 인덱스 : 6\t|\t이동 손실 : 1.4572464738573345\n",
      "배치 인덱스 : 7\t|\t이동 손실 : 1.4384986013174055\n",
      "배치 인덱스 : 8\t|\t이동 손실 : 1.4372135665681625\n",
      "배치 인덱스 : 9\t|\t이동 손실 : 1.43365660905838\n",
      "배치 인덱스 : 10\t|\t이동 손실 : 1.433073498985984\n",
      "배치 인덱스 : 11\t|\t이동 손실 : 1.437785506248474\n",
      "배치 인덱스 : 12\t|\t이동 손실 : 1.4351419577231772\n",
      "배치 인덱스 : 13\t|\t이동 손실 : 1.4307535290718076\n",
      "배치 인덱스 : 14\t|\t이동 손실 : 1.4287211736043293\n",
      "배치 인덱스 : 15\t|\t이동 손실 : 1.4297667890787122\n",
      "배치 인덱스 : 16\t|\t이동 손실 : 1.427216613993925\n",
      "배치 인덱스 : 17\t|\t이동 손실 : 1.4301729864544337\n",
      "배치 인덱스 : 18\t|\t이동 손실 : 1.4208673552462927\n",
      "배치 인덱스 : 19\t|\t이동 손실 : 1.4219995856285093\n",
      "배치 인덱스 : 20\t|\t이동 손실 : 1.4204518738247096\n",
      "배치 인덱스 : 21\t|\t이동 손실 : 1.4232580282471394\n",
      "배치 인덱스 : 22\t|\t이동 손실 : 1.426496246586675\n",
      "배치 인덱스 : 23\t|\t이동 손실 : 1.4279843121767042\n",
      "배치 인덱스 : 24\t|\t이동 손실 : 1.4277840852737425\n",
      "배치 인덱스 : 25\t|\t이동 손실 : 1.4302408465972312\n",
      "배치 인덱스 : 26\t|\t이동 손실 : 1.4327034906104756\n",
      "배치 인덱스 : 27\t|\t이동 손실 : 1.4322851470538545\n",
      "배치 인덱스 : 28\t|\t이동 손실 : 1.4289232615766851\n",
      "배치 인덱스 : 29\t|\t이동 손실 : 1.4316306749979653\n",
      "배치 인덱스 : 30\t|\t이동 손실 : 1.4313293233994513\n",
      "배치 인덱스 : 31\t|\t이동 손실 : 1.430914558470249\n",
      "배치 인덱스 : 32\t|\t이동 손실 : 1.430622061093648\n",
      "배치 인덱스 : 33\t|\t이동 손실 : 1.430232019985423\n",
      "배치 인덱스 : 34\t|\t이동 손실 : 1.4294657945632931\n",
      "배치 인덱스 : 35\t|\t이동 손실 : 1.4260504345099128\n",
      "배치 인덱스 : 36\t|\t이동 손실 : 1.4262547331887319\n",
      "배치 인덱스 : 37\t|\t이동 손실 : 1.4275848520429506\n",
      "배치 인덱스 : 38\t|\t이동 손실 : 1.4268568509664286\n",
      "배치 인덱스 : 39\t|\t이동 손실 : 1.4249734669923777\n",
      "배치 인덱스 : 40\t|\t이동 손실 : 1.424448190665826\n",
      "배치 인덱스 : 41\t|\t이동 손실 : 1.423471428099132\n",
      "배치 인덱스 : 42\t|\t이동 손실 : 1.423505594564038\n",
      "배치 인덱스 : 43\t|\t이동 손실 : 1.4226884029128328\n",
      "배치 인덱스 : 44\t|\t이동 손실 : 1.4221901257832839\n",
      "배치 인덱스 : 45\t|\t이동 손실 : 1.4247677740843394\n",
      "배치 인덱스 : 46\t|\t이동 손실 : 1.4249608440602073\n",
      "배치 인덱스 : 47\t|\t이동 손실 : 1.4247529531518612\n",
      "배치 인덱스 : 48\t|\t이동 손실 : 1.425758782698183\n",
      "배치 인덱스 : 49\t|\t이동 손실 : 1.4283309817314143\n",
      "배치 인덱스 : 50\t|\t이동 손실 : 1.4262736124150888\n",
      "배치 인덱스 : 51\t|\t이동 손실 : 1.4265763713763304\n",
      "배치 인덱스 : 52\t|\t이동 손실 : 1.428198409530351\n",
      "배치 인덱스 : 53\t|\t이동 손실 : 1.4264726749172911\n",
      "배치 인덱스 : 54\t|\t이동 손실 : 1.426279432123357\n",
      "배치 인덱스 : 55\t|\t이동 손실 : 1.4280431675059448\n",
      "배치 인덱스 : 56\t|\t이동 손실 : 1.4253166181999335\n",
      "배치 인덱스 : 57\t|\t이동 손실 : 1.4256231558733967\n",
      "배치 인덱스 : 58\t|\t이동 손실 : 1.4264579708293328\n",
      "배치 인덱스 : 59\t|\t이동 손실 : 1.427405428886413\n",
      "배치 인덱스 : 60\t|\t이동 손실 : 1.4283477341542474\n",
      "배치 인덱스 : 61\t|\t이동 손실 : 1.4275712890009722\n",
      "배치 인덱스 : 62\t|\t이동 손실 : 1.4274794601258773\n",
      "배치 인덱스 : 63\t|\t이동 손실 : 1.4255655538290735\n",
      "배치 인덱스 : 64\t|\t이동 손실 : 1.4243595013251666\n",
      "배치 인덱스 : 65\t|\t이동 손실 : 1.4241392684705325\n",
      "배치 인덱스 : 66\t|\t이동 손실 : 1.4236554245450599\n",
      "배치 인덱스 : 67\t|\t이동 손실 : 1.4245870604234578\n",
      "배치 인덱스 : 68\t|\t이동 손실 : 1.4249430601147632\n",
      "배치 인덱스 : 69\t|\t이동 손실 : 1.426299495356423\n",
      "배치 인덱스 : 70\t|\t이동 손실 : 1.4263181132330016\n",
      "배치 인덱스 : 71\t|\t이동 손실 : 1.4277408139573198\n",
      "배치 인덱스 : 72\t|\t이동 손실 : 1.428344997641158\n",
      "배치 인덱스 : 73\t|\t이동 손실 : 1.4286681945259503\n",
      "배치 인덱스 : 74\t|\t이동 손실 : 1.4285244671503698\n",
      "배치 인덱스 : 75\t|\t이동 손실 : 1.4275549101202107\n",
      "배치 인덱스 : 76\t|\t이동 손실 : 1.4292506428508012\n",
      "배치 인덱스 : 77\t|\t이동 손실 : 1.4271124356832257\n",
      "배치 인덱스 : 78\t|\t이동 손실 : 1.4282899476304836\n",
      "배치 인덱스 : 79\t|\t이동 손실 : 1.427765297889709\n",
      "배치 인덱스 : 80\t|\t이동 손실 : 1.4263520947209107\n",
      "배치 인덱스 : 81\t|\t이동 손실 : 1.4259253900225566\n",
      "배치 인덱스 : 82\t|\t이동 손실 : 1.4258836680148017\n",
      "배치 인덱스 : 83\t|\t이동 손실 : 1.4264598375275017\n",
      "배치 인덱스 : 84\t|\t이동 손실 : 1.42748889502357\n",
      "배치 인덱스 : 85\t|\t이동 손실 : 1.4270764478417326\n",
      "배치 인덱스 : 86\t|\t이동 손실 : 1.4271528241278106\n",
      "배치 인덱스 : 87\t|\t이동 손실 : 1.4264634712175885\n",
      "배치 인덱스 : 88\t|\t이동 손실 : 1.4261633787262302\n",
      "배치 인덱스 : 89\t|\t이동 손실 : 1.4255451639493304\n",
      "배치 인덱스 : 90\t|\t이동 손실 : 1.425905692708361\n",
      "배치 인덱스 : 91\t|\t이동 손실 : 1.4269158425538435\n",
      "배치 인덱스 : 92\t|\t이동 손실 : 1.4285436881485805\n",
      "배치 인덱스 : 93\t|\t이동 손실 : 1.427711675775812\n",
      "배치 인덱스 : 94\t|\t이동 손실 : 1.4279039608804802\n",
      "배치 인덱스 : 95\t|\t이동 손실 : 1.4265227342645326\n",
      "배치 인덱스 : 96\t|\t이동 손실 : 1.4270300594801755\n",
      "배치 인덱스 : 97\t|\t이동 손실 : 1.4263033416806434\n",
      "배치 인덱스 : 98\t|\t이동 손실 : 1.4268194834391275\n",
      "배치 인덱스 : 99\t|\t이동 손실 : 1.4269694197177885\n",
      "배치 인덱스 : 100\t|\t이동 손실 : 1.426969781960591\n",
      "배치 인덱스 : 101\t|\t이동 손실 : 1.4275314013163247\n",
      "배치 인덱스 : 102\t|\t이동 손실 : 1.4281997761680083\n",
      "배치 인덱스 : 103\t|\t이동 손실 : 1.428872777865483\n",
      "배치 인덱스 : 104\t|\t이동 손실 : 1.4281641653605868\n",
      "배치 인덱스 : 105\t|\t이동 손실 : 1.4288091367145752\n",
      "배치 인덱스 : 106\t|\t이동 손실 : 1.4293167279145427\n",
      "배치 인덱스 : 107\t|\t이동 손실 : 1.429408605451937\n",
      "배치 인덱스 : 108\t|\t이동 손실 : 1.4289914435202922\n",
      "배치 인덱스 : 109\t|\t이동 손실 : 1.4282186085527593\n",
      "배치 인덱스 : 110\t|\t이동 손실 : 1.429190540098929\n",
      "배치 인덱스 : 111\t|\t이동 손실 : 1.4302025267056055\n",
      "배치 인덱스 : 112\t|\t이동 손실 : 1.4301069352479108\n",
      "배치 인덱스 : 113\t|\t이동 손실 : 1.4299979439952917\n",
      "배치 인덱스 : 114\t|\t이동 손실 : 1.4296005373415739\n",
      "배치 인덱스 : 115\t|\t이동 손실 : 1.4296460295545643\n",
      "배치 인덱스 : 116\t|\t이동 손실 : 1.4295439577510214\n",
      "배치 인덱스 : 117\t|\t이동 손실 : 1.428938613099567\n",
      "배치 인덱스 : 118\t|\t이동 손실 : 1.4288285049069829\n",
      "배치 인덱스 : 119\t|\t이동 손실 : 1.4286571611960728\n",
      "배치 인덱스 : 120\t|\t이동 손실 : 1.4287322946816436\n",
      "배치 인덱스 : 121\t|\t이동 손실 : 1.428899895949442\n",
      "배치 인덱스 : 122\t|\t이동 손실 : 1.4290776010451278\n",
      "배치 인덱스 : 123\t|\t이동 손실 : 1.429041555812282\n",
      "배치 인덱스 : 124\t|\t이동 손실 : 1.4288752031326295\n",
      "배치 인덱스 : 125\t|\t이동 손실 : 1.4293695139506508\n",
      "배치 인덱스 : 126\t|\t이동 손실 : 1.4301450449650683\n",
      "배치 인덱스 : 127\t|\t이동 손실 : 1.431453903205693\n",
      "배치 인덱스 : 128\t|\t이동 손실 : 1.4315524184426598\n",
      "배치 인덱스 : 129\t|\t이동 손실 : 1.430618319144616\n",
      "배치 인덱스 : 130\t|\t이동 손실 : 1.42977202302627\n",
      "배치 인덱스 : 131\t|\t이동 손실 : 1.4306246385429846\n",
      "배치 인덱스 : 132\t|\t이동 손실 : 1.4308142706863864\n",
      "배치 인덱스 : 133\t|\t이동 손실 : 1.4304537559623152\n",
      "배치 인덱스 : 134\t|\t이동 손실 : 1.4305610533113835\n",
      "배치 인덱스 : 135\t|\t이동 손실 : 1.4304397930117216\n",
      "배치 인덱스 : 136\t|\t이동 손실 : 1.4304861857073152\n",
      "배치 인덱스 : 137\t|\t이동 손실 : 1.4307274671568389\n",
      "배치 인덱스 : 138\t|\t이동 손실 : 1.4308887968818063\n",
      "배치 인덱스 : 139\t|\t이동 손실 : 1.4305629576955525\n",
      "배치 인덱스 : 140\t|\t이동 손실 : 1.4307704191681343\n",
      "배치 인덱스 : 141\t|\t이동 손실 : 1.432041535914784\n",
      "배치 인덱스 : 142\t|\t이동 손실 : 1.4318084266635924\n",
      "배치 인덱스 : 143\t|\t이동 손실 : 1.4315742651621504\n",
      "배치 인덱스 : 144\t|\t이동 손실 : 1.4317644859182426\n",
      "배치 인덱스 : 145\t|\t이동 손실 : 1.4317958085504299\n",
      "배치 인덱스 : 146\t|\t이동 손실 : 1.433305387594262\n",
      "배치 인덱스 : 147\t|\t이동 손실 : 1.4346572619837685\n",
      "배치 인덱스 : 148\t|\t이동 손실 : 1.4351027275891914\n",
      "배치 인덱스 : 149\t|\t이동 손실 : 1.434649962584178\n",
      "배치 인덱스 : 150\t|\t이동 손실 : 1.4347053332044593\n",
      "배치 인덱스 : 151\t|\t이동 손실 : 1.4344968380112402\n",
      "배치 인덱스 : 152\t|\t이동 손실 : 1.4347240067774958\n",
      "배치 인덱스 : 153\t|\t이동 손실 : 1.4345037720420148\n",
      "배치 인덱스 : 154\t|\t이동 손실 : 1.4345576455516205\n",
      "배치 인덱스 : 155\t|\t이동 손실 : 1.4347241199933571\n",
      "배치 인덱스 : 156\t|\t이동 손실 : 1.4347729098265345\n",
      "배치 인덱스 : 157\t|\t이동 손실 : 1.43475039397614\n",
      "배치 인덱스 : 158\t|\t이동 손실 : 1.4344765307768343\n",
      "배치 인덱스 : 159\t|\t이동 손실 : 1.4348300114274033\n",
      "배치 인덱스 : 160\t|\t이동 손실 : 1.4359450458739864\n",
      "배치 인덱스 : 161\t|\t이동 손실 : 1.4368043402094908\n",
      "배치 인덱스 : 162\t|\t이동 손실 : 1.4369116458424769\n",
      "배치 인덱스 : 163\t|\t이동 손실 : 1.436582894586936\n",
      "배치 인덱스 : 164\t|\t이동 손실 : 1.4369375987486415\n",
      "배치 인덱스 : 165\t|\t이동 손실 : 1.4372612568269303\n",
      "배치 인덱스 : 166\t|\t이동 손실 : 1.4375570641306357\n",
      "배치 인덱스 : 167\t|\t이동 손실 : 1.438138619774865\n",
      "배치 인덱스 : 168\t|\t이동 손실 : 1.4388755665728337\n",
      "배치 인덱스 : 169\t|\t이동 손실 : 1.438460526045632\n",
      "배치 인덱스 : 170\t|\t이동 손실 : 1.4380801706983342\n",
      "배치 인덱스 : 171\t|\t이동 손실 : 1.437919193229011\n",
      "배치 인덱스 : 172\t|\t이동 손실 : 1.438047334637946\n",
      "배치 인덱스 : 173\t|\t이동 손실 : 1.4382373957798409\n",
      "배치 인덱스 : 174\t|\t이동 손실 : 1.4383346455437807\n",
      "배치 인덱스 : 175\t|\t이동 손실 : 1.4381762065670718\n",
      "배치 인덱스 : 176\t|\t이동 손실 : 1.4380416782562353\n",
      "배치 인덱스 : 177\t|\t이동 손실 : 1.43804174996494\n",
      "배치 인덱스 : 178\t|\t이동 손실 : 1.4388183881450642\n",
      "배치 인덱스 : 179\t|\t이동 손실 : 1.4391658663749705\n",
      "배치 인덱스 : 180\t|\t이동 손실 : 1.4389647568128396\n",
      "배치 인덱스 : 181\t|\t이동 손실 : 1.4391226192097097\n",
      "배치 인덱스 : 182\t|\t이동 손실 : 1.439541843419519\n",
      "배치 인덱스 : 183\t|\t이동 손실 : 1.4391277834125198\n",
      "배치 인덱스 : 184\t|\t이동 손실 : 1.4394803040736441\n",
      "배치 인덱스 : 185\t|\t이동 손실 : 1.4398030273375984\n",
      "배치 인덱스 : 186\t|\t이동 손실 : 1.439895453937552\n",
      "배치 인덱스 : 187\t|\t이동 손실 : 1.4403732780446408\n",
      "배치 인덱스 : 188\t|\t이동 손실 : 1.4399594793874761\n",
      "배치 인덱스 : 189\t|\t이동 손실 : 1.4400222157177183\n",
      "배치 인덱스 : 190\t|\t이동 손실 : 1.43987989612899\n",
      "배치 인덱스 : 191\t|\t이동 손실 : 1.4404347284386565\n",
      "배치 인덱스 : 192\t|\t이동 손실 : 1.4400019287445394\n",
      "배치 인덱스 : 193\t|\t이동 손실 : 1.4399585717732153\n",
      "배치 인덱스 : 194\t|\t이동 손실 : 1.4401761097785764\n",
      "배치 인덱스 : 195\t|\t이동 손실 : 1.4402223278065127\n",
      "배치 인덱스 : 196\t|\t이동 손실 : 1.4407639563991343\n",
      "배치 인덱스 : 197\t|\t이동 손실 : 1.440699066778627\n",
      "배치 인덱스 : 198\t|\t이동 손실 : 1.4407227776158404\n",
      "배치 인덱스 : 199\t|\t이동 손실 : 1.440468148589135\n",
      "배치 인덱스 : 200\t|\t이동 손실 : 1.4403952994749922\n",
      "배치 인덱스 : 201\t|\t이동 손실 : 1.440799271706308\n",
      "배치 인덱스 : 202\t|\t이동 손실 : 1.441158056259156\n",
      "배치 인덱스 : 203\t|\t이동 손실 : 1.4414328430213186\n",
      "배치 인덱스 : 204\t|\t이동 손실 : 1.4414583566712176\n",
      "배치 인덱스 : 205\t|\t이동 손실 : 1.44093626969069\n",
      "배치 인덱스 : 206\t|\t이동 손실 : 1.440880952249979\n",
      "배치 인덱스 : 207\t|\t이동 손실 : 1.4408876735430503\n",
      "배치 인덱스 : 208\t|\t이동 손실 : 1.4414333920729794\n",
      "배치 인덱스 : 209\t|\t이동 손실 : 1.4416036151704341\n",
      "배치 인덱스 : 210\t|\t이동 손실 : 1.442387083130426\n",
      "배치 인덱스 : 211\t|\t이동 손실 : 1.441824600381672\n",
      "배치 인덱스 : 212\t|\t이동 손실 : 1.4417301186933211\n",
      "배치 인덱스 : 213\t|\t이동 손실 : 1.4412810295541718\n",
      "배치 인덱스 : 214\t|\t이동 손실 : 1.4417914451554772\n",
      "배치 인덱스 : 215\t|\t이동 손실 : 1.4418749974833602\n",
      "배치 인덱스 : 216\t|\t이동 손실 : 1.4416606596538006\n",
      "배치 인덱스 : 217\t|\t이동 손실 : 1.4410910207197214\n",
      "배치 인덱스 : 218\t|\t이동 손실 : 1.4413855701821043\n",
      "배치 인덱스 : 219\t|\t이동 손실 : 1.4418695178898906\n",
      "배치 인덱스 : 220\t|\t이동 손실 : 1.4424517294939834\n",
      "배치 인덱스 : 221\t|\t이동 손실 : 1.4424222503696482\n",
      "배치 인덱스 : 222\t|\t이동 손실 : 1.4419822238485915\n",
      "배치 인덱스 : 223\t|\t이동 손실 : 1.4420426668865347\n",
      "배치 인덱스 : 224\t|\t이동 손실 : 1.4416719553205708\n",
      "배치 인덱스 : 225\t|\t이동 손실 : 1.4416611384501505\n",
      "배치 인덱스 : 226\t|\t이동 손실 : 1.44112469183716\n",
      "Epoch: 06 | Time: 13m 24s\n",
      "\tTrain Loss: 1.441 | Train PPL: 4.225\n",
      "\tValidation Loss: 1.711 | Validation PPL: 5.536\n",
      "에폭 : 6\n",
      "배치 인덱스 : 0\t|\t이동 손실 : 1.2072350978851318\n",
      "배치 인덱스 : 1\t|\t이동 손실 : 1.2895010113716125\n",
      "배치 인덱스 : 2\t|\t이동 손실 : 1.2917654514312744\n",
      "배치 인덱스 : 3\t|\t이동 손실 : 1.2693714797496796\n",
      "배치 인덱스 : 4\t|\t이동 손실 : 1.2259758949279784\n",
      "배치 인덱스 : 5\t|\t이동 손실 : 1.226548393567403\n",
      "배치 인덱스 : 6\t|\t이동 손실 : 1.2488363129752023\n",
      "배치 인덱스 : 7\t|\t이동 손실 : 1.2667730897665024\n",
      "배치 인덱스 : 8\t|\t이동 손실 : 1.25857679049174\n",
      "배치 인덱스 : 9\t|\t이동 손실 : 1.2580764770507813\n",
      "배치 인덱스 : 10\t|\t이동 손실 : 1.266189163381403\n",
      "배치 인덱스 : 11\t|\t이동 손실 : 1.260516196489334\n",
      "배치 인덱스 : 12\t|\t이동 손실 : 1.2553911392505352\n",
      "배치 인덱스 : 13\t|\t이동 손실 : 1.2698997259140015\n",
      "배치 인덱스 : 14\t|\t이동 손실 : 1.2651089350382487\n",
      "배치 인덱스 : 15\t|\t이동 손실 : 1.2578052654862404\n",
      "배치 인덱스 : 16\t|\t이동 손실 : 1.2621907416511984\n",
      "배치 인덱스 : 17\t|\t이동 손실 : 1.2600817879041035\n",
      "배치 인덱스 : 18\t|\t이동 손실 : 1.2638606711437828\n",
      "배치 인덱스 : 19\t|\t이동 손실 : 1.2667163014411926\n",
      "배치 인덱스 : 20\t|\t이동 손실 : 1.2666228669030326\n",
      "배치 인덱스 : 21\t|\t이동 손실 : 1.2663641463626516\n",
      "배치 인덱스 : 22\t|\t이동 손실 : 1.2633690004763396\n",
      "배치 인덱스 : 23\t|\t이동 손실 : 1.262655258178711\n",
      "배치 인덱스 : 24\t|\t이동 손실 : 1.261269450187683\n",
      "배치 인덱스 : 25\t|\t이동 손실 : 1.2575943240752587\n",
      "배치 인덱스 : 26\t|\t이동 손실 : 1.258272272569162\n",
      "배치 인덱스 : 27\t|\t이동 손실 : 1.258429080247879\n",
      "배치 인덱스 : 28\t|\t이동 손실 : 1.2597418571340626\n",
      "배치 인덱스 : 29\t|\t이동 손실 : 1.2607868313789368\n",
      "배치 인덱스 : 30\t|\t이동 손실 : 1.2614009764886671\n",
      "배치 인덱스 : 31\t|\t이동 손실 : 1.2595470026135445\n",
      "배치 인덱스 : 32\t|\t이동 손실 : 1.2617990645495327\n",
      "배치 인덱스 : 33\t|\t이동 손실 : 1.2654594954322365\n",
      "배치 인덱스 : 34\t|\t이동 손실 : 1.2636278731482369\n",
      "배치 인덱스 : 35\t|\t이동 손실 : 1.2628483937846289\n",
      "배치 인덱스 : 36\t|\t이동 손실 : 1.2634973300469887\n",
      "배치 인덱스 : 37\t|\t이동 손실 : 1.264879280015042\n",
      "배치 인덱스 : 38\t|\t이동 손실 : 1.2639301373408391\n",
      "배치 인덱스 : 39\t|\t이동 손실 : 1.2632789045572281\n",
      "배치 인덱스 : 40\t|\t이동 손실 : 1.26394639364103\n",
      "배치 인덱스 : 41\t|\t이동 손실 : 1.2626988802637373\n",
      "배치 인덱스 : 42\t|\t이동 손실 : 1.262544357499411\n",
      "배치 인덱스 : 43\t|\t이동 손실 : 1.2662163051691924\n",
      "배치 인덱스 : 44\t|\t이동 손실 : 1.2664856221940783\n",
      "배치 인덱스 : 45\t|\t이동 손실 : 1.26834040361902\n",
      "배치 인덱스 : 46\t|\t이동 손실 : 1.268470660169074\n",
      "배치 인덱스 : 47\t|\t이동 손실 : 1.2695141310493152\n",
      "배치 인덱스 : 48\t|\t이동 손실 : 1.2688194099737675\n",
      "배치 인덱스 : 49\t|\t이동 손실 : 1.2695722031593324\n",
      "배치 인덱스 : 50\t|\t이동 손실 : 1.268742460830539\n",
      "배치 인덱스 : 51\t|\t이동 손실 : 1.2677586537141068\n",
      "배치 인덱스 : 52\t|\t이동 손실 : 1.265916444220633\n",
      "배치 인덱스 : 53\t|\t이동 손실 : 1.2640338584228799\n",
      "배치 인덱스 : 54\t|\t이동 손실 : 1.26354811408303\n",
      "배치 인덱스 : 55\t|\t이동 손실 : 1.264617696404457\n",
      "배치 인덱스 : 56\t|\t이동 손실 : 1.2673278084972448\n",
      "배치 인덱스 : 57\t|\t이동 손실 : 1.2668870893017998\n",
      "배치 인덱스 : 58\t|\t이동 손실 : 1.2657833240799985\n",
      "배치 인덱스 : 59\t|\t이동 손실 : 1.266408375898997\n",
      "배치 인덱스 : 60\t|\t이동 손실 : 1.2660072436098193\n",
      "배치 인덱스 : 61\t|\t이동 손실 : 1.2652862937219682\n",
      "배치 인덱스 : 62\t|\t이동 손실 : 1.26510326824491\n",
      "배치 인덱스 : 63\t|\t이동 손실 : 1.265319760888815\n",
      "배치 인덱스 : 64\t|\t이동 손실 : 1.26553213596344\n",
      "배치 인덱스 : 65\t|\t이동 손실 : 1.2663263714674748\n",
      "배치 인덱스 : 66\t|\t이동 손실 : 1.2663871761578234\n",
      "배치 인덱스 : 67\t|\t이동 손실 : 1.267943569842507\n",
      "배치 인덱스 : 68\t|\t이동 손실 : 1.2685421687969265\n",
      "배치 인덱스 : 69\t|\t이동 손실 : 1.2689182451793128\n",
      "배치 인덱스 : 70\t|\t이동 손실 : 1.2715397854925883\n",
      "배치 인덱스 : 71\t|\t이동 손실 : 1.2718556506766214\n",
      "배치 인덱스 : 72\t|\t이동 손실 : 1.2713687191270804\n",
      "배치 인덱스 : 73\t|\t이동 손실 : 1.2718534179635952\n",
      "배치 인덱스 : 74\t|\t이동 손실 : 1.2713424396514894\n",
      "배치 인덱스 : 75\t|\t이동 손실 : 1.27151452710754\n",
      "배치 인덱스 : 76\t|\t이동 손실 : 1.2732242469663746\n",
      "배치 인덱스 : 77\t|\t이동 손실 : 1.2743854369872658\n",
      "배치 인덱스 : 78\t|\t이동 손실 : 1.2753695325006416\n",
      "배치 인덱스 : 79\t|\t이동 손실 : 1.2765874281525615\n",
      "배치 인덱스 : 80\t|\t이동 손실 : 1.2755806033993948\n",
      "배치 인덱스 : 81\t|\t이동 손실 : 1.2757193126329565\n",
      "배치 인덱스 : 82\t|\t이동 손실 : 1.2765904363379423\n",
      "배치 인덱스 : 83\t|\t이동 손실 : 1.2774819760095508\n",
      "배치 인덱스 : 84\t|\t이동 손실 : 1.2784301084630632\n",
      "배치 인덱스 : 85\t|\t이동 손실 : 1.2777397646460424\n",
      "배치 인덱스 : 86\t|\t이동 손실 : 1.2772011044381681\n",
      "배치 인덱스 : 87\t|\t이동 손실 : 1.2771012349562214\n",
      "배치 인덱스 : 88\t|\t이동 손실 : 1.277331401792805\n",
      "배치 인덱스 : 89\t|\t이동 손실 : 1.2767805337905886\n",
      "배치 인덱스 : 90\t|\t이동 손실 : 1.2772879011028417\n",
      "배치 인덱스 : 91\t|\t이동 손실 : 1.2762122193108436\n",
      "배치 인덱스 : 92\t|\t이동 손실 : 1.2756567167979416\n",
      "배치 인덱스 : 93\t|\t이동 손실 : 1.275344583582371\n",
      "배치 인덱스 : 94\t|\t이동 손실 : 1.2756596615439968\n",
      "배치 인덱스 : 95\t|\t이동 손실 : 1.2764348722994328\n",
      "배치 인덱스 : 96\t|\t이동 손실 : 1.2762800872940379\n",
      "배치 인덱스 : 97\t|\t이동 손실 : 1.2760039884216932\n",
      "배치 인덱스 : 98\t|\t이동 손실 : 1.2765709643412118\n",
      "배치 인덱스 : 99\t|\t이동 손실 : 1.276614943742752\n",
      "배치 인덱스 : 100\t|\t이동 손실 : 1.2767534716294544\n",
      "배치 인덱스 : 101\t|\t이동 손실 : 1.2757438561495613\n",
      "배치 인덱스 : 102\t|\t이동 손실 : 1.2758721715038264\n",
      "배치 인덱스 : 103\t|\t이동 손실 : 1.2759347386085071\n",
      "배치 인덱스 : 104\t|\t이동 손실 : 1.2746628886177427\n",
      "배치 인덱스 : 105\t|\t이동 손실 : 1.275130494585577\n",
      "배치 인덱스 : 106\t|\t이동 손실 : 1.2748977948572033\n",
      "배치 인덱스 : 107\t|\t이동 손실 : 1.275988311679275\n",
      "배치 인덱스 : 108\t|\t이동 손실 : 1.275314650404344\n",
      "배치 인덱스 : 109\t|\t이동 손실 : 1.2753175161101602\n",
      "배치 인덱스 : 110\t|\t이동 손실 : 1.2748291030660406\n",
      "배치 인덱스 : 111\t|\t이동 손실 : 1.2737166594181741\n",
      "배치 인덱스 : 112\t|\t이동 손실 : 1.2740827144774716\n",
      "배치 인덱스 : 113\t|\t이동 손실 : 1.274604973040129\n",
      "배치 인덱스 : 114\t|\t이동 손실 : 1.2746455731599227\n",
      "배치 인덱스 : 115\t|\t이동 손실 : 1.275216597935249\n",
      "배치 인덱스 : 116\t|\t이동 손실 : 1.276913790621309\n",
      "배치 인덱스 : 117\t|\t이동 손실 : 1.276299672611689\n",
      "배치 인덱스 : 118\t|\t이동 손실 : 1.2762795897091135\n",
      "배치 인덱스 : 119\t|\t이동 손실 : 1.2770087907711662\n",
      "배치 인덱스 : 120\t|\t이동 손실 : 1.2776445879423912\n",
      "배치 인덱스 : 121\t|\t이동 손실 : 1.2777850745154207\n",
      "배치 인덱스 : 122\t|\t이동 손실 : 1.2768751373135945\n",
      "배치 인덱스 : 123\t|\t이동 손실 : 1.277943206410254\n",
      "배치 인덱스 : 124\t|\t이동 손실 : 1.2787177305221555\n",
      "배치 인덱스 : 125\t|\t이동 손실 : 1.2782471596248564\n",
      "배치 인덱스 : 126\t|\t이동 손실 : 1.278548313876775\n",
      "배치 인덱스 : 127\t|\t이동 손실 : 1.278583727777004\n",
      "배치 인덱스 : 128\t|\t이동 손실 : 1.2782381079917728\n",
      "배치 인덱스 : 129\t|\t이동 손실 : 1.2781029389454766\n",
      "배치 인덱스 : 130\t|\t이동 손실 : 1.2780334976793242\n",
      "배치 인덱스 : 131\t|\t이동 손실 : 1.2776179819396045\n",
      "배치 인덱스 : 132\t|\t이동 손실 : 1.2783271827195817\n",
      "배치 인덱스 : 133\t|\t이동 손실 : 1.2783281731961376\n",
      "배치 인덱스 : 134\t|\t이동 손실 : 1.2782526607866638\n",
      "배치 인덱스 : 135\t|\t이동 손실 : 1.2788447124116558\n",
      "배치 인덱스 : 136\t|\t이동 손실 : 1.2787666921197929\n",
      "배치 인덱스 : 137\t|\t이동 손실 : 1.279089814510898\n",
      "배치 인덱스 : 138\t|\t이동 손실 : 1.2796331738396511\n",
      "배치 인덱스 : 139\t|\t이동 손실 : 1.2797124428408484\n",
      "배치 인덱스 : 140\t|\t이동 손실 : 1.2792104051468218\n",
      "배치 인덱스 : 141\t|\t이동 손실 : 1.2798891176640146\n",
      "배치 인덱스 : 142\t|\t이동 손실 : 1.2797422075605056\n",
      "배치 인덱스 : 143\t|\t이동 손실 : 1.279442196918858\n",
      "배치 인덱스 : 144\t|\t이동 손실 : 1.2790455333117778\n",
      "배치 인덱스 : 145\t|\t이동 손실 : 1.2793056140207262\n",
      "배치 인덱스 : 146\t|\t이동 손실 : 1.278927834666505\n",
      "배치 인덱스 : 147\t|\t이동 손실 : 1.2785881137525712\n",
      "배치 인덱스 : 148\t|\t이동 손실 : 1.278295224945017\n",
      "배치 인덱스 : 149\t|\t이동 손실 : 1.2783045721054076\n",
      "배치 인덱스 : 150\t|\t이동 손실 : 1.2783128552089462\n",
      "배치 인덱스 : 151\t|\t이동 손실 : 1.2784614006155415\n",
      "배치 인덱스 : 152\t|\t이동 손실 : 1.279096872977961\n",
      "배치 인덱스 : 153\t|\t이동 손실 : 1.2784071138926913\n",
      "배치 인덱스 : 154\t|\t이동 손실 : 1.2780146191197055\n",
      "배치 인덱스 : 155\t|\t이동 손실 : 1.2786880953189652\n",
      "배치 인덱스 : 156\t|\t이동 손실 : 1.2783205904019104\n",
      "배치 인덱스 : 157\t|\t이동 손실 : 1.2786369723609727\n",
      "배치 인덱스 : 158\t|\t이동 손실 : 1.2790475221549935\n",
      "배치 인덱스 : 159\t|\t이동 손실 : 1.2791746288537975\n",
      "배치 인덱스 : 160\t|\t이동 손실 : 1.2790487167998126\n",
      "배치 인덱스 : 161\t|\t이동 손실 : 1.2792860100298749\n",
      "배치 인덱스 : 162\t|\t이동 손실 : 1.2792452749299121\n",
      "배치 인덱스 : 163\t|\t이동 손실 : 1.2800105693863655\n",
      "배치 인덱스 : 164\t|\t이동 손실 : 1.279998912955775\n",
      "배치 인덱스 : 165\t|\t이동 손실 : 1.280998111489307\n",
      "배치 인덱스 : 166\t|\t이동 손실 : 1.2811374728551164\n",
      "배치 인덱스 : 167\t|\t이동 손실 : 1.2813002083982736\n",
      "배치 인덱스 : 168\t|\t이동 손실 : 1.2813043559091328\n",
      "배치 인덱스 : 169\t|\t이동 손실 : 1.28119523525238\n",
      "배치 인덱스 : 170\t|\t이동 손실 : 1.2813308385380524\n",
      "배치 인덱스 : 171\t|\t이동 손실 : 1.281597887360772\n",
      "배치 인덱스 : 172\t|\t이동 손실 : 1.2818103036439483\n",
      "배치 인덱스 : 173\t|\t이동 손실 : 1.2823215757293258\n",
      "배치 인덱스 : 174\t|\t이동 손실 : 1.2817858348573952\n",
      "배치 인덱스 : 175\t|\t이동 손실 : 1.282198658721013\n",
      "배치 인덱스 : 176\t|\t이동 손실 : 1.28199303688976\n",
      "배치 인덱스 : 177\t|\t이동 손실 : 1.2820526441831264\n",
      "배치 인덱스 : 178\t|\t이동 손실 : 1.2823963598166095\n",
      "배치 인덱스 : 179\t|\t이동 손실 : 1.2822290407286747\n",
      "배치 인덱스 : 180\t|\t이동 손실 : 1.2824243978900802\n",
      "배치 인덱스 : 181\t|\t이동 손실 : 1.2835015248466322\n",
      "배치 인덱스 : 182\t|\t이동 손실 : 1.2834713022565578\n",
      "배치 인덱스 : 183\t|\t이동 손실 : 1.283283950841945\n",
      "배치 인덱스 : 184\t|\t이동 손실 : 1.2832710994256507\n",
      "배치 인덱스 : 185\t|\t이동 손실 : 1.2836293776830034\n",
      "배치 인덱스 : 186\t|\t이동 손실 : 1.2834354843047848\n",
      "배치 인덱스 : 187\t|\t이동 손실 : 1.2833713153575326\n",
      "배치 인덱스 : 188\t|\t이동 손실 : 1.2834264216599638\n",
      "배치 인덱스 : 189\t|\t이동 손실 : 1.28346065659272\n",
      "배치 인덱스 : 190\t|\t이동 손실 : 1.2835389800096677\n",
      "배치 인덱스 : 191\t|\t이동 손실 : 1.283775884037216\n",
      "배치 인덱스 : 192\t|\t이동 손실 : 1.284252371812731\n",
      "배치 인덱스 : 193\t|\t이동 손실 : 1.2841974988426126\n",
      "배치 인덱스 : 194\t|\t이동 손실 : 1.284551703012906\n",
      "배치 인덱스 : 195\t|\t이동 손실 : 1.2846359105742702\n",
      "배치 인덱스 : 196\t|\t이동 손실 : 1.2847674395227184\n",
      "배치 인덱스 : 197\t|\t이동 손실 : 1.2848800794042716\n",
      "배치 인덱스 : 198\t|\t이동 손실 : 1.285202545137261\n",
      "배치 인덱스 : 199\t|\t이동 손실 : 1.2853183609247203\n",
      "배치 인덱스 : 200\t|\t이동 손실 : 1.285978194492966\n",
      "배치 인덱스 : 201\t|\t이동 손실 : 1.2861920530253115\n",
      "배치 인덱스 : 202\t|\t이동 손실 : 1.2866787517012044\n",
      "배치 인덱스 : 203\t|\t이동 손실 : 1.2868991026691359\n",
      "배치 인덱스 : 204\t|\t이동 손실 : 1.2866732655501945\n",
      "배치 인덱스 : 205\t|\t이동 손실 : 1.2873431583052697\n",
      "배치 인덱스 : 206\t|\t이동 손실 : 1.2874258624182804\n",
      "배치 인덱스 : 207\t|\t이동 손실 : 1.2870336461525693\n",
      "배치 인덱스 : 208\t|\t이동 손실 : 1.286888569736024\n",
      "배치 인덱스 : 209\t|\t이동 손실 : 1.2868339442071457\n",
      "배치 인덱스 : 210\t|\t이동 손실 : 1.2869035163761877\n",
      "배치 인덱스 : 211\t|\t이동 손실 : 1.2869317852101234\n",
      "배치 인덱스 : 212\t|\t이동 손실 : 1.2872736616313736\n",
      "배치 인덱스 : 213\t|\t이동 손실 : 1.287547746551371\n",
      "배치 인덱스 : 214\t|\t이동 손실 : 1.2879360697990239\n",
      "배치 인덱스 : 215\t|\t이동 손실 : 1.288083870101858\n",
      "배치 인덱스 : 216\t|\t이동 손실 : 1.2883185302057574\n",
      "배치 인덱스 : 217\t|\t이동 손실 : 1.288499838168468\n",
      "배치 인덱스 : 218\t|\t이동 손실 : 1.2889447108795655\n",
      "배치 인덱스 : 219\t|\t이동 손실 : 1.2898060229691595\n",
      "배치 인덱스 : 220\t|\t이동 손실 : 1.289745139320512\n",
      "배치 인덱스 : 221\t|\t이동 손실 : 1.2896025567441376\n",
      "배치 인덱스 : 222\t|\t이동 손실 : 1.2897627000851484\n",
      "배치 인덱스 : 223\t|\t이동 손실 : 1.2897650381284103\n",
      "배치 인덱스 : 224\t|\t이동 손실 : 1.2892705604765151\n",
      "배치 인덱스 : 225\t|\t이동 손실 : 1.2896718477780842\n",
      "배치 인덱스 : 226\t|\t이동 손실 : 1.2894063169210495\n",
      "Epoch: 07 | Time: 13m 12s\n",
      "\tTrain Loss: 1.289 | Train PPL: 3.631\n",
      "\tValidation Loss: 1.715 | Validation PPL: 5.558\n",
      "에폭 : 7\n",
      "배치 인덱스 : 0\t|\t이동 손실 : 1.0767371654510498\n",
      "배치 인덱스 : 1\t|\t이동 손실 : 1.088497817516327\n",
      "배치 인덱스 : 2\t|\t이동 손실 : 1.0559438069661458\n",
      "배치 인덱스 : 3\t|\t이동 손실 : 1.1048839092254639\n",
      "배치 인덱스 : 4\t|\t이동 손실 : 1.1222713708877563\n",
      "배치 인덱스 : 5\t|\t이동 손실 : 1.108527143796285\n",
      "배치 인덱스 : 6\t|\t이동 손실 : 1.1094321523393902\n",
      "배치 인덱스 : 7\t|\t이동 손실 : 1.09305003285408\n",
      "배치 인덱스 : 8\t|\t이동 손실 : 1.0964374807145858\n",
      "배치 인덱스 : 9\t|\t이동 손실 : 1.0908033490180966\n",
      "배치 인덱스 : 10\t|\t이동 손실 : 1.0901645096865564\n",
      "배치 인덱스 : 11\t|\t이동 손실 : 1.0906604826450346\n",
      "배치 인덱스 : 12\t|\t이동 손실 : 1.0917431391202483\n",
      "배치 인덱스 : 13\t|\t이동 손실 : 1.095570351396288\n",
      "배치 인덱스 : 14\t|\t이동 손실 : 1.0999292055765786\n",
      "배치 인덱스 : 15\t|\t이동 손실 : 1.103445030748844\n",
      "배치 인덱스 : 16\t|\t이동 손실 : 1.1105024043251484\n",
      "배치 인덱스 : 17\t|\t이동 손실 : 1.1096070408821104\n",
      "배치 인덱스 : 18\t|\t이동 손실 : 1.1062580409802887\n",
      "배치 인덱스 : 19\t|\t이동 손실 : 1.109502029418945\n",
      "배치 인덱스 : 20\t|\t이동 손실 : 1.1068152416320072\n",
      "배치 인덱스 : 21\t|\t이동 손실 : 1.1055791865695603\n",
      "배치 인덱스 : 22\t|\t이동 손실 : 1.1093940683033152\n",
      "배치 인덱스 : 23\t|\t이동 손실 : 1.1079219033320742\n",
      "배치 인덱스 : 24\t|\t이동 손실 : 1.105256013870239\n",
      "배치 인덱스 : 25\t|\t이동 손실 : 1.109194865593543\n",
      "배치 인덱스 : 26\t|\t이동 손실 : 1.1108836951079188\n",
      "배치 인덱스 : 27\t|\t이동 손실 : 1.111486596720559\n",
      "배치 인덱스 : 28\t|\t이동 손실 : 1.1116349409366473\n",
      "배치 인덱스 : 29\t|\t이동 손실 : 1.1131986697514848\n",
      "배치 인덱스 : 30\t|\t이동 손실 : 1.1140035583126926\n",
      "배치 인덱스 : 31\t|\t이동 손실 : 1.1119173206388946\n",
      "배치 인덱스 : 32\t|\t이동 손실 : 1.1107107364770135\n",
      "배치 인덱스 : 33\t|\t이동 손실 : 1.1125087562729328\n",
      "배치 인덱스 : 34\t|\t이동 손실 : 1.1158636467797414\n",
      "배치 인덱스 : 35\t|\t이동 손실 : 1.1131760146882796\n",
      "배치 인덱스 : 36\t|\t이동 손실 : 1.1128337351051534\n",
      "배치 인덱스 : 37\t|\t이동 손실 : 1.11326159301557\n",
      "배치 인덱스 : 38\t|\t이동 손실 : 1.1136130858690307\n",
      "배치 인덱스 : 39\t|\t이동 손실 : 1.1129498869180676\n",
      "배치 인덱스 : 40\t|\t이동 손실 : 1.1125628046873137\n",
      "배치 인덱스 : 41\t|\t이동 손실 : 1.1166851094790866\n",
      "배치 인덱스 : 42\t|\t이동 손실 : 1.1167873338211414\n",
      "배치 인덱스 : 43\t|\t이동 손실 : 1.1192040687257592\n",
      "배치 인덱스 : 44\t|\t이동 손실 : 1.1208284298578897\n",
      "배치 인덱스 : 45\t|\t이동 손실 : 1.1223099879596543\n",
      "배치 인덱스 : 46\t|\t이동 손실 : 1.126640685061191\n",
      "배치 인덱스 : 47\t|\t이동 손실 : 1.128319223721822\n",
      "배치 인덱스 : 48\t|\t이동 손실 : 1.1289808093285074\n",
      "배치 인덱스 : 49\t|\t이동 손실 : 1.1278209733963014\n",
      "배치 인덱스 : 50\t|\t이동 손실 : 1.1280426534951904\n",
      "배치 인덱스 : 51\t|\t이동 손실 : 1.1294288360155549\n",
      "배치 인덱스 : 52\t|\t이동 손실 : 1.1295436238342864\n",
      "배치 인덱스 : 53\t|\t이동 손실 : 1.129247656574956\n",
      "배치 인덱스 : 54\t|\t이동 손실 : 1.1288079565221616\n",
      "배치 인덱스 : 55\t|\t이동 손실 : 1.1302510031632018\n",
      "배치 인덱스 : 56\t|\t이동 손실 : 1.130430424422549\n",
      "배치 인덱스 : 57\t|\t이동 손실 : 1.1299105163278256\n",
      "배치 인덱스 : 58\t|\t이동 손실 : 1.1306087607044288\n",
      "배치 인덱스 : 59\t|\t이동 손실 : 1.1314863900343581\n",
      "배치 인덱스 : 60\t|\t이동 손실 : 1.1325762975411342\n",
      "배치 인덱스 : 61\t|\t이동 손실 : 1.1330725377605813\n",
      "배치 인덱스 : 62\t|\t이동 손실 : 1.131930864046491\n",
      "배치 인덱스 : 63\t|\t이동 손실 : 1.1330205444246535\n",
      "배치 인덱스 : 64\t|\t이동 손실 : 1.134601974487305\n",
      "배치 인덱스 : 65\t|\t이동 손실 : 1.1341627185994931\n",
      "배치 인덱스 : 66\t|\t이동 손실 : 1.133531590006245\n",
      "배치 인덱스 : 67\t|\t이동 손실 : 1.1321677495451539\n",
      "배치 인덱스 : 68\t|\t이동 손실 : 1.1324619296668237\n",
      "배치 인덱스 : 69\t|\t이동 손실 : 1.133165071691786\n",
      "배치 인덱스 : 70\t|\t이동 손실 : 1.1328620457313434\n",
      "배치 인덱스 : 71\t|\t이동 손실 : 1.1324907905525636\n",
      "배치 인덱스 : 72\t|\t이동 손실 : 1.1327501192484821\n",
      "배치 인덱스 : 73\t|\t이동 손실 : 1.1336406743204277\n",
      "배치 인덱스 : 74\t|\t이동 손실 : 1.1324455690383917\n",
      "배치 인덱스 : 75\t|\t이동 손실 : 1.132957827103766\n",
      "배치 인덱스 : 76\t|\t이동 손실 : 1.1341476316575885\n",
      "배치 인덱스 : 77\t|\t이동 손실 : 1.1351194076049027\n",
      "배치 인덱스 : 78\t|\t이동 손실 : 1.1347746924508981\n",
      "배치 인덱스 : 79\t|\t이동 손실 : 1.1348707005381589\n",
      "배치 인덱스 : 80\t|\t이동 손실 : 1.1341899030002551\n",
      "배치 인덱스 : 81\t|\t이동 손실 : 1.1340106449476106\n",
      "배치 인덱스 : 82\t|\t이동 손실 : 1.1336494282067544\n",
      "배치 인덱스 : 83\t|\t이동 손실 : 1.1339691508383982\n",
      "배치 인덱스 : 84\t|\t이동 손실 : 1.1356879528831036\n",
      "배치 인덱스 : 85\t|\t이동 손실 : 1.1359085676281955\n",
      "배치 인덱스 : 86\t|\t이동 손실 : 1.1371974629917367\n",
      "배치 인덱스 : 87\t|\t이동 손실 : 1.1377985111691737\n",
      "배치 인덱스 : 88\t|\t이동 손실 : 1.1378251541866349\n",
      "배치 인덱스 : 89\t|\t이동 손실 : 1.137831325001187\n",
      "배치 인덱스 : 90\t|\t이동 손실 : 1.1380808641622358\n",
      "배치 인덱스 : 91\t|\t이동 손실 : 1.1380497903927516\n",
      "배치 인덱스 : 92\t|\t이동 손실 : 1.138209801848217\n",
      "배치 인덱스 : 93\t|\t이동 손실 : 1.1376694428159837\n",
      "배치 인덱스 : 94\t|\t이동 손실 : 1.137793604951156\n",
      "배치 인덱스 : 95\t|\t이동 손실 : 1.1387146438161533\n",
      "배치 인덱스 : 96\t|\t이동 손실 : 1.139374681354798\n",
      "배치 인덱스 : 97\t|\t이동 손실 : 1.1404665209809128\n",
      "배치 인덱스 : 98\t|\t이동 손실 : 1.1403686181463377\n",
      "배치 인덱스 : 99\t|\t이동 손실 : 1.14022491812706\n",
      "배치 인덱스 : 100\t|\t이동 손실 : 1.1409183835039045\n",
      "배치 인덱스 : 101\t|\t이동 손실 : 1.1410555418799906\n",
      "배치 인덱스 : 102\t|\t이동 손실 : 1.1416616567130229\n",
      "배치 인덱스 : 103\t|\t이동 손실 : 1.1420206553660908\n",
      "배치 인덱스 : 104\t|\t이동 손실 : 1.1424580358323597\n",
      "배치 인덱스 : 105\t|\t이동 손실 : 1.1418339947484575\n",
      "배치 인덱스 : 106\t|\t이동 손실 : 1.1421243988464926\n",
      "배치 인덱스 : 107\t|\t이동 손실 : 1.1426638905648832\n",
      "배치 인덱스 : 108\t|\t이동 손실 : 1.1420676281692785\n",
      "배치 인덱스 : 109\t|\t이동 손실 : 1.141899620402943\n",
      "배치 인덱스 : 110\t|\t이동 손실 : 1.14222450728889\n",
      "배치 인덱스 : 111\t|\t이동 손실 : 1.1428182678563255\n",
      "배치 인덱스 : 112\t|\t이동 손실 : 1.1427008588757135\n",
      "배치 인덱스 : 113\t|\t이동 손실 : 1.1429448033633984\n",
      "배치 인덱스 : 114\t|\t이동 손실 : 1.1430728839791338\n",
      "배치 인덱스 : 115\t|\t이동 손실 : 1.143549326164969\n",
      "배치 인덱스 : 116\t|\t이동 손실 : 1.1438214941921396\n",
      "배치 인덱스 : 117\t|\t이동 손실 : 1.1445020649392725\n",
      "배치 인덱스 : 118\t|\t이동 손실 : 1.1447040403590483\n",
      "배치 인덱스 : 119\t|\t이동 손실 : 1.144785996278127\n",
      "배치 인덱스 : 120\t|\t이동 손실 : 1.1440419894604643\n",
      "배치 인덱스 : 121\t|\t이동 손실 : 1.1448426002361736\n",
      "배치 인덱스 : 122\t|\t이동 손실 : 1.145597680797422\n",
      "배치 인덱스 : 123\t|\t이동 손실 : 1.1451361813852865\n",
      "배치 인덱스 : 124\t|\t이동 손실 : 1.1450473375320436\n",
      "배치 인덱스 : 125\t|\t이동 손실 : 1.1453749982137529\n",
      "배치 인덱스 : 126\t|\t이동 손실 : 1.1454632160231824\n",
      "배치 인덱스 : 127\t|\t이동 손실 : 1.1453910572454333\n",
      "배치 인덱스 : 128\t|\t이동 손실 : 1.1457256550012633\n",
      "배치 인덱스 : 129\t|\t이동 손실 : 1.146679241840656\n",
      "배치 인덱스 : 130\t|\t이동 손실 : 1.1464857500018053\n",
      "배치 인덱스 : 131\t|\t이동 손실 : 1.1469854342214987\n",
      "배치 인덱스 : 132\t|\t이동 손실 : 1.1468164149979898\n",
      "배치 인덱스 : 133\t|\t이동 손실 : 1.1476019007056506\n",
      "배치 인덱스 : 134\t|\t이동 손실 : 1.1483195304870604\n",
      "배치 인덱스 : 135\t|\t이동 손실 : 1.1489302419564302\n",
      "배치 인덱스 : 136\t|\t이동 손실 : 1.1490553660984455\n",
      "배치 인덱스 : 137\t|\t이동 손실 : 1.1495957555978193\n",
      "배치 인덱스 : 138\t|\t이동 손실 : 1.1498871029709739\n",
      "배치 인덱스 : 139\t|\t이동 손실 : 1.1495588728359765\n",
      "배치 인덱스 : 140\t|\t이동 손실 : 1.1497944720247957\n",
      "배치 인덱스 : 141\t|\t이동 손실 : 1.1497402568938024\n",
      "배치 인덱스 : 142\t|\t이동 손실 : 1.1501838168897827\n",
      "배치 인덱스 : 143\t|\t이동 손실 : 1.1509951353073118\n",
      "배치 인덱스 : 144\t|\t이동 손실 : 1.151198054182118\n",
      "배치 인덱스 : 145\t|\t이동 손실 : 1.1510769267604772\n",
      "배치 인덱스 : 146\t|\t이동 손실 : 1.151182319842228\n",
      "배치 인덱스 : 147\t|\t이동 손실 : 1.1511897219193945\n",
      "배치 인덱스 : 148\t|\t이동 손실 : 1.150412860332719\n",
      "배치 인덱스 : 149\t|\t이동 손실 : 1.1500252564748124\n",
      "배치 인덱스 : 150\t|\t이동 손실 : 1.150003192440563\n",
      "배치 인덱스 : 151\t|\t이동 손실 : 1.1505804305013851\n",
      "배치 인덱스 : 152\t|\t이동 손실 : 1.1506632940441948\n",
      "배치 인덱스 : 153\t|\t이동 손실 : 1.1509559115806176\n",
      "배치 인덱스 : 154\t|\t이동 손실 : 1.151307559013366\n",
      "배치 인덱스 : 155\t|\t이동 손실 : 1.1517014236022256\n",
      "배치 인덱스 : 156\t|\t이동 손실 : 1.151170644031208\n",
      "배치 인덱스 : 157\t|\t이동 손실 : 1.1517494388773464\n",
      "배치 인덱스 : 158\t|\t이동 손실 : 1.1527951460964267\n",
      "배치 인덱스 : 159\t|\t이동 손실 : 1.1533346220850937\n",
      "배치 인덱스 : 160\t|\t이동 손실 : 1.1536092291707571\n",
      "배치 인덱스 : 161\t|\t이동 손실 : 1.1543481026166744\n",
      "배치 인덱스 : 162\t|\t이동 손실 : 1.1546672202326762\n",
      "배치 인덱스 : 163\t|\t이동 손실 : 1.155302001935679\n",
      "배치 인덱스 : 164\t|\t이동 손실 : 1.155241891832062\n",
      "배치 인덱스 : 165\t|\t이동 손실 : 1.155272888850016\n",
      "배치 인덱스 : 166\t|\t이동 손실 : 1.1554287700595964\n",
      "배치 인덱스 : 167\t|\t이동 손실 : 1.1551378873132518\n",
      "배치 인덱스 : 168\t|\t이동 손실 : 1.1551691928558796\n",
      "배치 인덱스 : 169\t|\t이동 손실 : 1.1547116574119114\n",
      "배치 인덱스 : 170\t|\t이동 손실 : 1.1551990557832323\n",
      "배치 인덱스 : 171\t|\t이동 손실 : 1.1544964209545485\n",
      "배치 인덱스 : 172\t|\t이동 손실 : 1.1543231010437007\n",
      "배치 인덱스 : 173\t|\t이동 손실 : 1.1547894464142017\n",
      "배치 인덱스 : 174\t|\t이동 손실 : 1.1549673352922707\n",
      "배치 인덱스 : 175\t|\t이동 손실 : 1.1553846502845933\n",
      "배치 인덱스 : 176\t|\t이동 손실 : 1.1553219785798063\n",
      "배치 인덱스 : 177\t|\t이동 손실 : 1.1551359362816538\n",
      "배치 인덱스 : 178\t|\t이동 손실 : 1.155469603378679\n",
      "배치 인덱스 : 179\t|\t이동 손실 : 1.1554148726993132\n",
      "배치 인덱스 : 180\t|\t이동 손실 : 1.155615962671311\n",
      "배치 인덱스 : 181\t|\t이동 손실 : 1.1559772268756399\n",
      "배치 인덱스 : 182\t|\t이동 손실 : 1.156040202724477\n",
      "배치 인덱스 : 183\t|\t이동 손실 : 1.156113014273021\n",
      "배치 인덱스 : 184\t|\t이동 손실 : 1.1564400363612812\n",
      "배치 인덱스 : 185\t|\t이동 손실 : 1.1566719034666648\n",
      "배치 인덱스 : 186\t|\t이동 손실 : 1.156381194604271\n",
      "배치 인덱스 : 187\t|\t이동 손실 : 1.1564797575169412\n",
      "배치 인덱스 : 188\t|\t이동 손실 : 1.1571038955103143\n",
      "배치 인덱스 : 189\t|\t이동 손실 : 1.1573803976962431\n",
      "배치 인덱스 : 190\t|\t이동 손실 : 1.1579141061343439\n",
      "배치 인덱스 : 191\t|\t이동 손실 : 1.1581212307016047\n",
      "배치 인덱스 : 192\t|\t이동 손실 : 1.1583081310894814\n",
      "배치 인덱스 : 193\t|\t이동 손실 : 1.1589570721400144\n",
      "배치 인덱스 : 194\t|\t이동 손실 : 1.159219744266607\n",
      "배치 인덱스 : 195\t|\t이동 손실 : 1.158937055845649\n",
      "배치 인덱스 : 196\t|\t이동 손실 : 1.1586340296692041\n",
      "배치 인덱스 : 197\t|\t이동 손실 : 1.1589767053873845\n",
      "배치 인덱스 : 198\t|\t이동 손실 : 1.1591935942520442\n",
      "배치 인덱스 : 199\t|\t이동 손실 : 1.1602098703384394\n",
      "배치 인덱스 : 200\t|\t이동 손실 : 1.1601867076769392\n",
      "배치 인덱스 : 201\t|\t이동 손실 : 1.1603772752355817\n",
      "배치 인덱스 : 202\t|\t이동 손실 : 1.1609020350601869\n",
      "배치 인덱스 : 203\t|\t이동 손실 : 1.1610670463711603\n",
      "배치 인덱스 : 204\t|\t이동 손실 : 1.1611460174002295\n",
      "배치 인덱스 : 205\t|\t이동 손실 : 1.1615108500406577\n",
      "배치 인덱스 : 206\t|\t이동 손실 : 1.1615240378080356\n",
      "배치 인덱스 : 207\t|\t이동 손실 : 1.1619035498454018\n",
      "배치 인덱스 : 208\t|\t이동 손실 : 1.1614726998589253\n",
      "배치 인덱스 : 209\t|\t이동 손실 : 1.1615202313377742\n",
      "배치 인덱스 : 210\t|\t이동 손실 : 1.1616796774886793\n",
      "배치 인덱스 : 211\t|\t이동 손실 : 1.1626505997945675\n",
      "배치 인덱스 : 212\t|\t이동 손실 : 1.1630230996530377\n",
      "배치 인덱스 : 213\t|\t이동 손실 : 1.1634070761849944\n",
      "배치 인덱스 : 214\t|\t이동 손실 : 1.1632928388063295\n",
      "배치 인덱스 : 215\t|\t이동 손실 : 1.1633988387054865\n",
      "배치 인덱스 : 216\t|\t이동 손실 : 1.1633338955690233\n",
      "배치 인덱스 : 217\t|\t이동 손실 : 1.1634145986049547\n",
      "배치 인덱스 : 218\t|\t이동 손실 : 1.1632296734204575\n",
      "배치 인덱스 : 219\t|\t이동 손실 : 1.1634780488230965\n",
      "배치 인덱스 : 220\t|\t이동 손실 : 1.163704502636491\n",
      "배치 인덱스 : 221\t|\t이동 손실 : 1.1639231883727752\n",
      "배치 인덱스 : 222\t|\t이동 손실 : 1.16427627914155\n",
      "배치 인덱스 : 223\t|\t이동 손실 : 1.1640545592776366\n",
      "배치 인덱스 : 224\t|\t이동 손실 : 1.1640955029593574\n",
      "배치 인덱스 : 225\t|\t이동 손실 : 1.163876874256978\n",
      "배치 인덱스 : 226\t|\t이동 손실 : 1.1640062489698637\n",
      "Epoch: 08 | Time: 13m 12s\n",
      "\tTrain Loss: 1.164 | Train PPL: 3.203\n",
      "\tValidation Loss: 1.696 | Validation PPL: 5.451\n",
      "에폭 : 8\n",
      "배치 인덱스 : 0\t|\t이동 손실 : 1.0292749404907227\n",
      "배치 인덱스 : 1\t|\t이동 손실 : 0.9862106740474701\n",
      "배치 인덱스 : 2\t|\t이동 손실 : 0.9624722798665365\n",
      "배치 인덱스 : 3\t|\t이동 손실 : 0.9508009701967239\n",
      "배치 인덱스 : 4\t|\t이동 손실 : 0.9542161345481872\n",
      "배치 인덱스 : 5\t|\t이동 손실 : 0.9754268030325571\n",
      "배치 인덱스 : 6\t|\t이동 손실 : 0.9747400624411446\n",
      "배치 인덱스 : 7\t|\t이동 손실 : 0.966052457690239\n",
      "배치 인덱스 : 8\t|\t이동 손실 : 0.9615352153778076\n",
      "배치 인덱스 : 9\t|\t이동 손실 : 0.959658008813858\n",
      "배치 인덱스 : 10\t|\t이동 손실 : 0.9533284414898265\n",
      "배치 인덱스 : 11\t|\t이동 손실 : 0.9590005427598953\n",
      "배치 인덱스 : 12\t|\t이동 손실 : 0.9508445308758662\n",
      "배치 인덱스 : 13\t|\t이동 손실 : 0.953987717628479\n",
      "배치 인덱스 : 14\t|\t이동 손실 : 0.9515770872433981\n",
      "배치 인덱스 : 15\t|\t이동 손실 : 0.953356746584177\n",
      "배치 인덱스 : 16\t|\t이동 손실 : 0.9566142033128178\n",
      "배치 인덱스 : 17\t|\t이동 손실 : 0.9582152234183418\n",
      "배치 인덱스 : 18\t|\t이동 손실 : 0.9593486754517806\n",
      "배치 인덱스 : 19\t|\t이동 손실 : 0.965159198641777\n",
      "배치 인덱스 : 20\t|\t이동 손실 : 0.9650785554023016\n",
      "배치 인덱스 : 21\t|\t이동 손실 : 0.9693743017586794\n",
      "배치 인덱스 : 22\t|\t이동 손실 : 0.9693524267362511\n",
      "배치 인덱스 : 23\t|\t이동 손실 : 0.9712611238161722\n",
      "배치 인덱스 : 24\t|\t이동 손실 : 0.9734571647644042\n",
      "배치 인덱스 : 25\t|\t이동 손실 : 0.9741592177977928\n",
      "배치 인덱스 : 26\t|\t이동 손실 : 0.9769545837684913\n",
      "배치 인덱스 : 27\t|\t이동 손실 : 0.9789286681583949\n",
      "배치 인덱스 : 28\t|\t이동 손실 : 0.9781020427572316\n",
      "배치 인덱스 : 29\t|\t이동 손실 : 0.9813511729240417\n",
      "배치 인덱스 : 30\t|\t이동 손실 : 0.9819967400643134\n",
      "배치 인덱스 : 31\t|\t이동 손실 : 0.9859857968986034\n",
      "배치 인덱스 : 32\t|\t이동 손실 : 0.9870336814360186\n",
      "배치 인덱스 : 33\t|\t이동 손실 : 0.9887697275947123\n",
      "배치 인덱스 : 34\t|\t이동 손실 : 0.9898868833269392\n",
      "배치 인덱스 : 35\t|\t이동 손실 : 0.9915770557191637\n",
      "배치 인덱스 : 36\t|\t이동 손실 : 0.9904102360880053\n",
      "배치 인덱스 : 37\t|\t이동 손실 : 0.9895558451351366\n",
      "배치 인덱스 : 38\t|\t이동 손실 : 0.9892294972370832\n",
      "배치 인덱스 : 39\t|\t이동 손실 : 0.9889051795005798\n",
      "배치 인덱스 : 40\t|\t이동 손실 : 0.9908487447878209\n",
      "배치 인덱스 : 41\t|\t이동 손실 : 0.991614472298395\n",
      "배치 인덱스 : 42\t|\t이동 손실 : 0.992752285890801\n",
      "배치 인덱스 : 43\t|\t이동 손실 : 0.9916045652194456\n",
      "배치 인덱스 : 44\t|\t이동 손실 : 0.9938814123471578\n",
      "배치 인덱스 : 45\t|\t이동 손실 : 0.9945320551810057\n",
      "배치 인덱스 : 46\t|\t이동 손실 : 0.9960271082025893\n",
      "배치 인덱스 : 47\t|\t이동 손실 : 0.9967279670139154\n",
      "배치 인덱스 : 48\t|\t이동 손실 : 0.9992138743400574\n",
      "배치 인덱스 : 49\t|\t이동 손실 : 1.0008956611156463\n",
      "배치 인덱스 : 50\t|\t이동 손실 : 1.0011689510999942\n",
      "배치 인덱스 : 51\t|\t이동 손실 : 1.00250917329238\n",
      "배치 인덱스 : 52\t|\t이동 손실 : 1.0025840334172518\n",
      "배치 인덱스 : 53\t|\t이동 손실 : 1.002620095456088\n",
      "배치 인덱스 : 54\t|\t이동 손실 : 1.0033212997696617\n",
      "배치 인덱스 : 55\t|\t이동 손실 : 1.0048662817903928\n",
      "배치 인덱스 : 56\t|\t이동 손실 : 1.0058595454483703\n",
      "배치 인덱스 : 57\t|\t이동 손실 : 1.0058964871127032\n",
      "배치 인덱스 : 58\t|\t이동 손실 : 1.0065258569636588\n",
      "배치 인덱스 : 59\t|\t이동 손실 : 1.0065851877133052\n",
      "배치 인덱스 : 60\t|\t이동 손실 : 1.0071315306131958\n",
      "배치 인덱스 : 61\t|\t이동 손실 : 1.0068373785864924\n",
      "배치 인덱스 : 62\t|\t이동 손실 : 1.0080886842712524\n",
      "배치 인덱스 : 63\t|\t이동 손실 : 1.007878601551056\n",
      "배치 인덱스 : 64\t|\t이동 손실 : 1.00844144821167\n",
      "배치 인덱스 : 65\t|\t이동 손실 : 1.0090080698331196\n",
      "배치 인덱스 : 66\t|\t이동 손실 : 1.0093331675031292\n",
      "배치 인덱스 : 67\t|\t이동 손실 : 1.0089518322664148\n",
      "배치 인덱스 : 68\t|\t이동 손실 : 1.0096275167188782\n",
      "배치 인덱스 : 69\t|\t이동 손실 : 1.0097714373043605\n",
      "배치 인덱스 : 70\t|\t이동 손실 : 1.0098897957466018\n",
      "배치 인덱스 : 71\t|\t이동 손실 : 1.0099606298738055\n",
      "배치 인덱스 : 72\t|\t이동 손실 : 1.01057689647152\n",
      "배치 인덱스 : 73\t|\t이동 손실 : 1.0116912497056498\n",
      "배치 인덱스 : 74\t|\t이동 손실 : 1.011905916531881\n",
      "배치 인덱스 : 75\t|\t이동 손실 : 1.0127756768151335\n",
      "배치 인덱스 : 76\t|\t이동 손실 : 1.0130819190632214\n",
      "배치 인덱스 : 77\t|\t이동 손실 : 1.0146104448880906\n",
      "배치 인덱스 : 78\t|\t이동 손실 : 1.0154215761377843\n",
      "배치 인덱스 : 79\t|\t이동 손실 : 1.0161385491490365\n",
      "배치 인덱스 : 80\t|\t이동 손실 : 1.016307293632884\n",
      "배치 인덱스 : 81\t|\t이동 손실 : 1.0167191406575644\n",
      "배치 인덱스 : 82\t|\t이동 손실 : 1.0166924861540276\n",
      "배치 인덱스 : 83\t|\t이동 손실 : 1.0169482954910822\n",
      "배치 인덱스 : 84\t|\t이동 손실 : 1.016979340945973\n",
      "배치 인덱스 : 85\t|\t이동 손실 : 1.0172395983407663\n",
      "배치 인덱스 : 86\t|\t이동 손실 : 1.019172269722511\n",
      "배치 인덱스 : 87\t|\t이동 손실 : 1.0192989747632633\n",
      "배치 인덱스 : 88\t|\t이동 손실 : 1.0195604830645442\n",
      "배치 인덱스 : 89\t|\t이동 손실 : 1.0201154218779669\n",
      "배치 인덱스 : 90\t|\t이동 손실 : 1.0207207753108096\n",
      "배치 인덱스 : 91\t|\t이동 손실 : 1.0205650977466416\n",
      "배치 인덱스 : 92\t|\t이동 손실 : 1.0212085926404562\n",
      "배치 인덱스 : 93\t|\t이동 손실 : 1.0221474081911937\n",
      "배치 인덱스 : 94\t|\t이동 손실 : 1.023255466160021\n",
      "배치 인덱스 : 95\t|\t이동 손실 : 1.022805317615469\n",
      "배치 인덱스 : 96\t|\t이동 손실 : 1.0230543545840938\n",
      "배치 인덱스 : 97\t|\t이동 손실 : 1.0234870843741355\n",
      "배치 인덱스 : 98\t|\t이동 손실 : 1.023921632405483\n",
      "배치 인덱스 : 99\t|\t이동 손실 : 1.0241072243452067\n",
      "배치 인덱스 : 100\t|\t이동 손실 : 1.0240239158715347\n",
      "배치 인덱스 : 101\t|\t이동 손실 : 1.022935275353637\n",
      "배치 인덱스 : 102\t|\t이동 손실 : 1.0229844022723074\n",
      "배치 인덱스 : 103\t|\t이동 손실 : 1.023489073492013\n",
      "배치 인덱스 : 104\t|\t이동 손실 : 1.0239338937259852\n",
      "배치 인덱스 : 105\t|\t이동 손실 : 1.0242699424050885\n",
      "배치 인덱스 : 106\t|\t이동 손실 : 1.0245349824985608\n",
      "배치 인덱스 : 107\t|\t이동 손실 : 1.0248075431143793\n",
      "배치 인덱스 : 108\t|\t이동 손실 : 1.0249401106746916\n",
      "배치 인덱스 : 109\t|\t이동 손실 : 1.0250461269508706\n",
      "배치 인덱스 : 110\t|\t이동 손실 : 1.0259853349075658\n",
      "배치 인덱스 : 111\t|\t이동 손실 : 1.0259764987443172\n",
      "배치 인덱스 : 112\t|\t이동 손실 : 1.0263692177502453\n",
      "배치 인덱스 : 113\t|\t이동 손실 : 1.0261936736734287\n",
      "배치 인덱스 : 114\t|\t이동 손실 : 1.026670282301695\n",
      "배치 인덱스 : 115\t|\t이동 손실 : 1.0276060325318366\n",
      "배치 인덱스 : 116\t|\t이동 손실 : 1.0286857322749925\n",
      "배치 인덱스 : 117\t|\t이동 손실 : 1.029673912262512\n",
      "배치 인덱스 : 118\t|\t이동 손실 : 1.0303730318526256\n",
      "배치 인덱스 : 119\t|\t이동 손실 : 1.0310539806882537\n",
      "배치 인덱스 : 120\t|\t이동 손실 : 1.0315072501986478\n",
      "배치 인덱스 : 121\t|\t이동 손실 : 1.0321398724298005\n",
      "배치 인덱스 : 122\t|\t이동 손실 : 1.0321182046479322\n",
      "배치 인덱스 : 123\t|\t이동 손실 : 1.0326108235505316\n",
      "배치 인덱스 : 124\t|\t이동 손실 : 1.03313988161087\n",
      "배치 인덱스 : 125\t|\t이동 손실 : 1.0336952412885327\n",
      "배치 인덱스 : 126\t|\t이동 손실 : 1.0339563592212402\n",
      "배치 인덱스 : 127\t|\t이동 손실 : 1.0336552225053306\n",
      "배치 인덱스 : 128\t|\t이동 손실 : 1.0339534957279526\n",
      "배치 인덱스 : 129\t|\t이동 손실 : 1.0339906435746409\n",
      "배치 인덱스 : 130\t|\t이동 손실 : 1.033862815558455\n",
      "배치 인덱스 : 131\t|\t이동 손실 : 1.0340073081580072\n",
      "배치 인덱스 : 132\t|\t이동 손실 : 1.033906805784182\n",
      "배치 인덱스 : 133\t|\t이동 손실 : 1.0343638044684678\n",
      "배치 인덱스 : 134\t|\t이동 손실 : 1.0347039787857617\n",
      "배치 인덱스 : 135\t|\t이동 손실 : 1.0345602938357519\n",
      "배치 인덱스 : 136\t|\t이동 손실 : 1.035096659277477\n",
      "배치 인덱스 : 137\t|\t이동 손실 : 1.0355772281038584\n",
      "배치 인덱스 : 138\t|\t이동 손실 : 1.035968491499372\n",
      "배치 인덱스 : 139\t|\t이동 손실 : 1.0363232050623208\n",
      "배치 인덱스 : 140\t|\t이동 손실 : 1.0362548735124841\n",
      "배치 인덱스 : 141\t|\t이동 손실 : 1.036057051638482\n",
      "배치 인덱스 : 142\t|\t이동 손실 : 1.036520694519256\n",
      "배치 인덱스 : 143\t|\t이동 손실 : 1.036824790967835\n",
      "배치 인덱스 : 144\t|\t이동 손실 : 1.037272396580926\n",
      "배치 인덱스 : 145\t|\t이동 손실 : 1.0376150714208\n",
      "배치 인덱스 : 146\t|\t이동 손실 : 1.0380401011226936\n",
      "배치 인덱스 : 147\t|\t이동 손실 : 1.0385581754349371\n",
      "배치 인덱스 : 148\t|\t이동 손실 : 1.0385008994364897\n",
      "배치 인덱스 : 149\t|\t이동 손실 : 1.0390461587905881\n",
      "배치 인덱스 : 150\t|\t이동 손실 : 1.0398506699808383\n",
      "배치 인덱스 : 151\t|\t이동 손실 : 1.0403044255156264\n",
      "배치 인덱스 : 152\t|\t이동 손실 : 1.0406569639841714\n",
      "배치 인덱스 : 153\t|\t이동 손실 : 1.0409622703279766\n",
      "배치 인덱스 : 154\t|\t이동 손실 : 1.0413762100281252\n",
      "배치 인덱스 : 155\t|\t이동 손실 : 1.0416377721688683\n",
      "배치 인덱스 : 156\t|\t이동 손실 : 1.041345971405126\n",
      "배치 인덱스 : 157\t|\t이동 손실 : 1.0414250130894813\n",
      "배치 인덱스 : 158\t|\t이동 손실 : 1.0416758750219761\n",
      "배치 인덱스 : 159\t|\t이동 손실 : 1.0414671063423153\n",
      "배치 인덱스 : 160\t|\t이동 손실 : 1.0415834662336736\n",
      "배치 인덱스 : 161\t|\t이동 손실 : 1.0420457617736152\n",
      "배치 인덱스 : 162\t|\t이동 손실 : 1.0419546526633883\n",
      "배치 인덱스 : 163\t|\t이동 손실 : 1.0425538682356108\n",
      "배치 인덱스 : 164\t|\t이동 손실 : 1.0423500732942055\n",
      "배치 인덱스 : 165\t|\t이동 손실 : 1.04264100847474\n",
      "배치 인덱스 : 166\t|\t이동 손실 : 1.0433425624927355\n",
      "배치 인덱스 : 167\t|\t이동 손실 : 1.0442345745506736\n",
      "배치 인덱스 : 168\t|\t이동 손실 : 1.0444731782879344\n",
      "배치 인덱스 : 169\t|\t이동 손실 : 1.0446903221747448\n",
      "배치 인덱스 : 170\t|\t이동 손실 : 1.0452475903326999\n",
      "배치 인덱스 : 171\t|\t이동 손실 : 1.0453667994155433\n",
      "배치 인덱스 : 172\t|\t이동 손실 : 1.0450784398641193\n",
      "배치 인덱스 : 173\t|\t이동 손실 : 1.045372236391593\n",
      "배치 인덱스 : 174\t|\t이동 손실 : 1.0453129179137086\n",
      "배치 인덱스 : 175\t|\t이동 손실 : 1.0450760583308603\n",
      "배치 인덱스 : 176\t|\t이동 손실 : 1.0457624806522643\n",
      "배치 인덱스 : 177\t|\t이동 손실 : 1.045898188031121\n",
      "배치 인덱스 : 178\t|\t이동 손실 : 1.045625904418902\n",
      "배치 인덱스 : 179\t|\t이동 손실 : 1.045659920242097\n",
      "배치 인덱스 : 180\t|\t이동 손실 : 1.0461620118736557\n",
      "배치 인덱스 : 181\t|\t이동 손실 : 1.0458973760788253\n",
      "배치 인덱스 : 182\t|\t이동 손실 : 1.0465727298637553\n",
      "배치 인덱스 : 183\t|\t이동 손실 : 1.046867414337137\n",
      "배치 인덱스 : 184\t|\t이동 손실 : 1.0468171515980278\n",
      "배치 인덱스 : 185\t|\t이동 손실 : 1.0468624083585631\n",
      "배치 인덱스 : 186\t|\t이동 손실 : 1.0466409427596919\n",
      "배치 인덱스 : 187\t|\t이동 손실 : 1.0470562073144503\n",
      "배치 인덱스 : 188\t|\t이동 손실 : 1.0469371594449195\n",
      "배치 인덱스 : 189\t|\t이동 손실 : 1.047773407948644\n",
      "배치 인덱스 : 190\t|\t이동 손실 : 1.0480914992811787\n",
      "배치 인덱스 : 191\t|\t이동 손실 : 1.048321501972774\n",
      "배치 인덱스 : 192\t|\t이동 손실 : 1.0482862764689582\n",
      "배치 인덱스 : 193\t|\t이동 손실 : 1.0486790393431156\n",
      "배치 인덱스 : 194\t|\t이동 손실 : 1.0490096963368922\n",
      "배치 인덱스 : 195\t|\t이동 손실 : 1.0490893450926755\n",
      "배치 인덱스 : 196\t|\t이동 손실 : 1.049545482633077\n",
      "배치 인덱스 : 197\t|\t이동 손실 : 1.0495654431858443\n",
      "배치 인덱스 : 198\t|\t이동 손실 : 1.0494837584207999\n",
      "배치 인덱스 : 199\t|\t이동 손실 : 1.0496243670582766\n",
      "배치 인덱스 : 200\t|\t이동 손실 : 1.0490890169025056\n",
      "배치 인덱스 : 201\t|\t이동 손실 : 1.0493914901029942\n",
      "배치 인덱스 : 202\t|\t이동 손실 : 1.04993252360762\n",
      "배치 인덱스 : 203\t|\t이동 손실 : 1.0506976617901929\n",
      "배치 인덱스 : 204\t|\t이동 손실 : 1.0510189739669238\n",
      "배치 인덱스 : 205\t|\t이동 손실 : 1.0507255937289262\n",
      "배치 인덱스 : 206\t|\t이동 손실 : 1.0511550459884786\n",
      "배치 인덱스 : 207\t|\t이동 손실 : 1.0509555907203596\n",
      "배치 인덱스 : 208\t|\t이동 손실 : 1.0511226328936485\n",
      "배치 인덱스 : 209\t|\t이동 손실 : 1.0510966073899037\n",
      "배치 인덱스 : 210\t|\t이동 손실 : 1.0508446546527441\n",
      "배치 인덱스 : 211\t|\t이동 손실 : 1.050915086606763\n",
      "배치 인덱스 : 212\t|\t이동 손실 : 1.0509886215550235\n",
      "배치 인덱스 : 213\t|\t이동 손실 : 1.0512199830786086\n",
      "배치 인덱스 : 214\t|\t이동 손실 : 1.0515556573867795\n",
      "배치 인덱스 : 215\t|\t이동 손실 : 1.0518543273210523\n",
      "배치 인덱스 : 216\t|\t이동 손실 : 1.0521279897557974\n",
      "배치 인덱스 : 217\t|\t이동 손실 : 1.0526263773988145\n",
      "배치 인덱스 : 218\t|\t이동 손실 : 1.053265663586795\n",
      "배치 인덱스 : 219\t|\t이동 손실 : 1.0535318580540742\n",
      "배치 인덱스 : 220\t|\t이동 손실 : 1.053701370549957\n",
      "배치 인덱스 : 221\t|\t이동 손실 : 1.053940103397713\n",
      "배치 인덱스 : 222\t|\t이동 손실 : 1.0540958573465389\n",
      "배치 인덱스 : 223\t|\t이동 손실 : 1.0544132169868263\n",
      "배치 인덱스 : 224\t|\t이동 손실 : 1.0545554166369966\n",
      "배치 인덱스 : 225\t|\t이동 손실 : 1.0543685402490395\n",
      "배치 인덱스 : 226\t|\t이동 손실 : 1.054597440795226\n",
      "Epoch: 09 | Time: 13m 20s\n",
      "\tTrain Loss: 1.055 | Train PPL: 2.871\n",
      "\tValidation Loss: 1.691 | Validation PPL: 5.424\n",
      "에폭 : 9\n",
      "배치 인덱스 : 0\t|\t이동 손실 : 0.8716952800750732\n",
      "배치 인덱스 : 1\t|\t이동 손실 : 0.8965635895729065\n",
      "배치 인덱스 : 2\t|\t이동 손실 : 0.9031986196835836\n",
      "배치 인덱스 : 3\t|\t이동 손실 : 0.9239140003919601\n",
      "배치 인덱스 : 4\t|\t이동 손실 : 0.9239734292030335\n",
      "배치 인덱스 : 5\t|\t이동 손실 : 0.9205188353856405\n",
      "배치 인덱스 : 6\t|\t이동 손실 : 0.9301740782601493\n",
      "배치 인덱스 : 7\t|\t이동 손실 : 0.9272373542189598\n",
      "배치 인덱스 : 8\t|\t이동 손실 : 0.9214783509572347\n",
      "배치 인덱스 : 9\t|\t이동 손실 : 0.9145670354366303\n",
      "배치 인덱스 : 10\t|\t이동 손실 : 0.9094708453525197\n",
      "배치 인덱스 : 11\t|\t이동 손실 : 0.9131105045477549\n",
      "배치 인덱스 : 12\t|\t이동 손실 : 0.9117774000534644\n",
      "배치 인덱스 : 13\t|\t이동 손실 : 0.913465827703476\n",
      "배치 인덱스 : 14\t|\t이동 손실 : 0.910105554262797\n",
      "배치 인덱스 : 15\t|\t이동 손실 : 0.9133552461862564\n",
      "배치 인덱스 : 16\t|\t이동 손실 : 0.9158747757182402\n",
      "배치 인덱스 : 17\t|\t이동 손실 : 0.9144845671123928\n",
      "배치 인덱스 : 18\t|\t이동 손실 : 0.9155766116945366\n",
      "배치 인덱스 : 19\t|\t이동 손실 : 0.9167107313871383\n",
      "배치 인덱스 : 20\t|\t이동 손실 : 0.9193204243977864\n",
      "배치 인덱스 : 21\t|\t이동 손실 : 0.9151897809722206\n",
      "배치 인덱스 : 22\t|\t이동 손실 : 0.9171393539594567\n",
      "배치 인덱스 : 23\t|\t이동 손실 : 0.9125896940628687\n",
      "배치 인덱스 : 24\t|\t이동 손실 : 0.913102879524231\n",
      "배치 인덱스 : 25\t|\t이동 손실 : 0.9152880494411175\n",
      "배치 인덱스 : 26\t|\t이동 손실 : 0.9143459708602341\n",
      "배치 인덱스 : 27\t|\t이동 손실 : 0.9138856892074858\n",
      "배치 인덱스 : 28\t|\t이동 손실 : 0.9157038228265171\n",
      "배치 인덱스 : 29\t|\t이동 손실 : 0.9162204802036286\n",
      "배치 인덱스 : 30\t|\t이동 손실 : 0.914757090230142\n",
      "배치 인덱스 : 31\t|\t이동 손실 : 0.9128203205764294\n",
      "배치 인덱스 : 32\t|\t이동 손실 : 0.9116388577403445\n",
      "배치 인덱스 : 33\t|\t이동 손실 : 0.9126462235170253\n",
      "배치 인덱스 : 34\t|\t이동 손실 : 0.9111908401761737\n",
      "배치 인덱스 : 35\t|\t이동 손실 : 0.9107466124826008\n",
      "배치 인덱스 : 36\t|\t이동 손실 : 0.9101742151621226\n",
      "배치 인덱스 : 37\t|\t이동 손실 : 0.9135887842429312\n",
      "배치 인덱스 : 38\t|\t이동 손실 : 0.9133015825198247\n",
      "배치 인덱스 : 39\t|\t이동 손실 : 0.9135504037141801\n",
      "배치 인덱스 : 40\t|\t이동 손실 : 0.9126846412333047\n",
      "배치 인덱스 : 41\t|\t이동 손실 : 0.9137330793199085\n",
      "배치 인덱스 : 42\t|\t이동 손실 : 0.9132245252298755\n",
      "배치 인덱스 : 43\t|\t이동 손실 : 0.9149911959062924\n",
      "배치 인덱스 : 44\t|\t이동 손실 : 0.9150610499911839\n",
      "배치 인덱스 : 45\t|\t이동 손실 : 0.917016018991885\n",
      "배치 인덱스 : 46\t|\t이동 손실 : 0.9173243071170564\n",
      "배치 인덱스 : 47\t|\t이동 손실 : 0.9165267335871856\n",
      "배치 인덱스 : 48\t|\t이동 손실 : 0.9184414939004548\n",
      "배치 인덱스 : 49\t|\t이동 손실 : 0.9167461860179902\n",
      "배치 인덱스 : 50\t|\t이동 손실 : 0.9157381244734223\n",
      "배치 인덱스 : 51\t|\t이동 손실 : 0.9156440301583364\n",
      "배치 인덱스 : 52\t|\t이동 손실 : 0.9173840947870939\n",
      "배치 인덱스 : 53\t|\t이동 손실 : 0.9168027076456283\n",
      "배치 인덱스 : 54\t|\t이동 손실 : 0.91634667895057\n",
      "배치 인덱스 : 55\t|\t이동 손실 : 0.9173639257039344\n",
      "배치 인덱스 : 56\t|\t이동 손실 : 0.9172910284577757\n",
      "배치 인덱스 : 57\t|\t이동 손실 : 0.9171489189411034\n",
      "배치 인덱스 : 58\t|\t이동 손실 : 0.9167286895089233\n",
      "배치 인덱스 : 59\t|\t이동 손실 : 0.9163766463597618\n",
      "배치 인덱스 : 60\t|\t이동 손실 : 0.9167904316401875\n",
      "배치 인덱스 : 61\t|\t이동 손실 : 0.9174804389476778\n",
      "배치 인덱스 : 62\t|\t이동 손실 : 0.917343646760971\n",
      "배치 인덱스 : 63\t|\t이동 손실 : 0.9178040185943248\n",
      "배치 인덱스 : 64\t|\t이동 손실 : 0.9192853991801925\n",
      "배치 인덱스 : 65\t|\t이동 손실 : 0.9199346629056067\n",
      "배치 인덱스 : 66\t|\t이동 손실 : 0.919619336946687\n",
      "배치 인덱스 : 67\t|\t이동 손실 : 0.9198848955771505\n",
      "배치 인덱스 : 68\t|\t이동 손실 : 0.9199564102767173\n",
      "배치 인덱스 : 69\t|\t이동 손실 : 0.9211810699531012\n",
      "배치 인덱스 : 70\t|\t이동 손실 : 0.9220273754966093\n",
      "배치 인덱스 : 71\t|\t이동 손실 : 0.9224767519368068\n",
      "배치 인덱스 : 72\t|\t이동 손실 : 0.9214277790017326\n",
      "배치 인덱스 : 73\t|\t이동 손실 : 0.9211132639163251\n",
      "배치 인덱스 : 74\t|\t이동 손실 : 0.9213652269045514\n",
      "배치 인덱스 : 75\t|\t이동 손실 : 0.9225683690685976\n",
      "배치 인덱스 : 76\t|\t이동 손실 : 0.921960590721725\n",
      "배치 인덱스 : 77\t|\t이동 손실 : 0.9218584963908564\n",
      "배치 인덱스 : 78\t|\t이동 손실 : 0.9221860351441783\n",
      "배치 인덱스 : 79\t|\t이동 손실 : 0.9227348126471043\n",
      "배치 인덱스 : 80\t|\t이동 손실 : 0.9228267507788577\n",
      "배치 인덱스 : 81\t|\t이동 손실 : 0.9239973905609876\n",
      "배치 인덱스 : 82\t|\t이동 손실 : 0.9239626354481801\n",
      "배치 인덱스 : 83\t|\t이동 손실 : 0.9247003424735297\n",
      "배치 인덱스 : 84\t|\t이동 손실 : 0.9245031440959258\n",
      "배치 인덱스 : 85\t|\t이동 손실 : 0.9248236015785574\n",
      "배치 인덱스 : 86\t|\t이동 손실 : 0.9243145811146705\n",
      "배치 인덱스 : 87\t|\t이동 손실 : 0.9246348786083136\n",
      "배치 인덱스 : 88\t|\t이동 손실 : 0.9243323267175911\n",
      "배치 인덱스 : 89\t|\t이동 손실 : 0.9244645959801145\n",
      "배치 인덱스 : 90\t|\t이동 손실 : 0.9245677989917799\n",
      "배치 인덱스 : 91\t|\t이동 손실 : 0.925627834123114\n",
      "배치 인덱스 : 92\t|\t이동 손실 : 0.9266083753237162\n",
      "배치 인덱스 : 93\t|\t이동 손실 : 0.9259993789043834\n",
      "배치 인덱스 : 94\t|\t이동 손실 : 0.9266587878528396\n",
      "배치 인덱스 : 95\t|\t이동 손실 : 0.9254173785448077\n",
      "배치 인덱스 : 96\t|\t이동 손실 : 0.9264143201493727\n",
      "배치 인덱스 : 97\t|\t이동 손실 : 0.9266109089462127\n",
      "배치 인덱스 : 98\t|\t이동 손실 : 0.9272433868562334\n",
      "배치 인덱스 : 99\t|\t이동 손실 : 0.9271530282497408\n",
      "배치 인덱스 : 100\t|\t이동 손실 : 0.9275456879398613\n",
      "배치 인덱스 : 101\t|\t이동 손실 : 0.9280323789400216\n",
      "배치 인덱스 : 102\t|\t이동 손실 : 0.9286099249876821\n",
      "배치 인덱스 : 103\t|\t이동 손실 : 0.9284628698459041\n",
      "배치 인덱스 : 104\t|\t이동 손실 : 0.9284434488841468\n",
      "배치 인덱스 : 105\t|\t이동 손실 : 0.929562272890559\n",
      "배치 인덱스 : 106\t|\t이동 손실 : 0.929491889811008\n",
      "배치 인덱스 : 107\t|\t이동 손실 : 0.9298612011803524\n",
      "배치 인덱스 : 108\t|\t이동 손실 : 0.9307930961661386\n",
      "배치 인덱스 : 109\t|\t이동 손실 : 0.9304042783650488\n",
      "배치 인덱스 : 110\t|\t이동 손실 : 0.9310080956768348\n",
      "배치 인덱스 : 111\t|\t이동 손실 : 0.9311020895838741\n",
      "배치 인덱스 : 112\t|\t이동 손실 : 0.9307564354575844\n",
      "배치 인덱스 : 113\t|\t이동 손실 : 0.9316312728220959\n",
      "배치 인덱스 : 114\t|\t이동 손실 : 0.9308449543040734\n",
      "배치 인덱스 : 115\t|\t이동 손실 : 0.9308056959818152\n",
      "배치 인덱스 : 116\t|\t이동 손실 : 0.9306922682330142\n",
      "배치 인덱스 : 117\t|\t이동 손실 : 0.9307327952425362\n",
      "배치 인덱스 : 118\t|\t이동 손실 : 0.9308003292364235\n",
      "배치 인덱스 : 119\t|\t이동 손실 : 0.9304178327322009\n",
      "배치 인덱스 : 120\t|\t이동 손실 : 0.930180075247426\n",
      "배치 인덱스 : 121\t|\t이동 손실 : 0.9305157099590929\n",
      "배치 인덱스 : 122\t|\t이동 손실 : 0.9308487690561188\n",
      "배치 인덱스 : 123\t|\t이동 손실 : 0.9321847961794948\n",
      "배치 인덱스 : 124\t|\t이동 손실 : 0.9329075155258181\n",
      "배치 인덱스 : 125\t|\t이동 손실 : 0.9338854097184682\n",
      "배치 인덱스 : 126\t|\t이동 손실 : 0.9347452178714784\n",
      "배치 인덱스 : 127\t|\t이동 손실 : 0.9353710170835258\n",
      "배치 인덱스 : 128\t|\t이동 손실 : 0.9351270822591561\n",
      "배치 인덱스 : 129\t|\t이동 손실 : 0.935875629920226\n",
      "배치 인덱스 : 130\t|\t이동 손실 : 0.9363866211803816\n",
      "배치 인덱스 : 131\t|\t이동 손실 : 0.9362862236572036\n",
      "배치 인덱스 : 132\t|\t이동 손실 : 0.937090905985438\n",
      "배치 인덱스 : 133\t|\t이동 손실 : 0.9372339924769616\n",
      "배치 인덱스 : 134\t|\t이동 손실 : 0.937860499487983\n",
      "배치 인덱스 : 135\t|\t이동 손실 : 0.9375264486845803\n",
      "배치 인덱스 : 136\t|\t이동 손실 : 0.9382458759920442\n",
      "배치 인덱스 : 137\t|\t이동 손실 : 0.9386900123478712\n",
      "배치 인덱스 : 138\t|\t이동 손실 : 0.9389034488218296\n",
      "배치 인덱스 : 139\t|\t이동 손실 : 0.9392542289836069\n",
      "배치 인덱스 : 140\t|\t이동 손실 : 0.9391336047903023\n",
      "배치 인덱스 : 141\t|\t이동 손실 : 0.9393090013886843\n",
      "배치 인덱스 : 142\t|\t이동 손실 : 0.9397988398591958\n",
      "배치 인덱스 : 143\t|\t이동 손실 : 0.9399975865251491\n",
      "배치 인덱스 : 144\t|\t이동 손실 : 0.9403157867234332\n",
      "배치 인덱스 : 145\t|\t이동 손실 : 0.9408295832268182\n",
      "배치 인덱스 : 146\t|\t이동 손실 : 0.9404966405459816\n",
      "배치 인덱스 : 147\t|\t이동 손실 : 0.9406924876006877\n",
      "배치 인덱스 : 148\t|\t이동 손실 : 0.9403453733297006\n",
      "배치 인덱스 : 149\t|\t이동 손실 : 0.9408490892251336\n",
      "배치 인덱스 : 150\t|\t이동 손실 : 0.9411719922987833\n",
      "배치 인덱스 : 151\t|\t이동 손실 : 0.9410827136353446\n",
      "배치 인덱스 : 152\t|\t이동 손실 : 0.9415742073183748\n",
      "배치 인덱스 : 153\t|\t이동 손실 : 0.9416156651137714\n",
      "배치 인덱스 : 154\t|\t이동 손실 : 0.9413580925233905\n",
      "배치 인덱스 : 155\t|\t이동 손실 : 0.941564093415554\n",
      "배치 인덱스 : 156\t|\t이동 손실 : 0.9415391736729133\n",
      "배치 인덱스 : 157\t|\t이동 손실 : 0.9417586368096029\n",
      "배치 인덱스 : 158\t|\t이동 손실 : 0.9412261322609287\n",
      "배치 인덱스 : 159\t|\t이동 손실 : 0.9414883207529786\n",
      "배치 인덱스 : 160\t|\t이동 손실 : 0.9419653486020819\n",
      "배치 인덱스 : 161\t|\t이동 손실 : 0.9422214296129017\n",
      "배치 인덱스 : 162\t|\t이동 손실 : 0.9429191592280852\n",
      "배치 인덱스 : 163\t|\t이동 손실 : 0.9433579212281764\n",
      "배치 인덱스 : 164\t|\t이동 손실 : 0.9439353986219928\n",
      "배치 인덱스 : 165\t|\t이동 손실 : 0.9436624290713347\n",
      "배치 인덱스 : 166\t|\t이동 손실 : 0.9441138745068078\n",
      "배치 인덱스 : 167\t|\t이동 손실 : 0.9448226218422257\n",
      "배치 인덱스 : 168\t|\t이동 손실 : 0.9453560187971806\n",
      "배치 인덱스 : 169\t|\t이동 손실 : 0.9453025979154253\n",
      "배치 인덱스 : 170\t|\t이동 손실 : 0.9452569892531949\n",
      "배치 인덱스 : 171\t|\t이동 손실 : 0.9450146694516028\n",
      "배치 인덱스 : 172\t|\t이동 손실 : 0.9456694236380518\n",
      "배치 인덱스 : 173\t|\t이동 손실 : 0.9455360246115719\n",
      "배치 인덱스 : 174\t|\t이동 손실 : 0.9456986573764258\n",
      "배치 인덱스 : 175\t|\t이동 손실 : 0.9459969171068887\n",
      "배치 인덱스 : 176\t|\t이동 손실 : 0.9465957415305964\n",
      "배치 인덱스 : 177\t|\t이동 손실 : 0.9470839654461723\n",
      "배치 인덱스 : 178\t|\t이동 손실 : 0.9475594099673481\n",
      "배치 인덱스 : 179\t|\t이동 손실 : 0.9473892589410148\n",
      "배치 인덱스 : 180\t|\t이동 손실 : 0.9478403125678638\n",
      "배치 인덱스 : 181\t|\t이동 손실 : 0.9481060550763059\n",
      "배치 인덱스 : 182\t|\t이동 손실 : 0.9485126525326506\n",
      "배치 인덱스 : 183\t|\t이동 손실 : 0.9490439574355666\n",
      "배치 인덱스 : 184\t|\t이동 손실 : 0.9489547938913914\n",
      "배치 인덱스 : 185\t|\t이동 손실 : 0.9494041835749022\n",
      "배치 인덱스 : 186\t|\t이동 손실 : 0.9495299343756815\n",
      "배치 인덱스 : 187\t|\t이동 손실 : 0.9501246990675623\n",
      "배치 인덱스 : 188\t|\t이동 손실 : 0.9500172740567929\n",
      "배치 인덱스 : 189\t|\t이동 손실 : 0.9502702433811991\n",
      "배치 인덱스 : 190\t|\t이동 손실 : 0.9506075653730264\n",
      "배치 인덱스 : 191\t|\t이동 손실 : 0.9507050796722374\n",
      "배치 인덱스 : 192\t|\t이동 손실 : 0.9510934837741557\n",
      "배치 인덱스 : 193\t|\t이동 손실 : 0.9509799197777032\n",
      "배치 인덱스 : 194\t|\t이동 손실 : 0.9510730648652104\n",
      "배치 인덱스 : 195\t|\t이동 손실 : 0.9513791109226191\n",
      "배치 인덱스 : 196\t|\t이동 손실 : 0.9515967220824385\n",
      "배치 인덱스 : 197\t|\t이동 손실 : 0.9517152502079206\n",
      "배치 인덱스 : 198\t|\t이동 손실 : 0.9518234792666223\n",
      "배치 인덱스 : 199\t|\t이동 손실 : 0.9522624334692958\n",
      "배치 인덱스 : 200\t|\t이동 손실 : 0.9524434935394215\n",
      "배치 인덱스 : 201\t|\t이동 손실 : 0.9533035536803826\n",
      "배치 인덱스 : 202\t|\t이동 손실 : 0.9534525442593207\n",
      "배치 인덱스 : 203\t|\t이동 손실 : 0.9536189641438282\n",
      "배치 인덱스 : 204\t|\t이동 손실 : 0.9535299900101456\n",
      "배치 인덱스 : 205\t|\t이동 손실 : 0.9537641215092931\n",
      "배치 인덱스 : 206\t|\t이동 손실 : 0.9540476660797566\n",
      "배치 인덱스 : 207\t|\t이동 손실 : 0.9544268892361571\n",
      "배치 인덱스 : 208\t|\t이동 손실 : 0.9549049144726625\n",
      "배치 인덱스 : 209\t|\t이동 손실 : 0.955128569830032\n",
      "배치 인덱스 : 210\t|\t이동 손실 : 0.9548838373044095\n",
      "배치 인덱스 : 211\t|\t이동 손실 : 0.9549524786899679\n",
      "배치 인덱스 : 212\t|\t이동 손실 : 0.9553897226920155\n",
      "배치 인덱스 : 213\t|\t이동 손실 : 0.9558674707033928\n",
      "배치 인덱스 : 214\t|\t이동 손실 : 0.9555934966996663\n",
      "배치 인덱스 : 215\t|\t이동 손실 : 0.9557257424350143\n",
      "배치 인덱스 : 216\t|\t이동 손실 : 0.9556510970339802\n",
      "배치 인덱스 : 217\t|\t이동 손실 : 0.9555606215918835\n",
      "배치 인덱스 : 218\t|\t이동 손실 : 0.9558488536098781\n",
      "배치 인덱스 : 219\t|\t이동 손실 : 0.9559617058797322\n",
      "배치 인덱스 : 220\t|\t이동 손실 : 0.9563603093721215\n",
      "배치 인덱스 : 221\t|\t이동 손실 : 0.9562632712694982\n",
      "배치 인덱스 : 222\t|\t이동 손실 : 0.9567232776115834\n",
      "배치 인덱스 : 223\t|\t이동 손실 : 0.9567137754389223\n",
      "배치 인덱스 : 224\t|\t이동 손실 : 0.9569757938385015\n",
      "배치 인덱스 : 225\t|\t이동 손실 : 0.9576362461115412\n",
      "배치 인덱스 : 226\t|\t이동 손실 : 0.9584473744362991\n",
      "Epoch: 10 | Time: 13m 38s\n",
      "\tTrain Loss: 0.958 | Train PPL: 2.608\n",
      "\tValidation Loss: 1.732 | Validation PPL: 5.655\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "import random\n",
    "\n",
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time() # 시작 시간 기록\n",
    "\n",
    "    print(f\"에폭 : {epoch}\")\n",
    "\n",
    "    train_loss = train(model, train_dataloader, optimizer, criterion, CLIP, device)\n",
    "    valid_loss = evaluate(model, valid_dataloader, criterion, device)\n",
    "\n",
    "    end_time = time.time() # 종료 시간 기록\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'transformer_german_to_english.pt')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):.3f}')\n",
    "    print(f'\\tValidation Loss: {valid_loss:.3f} | Validation PPL: {math.exp(valid_loss):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1cENwd0ik9C"
   },
   "source": [
    "Epoch: 09 | Time: 13m 20s\n",
    "\tTrain Loss: 1.055 | Train PPL: 2.871\n",
    "\tValidation Loss: 1.691 | Validation PPL: 5.424\n",
    "\n",
    "Epoch: 10 | Time: 13m 38s\n",
    "\tTrain Loss: 0.958 | Train PPL: 2.608\n",
    "\tValidation Loss: 1.732 | Validation PPL: 5.655"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('transformer_german_to_english.pt'))\n",
    "\n",
    "#test_loss = evaluate(model, train_dataloader, criterion, device)\n",
    "\n",
    "#print(f'Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역(translation) 함수\n",
    "def translate_sentence(sentence, src_vocab, trg_vocab, model, device, max_len=50, logging=True):\n",
    "    model.eval() # 평가 모드\n",
    "\n",
    "    if isinstance(sentence, str):\n",
    "        nlp = spacy.load('de')\n",
    "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "\n",
    "    # 처음에  토큰, 마지막에  토큰 붙이기\n",
    "    tokens = ['<bos>'] + tokens + ['<eos>']\n",
    "    if logging:\n",
    "        print(f\"전체 소스 토큰: {tokens}\")\n",
    "\n",
    "    src_indexes = src_vocab.lookup_indices(tokens)\n",
    "    if logging:\n",
    "        print(f\"소스 문장 인덱스: {src_indexes}\")\n",
    "\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
    "\n",
    "    # 소스 문장에 따른 마스크 생성\n",
    "    src_mask = model.create_src_mask(src_tensor)\n",
    "\n",
    "    # 인코더(endocer)에 소스 문장을 넣어 출력 값 구하기\n",
    "    with torch.no_grad():\n",
    "        enc_src = model.encoder(src_tensor, src_mask)\n",
    "\n",
    "    # 처음에는  토큰 하나만 가지고 있도록 하기\n",
    "    trg_indexes = [2] #trg_vocab.lookup_indices(['<bos>'])\n",
    "\n",
    "    for i in range(max_len):\n",
    "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
    "\n",
    "        # 출력 문장에 따른 마스크 생성\n",
    "        trg_mask = model.create_tgt_mask(trg_tensor)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
    "\n",
    "        # 출력 문장에서 가장 마지막 단어만 사용\n",
    "        pred_token = output.argmax(2)[:,-1].item()\n",
    "        trg_indexes.append(pred_token) # 출력 문장에 더하기\n",
    "\n",
    "        # 를 만나는 순간 끝\n",
    "        if pred_token == trg_vocab.lookup_indices(['<eos>'])[0]:\n",
    "            break\n",
    "\n",
    "    # 각 출력 단어 인덱스를 실제 단어로 변환\n",
    "    trg_tokens = [trg_vocab.lookup_token(i) for i in trg_indexes]\n",
    "\n",
    "    # 첫 번째 는 제외하고 출력 문장 반환\n",
    "    return trg_tokens[1:], attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 소스 토큰: ['<bos>', 'ein', 'mädchen', 'in', 'einem', 'jeanskleid', 'läuft', 'über', 'einen', 'erhöhten', 'schwebebalken', '.', '<eos>']\n",
      "소스 문장 인덱스: [2, 15, 0, 7, 6, 0, 86, 43, 20, 3480, 0, 4, 3]\n",
      "['<unk>', '<unk>', 'in', 'a', '<unk>', \"'s\", 'and', 'running', 'over', 'an', 'elevated', 'platform', '.', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "#test_src_sentence = ['eine', 'mutter', 'und', 'ihr', 'kleiner', 'sohn', 'genießen', 'einen', 'schönen', 'tag', 'im', 'freien', '.']\n",
    "test_src_sentence = ['Ein', 'Mädchen', 'in', 'einem', 'Jeanskleid', 'läuft', 'über', 'einen', 'erhöhten', 'Schwebebalken', '.']\n",
    "translation, attention = translate_sentence(test_src_sentence, vocab_transform[SRC_LANG], vocab_transform[TGT_LANG], model, device, logging=True)\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 소스 토큰: ['<bos>', 'eine', 'frau', 'sitzt', 'an', 'einer', 'dunklen', 'bar', '.', '<eos>']\n",
      "소스 문장 인덱스: [2, 18, 0, 32, 23, 13, 389, 0, 4, 3]\n",
      "모델 출력 결과: <unk> <unk> sitting at a dark plastic bar . <eos>\n"
     ]
    }
   ],
   "source": [
    "test_src_sentence = ['Eine', 'Frau', 'sitzt', 'an', 'einer', 'dunklen', 'Bar','.']\n",
    "#A woman sits at a dark bar.\n",
    "translation, attention = translate_sentence(test_src_sentence, vocab_transform[SRC_LANG], vocab_transform[TGT_LANG], model, device, logging=True)\n",
    "print(\"모델 출력 결과:\", \" \".join(translation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
