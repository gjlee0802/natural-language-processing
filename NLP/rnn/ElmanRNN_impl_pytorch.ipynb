{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch에서 제공하는 RNN 클래스는 기본적으로 Elman RNN 이지만,\n",
        "제공하는 클래스 대신 직접 Elman RNN을 구현한다.\n",
        "하나의 RNN 타임 스텝을 구현한 RNNCell을 사용하여 Elman RNN을 구현해보자."
      ],
      "metadata": {
        "id": "xgl8WjQfk-mT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "INTAf_IUmXxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ElmanRNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, batch_first=False): # input_size : 입력 벡터 크기, hidden_size : 은닉 상태 벡터 크기, batch_first : 0번째 차원이 배치인지 여부\n",
        "    super(ElmanRNN, self).__init__()\n",
        "    self.rnn_cell = nn.RNNCell(input_size, hidden_size)\n",
        "\n",
        "    self.batch_first = batch_first  # 0번째 차원이 배치인지 여부\n",
        "    self.hidden_size = hidden_size  # 은닉 상태 벡터 크기\n",
        "\n",
        "  def _initialize_hidden(self, batch_size):\n",
        "    return torch.zeros((batch_size, self.hidden_size)) # 형상은 (N x H)가 되며, N : 배치 크기, H :은닉 상태 크기\n",
        "\n",
        "  def forward(self, x_in, initial_hidden=None):\n",
        "    '''\n",
        "    0번째 차원이 배치라면 x_in의 0번째와 1번째 순서를 바꾸어준다.\n",
        "    반대로 0번째 차원이 배치가 아닌 경우에는\n",
        "    0번째 차원 : 시퀀스 크기 (시계열 데이터의 분량)\n",
        "    1번째 차원 : 배치 크기\n",
        "    '''\n",
        "    if self.batch_first:\n",
        "      batch_size, seq_size, feat_size = x_in.size()\n",
        "      x_in = x_in.permute(1, 0, 2)\n",
        "    else:\n",
        "      seq_size, batch_size, feat_size = x_in.size()\n",
        "\n",
        "    hiddens = []\n",
        "\n",
        "    if initial_hidden is None:                    # 초기 은닉이 정해져있지 않다면, 초기화한다.\n",
        "      initial_hidden = self._initialize_hidden(batch_size)\n",
        "      initial_hidden = initial_hidden.to(x_in.device)\n",
        "\n",
        "    hidden_t = initial_hidden\n",
        "\n",
        "    for t in range(seq_size):\n",
        "      hidden_t = self.rnn_cell(x_in[t], hidden_t) # 입력 벡터와 은닉 상태를 전달하는데, 출력된 은닉 상태는 다음의 rnn_cell에 전달된다.\n",
        "      hiddens.append(hidden_t)\n",
        "\n",
        "    hiddens = torch.stack(hiddens)\n",
        "\n",
        "    if self.batch_first:                          # 0번째 차원이 배치라면 은닉 상태 순서를 바꿔준다.\n",
        "      hiddens = hiddens.permute(1, 0, 2)\n",
        "\n",
        "    return hiddens"
      ],
      "metadata": {
        "id": "lvqI8OMllAED"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}